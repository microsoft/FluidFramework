# Distributed Token Bucket Throttling

> [!TODO] Generated by CoPilot
> This needs review

This module provides a distributed throttling system based on the token bucket algorithm, designed to provide rate limiting across multiple service instances while maintaining local protection against traffic bursts.

## Overview

The `DistributedTokenBucketThrottler` implements a hybrid approach combining local and distributed rate limiting:

-   **Local Token Bucket**: Provides immediate protection within a single service instance
-   **Distributed Token Bucket**: Coordinates rate limiting across multiple service instances via shared storage
-   **Dual-Layer Protection**: Uses the most restrictive limit from either bucket

## Architecture

```text
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Instance A    │    │   Instance B    │    │   Instance C    │
│                 │    │                 │    │                 │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │Local Bucket │ │    │ │Local Bucket │ │    │ │Local Bucket │ │
│ │(Immediate)  │ │    │ │(Immediate)  │ │    │ │(Immediate)  │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
│        │        │    │        │        │    │        │        │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │Distributed  │ │    │ │Distributed  │ │    │ │Distributed  │ │
│ │Bucket       │ │    │ │Bucket       │ │    │ │Bucket       │ │
│ │(Periodic)   │ │    │ │(Periodic)   │ │    │ │(Periodic)   │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
└─────────┬───────┘    └─────────┬───────┘    └─────────┬───────┘
          │                      │                      │
          └──────────────────────┼──────────────────────┘
                                 │
                    ┌─────────────────────┐
                    │   Shared Storage    │
                    │  (Redis/MongoDB)    │
                    └─────────────────────┘
```

## Key Features

### Benefits

1. **Immediate Local Protection**: Local token buckets provide instant rate limiting without waiting for distributed coordination
2. **Cross-Instance Coordination**: Distributed buckets ensure global rate limits are respected across all service instances
3. **Reduced Storage Load**: Asynchronous periodic syncing minimizes pressure on shared storage
4. **Flexible Configuration**: Independent configuration of local and distributed bucket parameters
5. **Backward Compatibility**: Drop-in replacement for legacy throttling systems
6. **Enhanced Telemetry**: Optional detailed logging for monitoring and debugging

### Limitations

1. **Eventual Consistency**: Distributed state has a one sync-cycle delay, which may allow brief over-limit bursts
2. **Memory Overhead**: Maintains LRU cache of token buckets in memory per service instance
3. **Storage Dependency**: Requires shared storage (Redis/MongoDB) for distributed coordination
4. **Configuration Complexity**: Requires careful tuning of both local and distributed parameters

## Configuration

The throttler is configured via `IDistributedTokenBucketThrottlerConfig`:

### Local Token Bucket Configuration

```typescript
localTokenBucket: {
	capacity: number; // Maximum tokens the bucket can hold
	refillRatePerMs: number; // Tokens added per millisecond
	minCooldownIntervalMs: number; // Minimum time between refill operations
}
```

### Distributed Token Bucket Configuration

```typescript
distributedTokenBucket: {
	capacity: number; // Maximum tokens across all instances
	refillRatePerMs: number; // Tokens added per millisecond globally
	minCooldownIntervalMs: number; // Minimum time between refill operations
	distributedSyncIntervalInMs: number; // How often to sync with storage
}
```

### Cache and Telemetry Options

```typescript
maxLocalCacheSize?: number;        // Max number of tracked IDs (default: 1,000,000)
maxLocalCacheAgeInMs?: number;     // Cache entry expiration (default: 60,000ms)
enableEnhancedTelemetry?: boolean; // Detailed logging (default: false)
```

## Usage Examples

### Basic Setup

```typescript
import {
	DistributedTokenBucketThrottler,
	IDistributedTokenBucketThrottlerConfig,
} from "@fluidframework/server-services";

const config: IDistributedTokenBucketThrottlerConfig = {
	localTokenBucket: {
		capacity: 10, // Allow 10 operations per instance immediately
		refillRatePerMs: 0.1, // Add 1 token every 10ms (100 ops/second)
		minCooldownIntervalMs: 100,
	},
	distributedTokenBucket: {
		capacity: 100, // Allow 100 operations across all instances
		refillRatePerMs: 1, // Add 1 token per ms (1000 ops/second globally)
		minCooldownIntervalMs: 1000,
		distributedSyncIntervalInMs: 5000, // Sync every 5 seconds
	},
};

const throttler = new DistributedTokenBucketThrottler(
	storageManager, // IThrottleAndUsageStorageManager instance
	logger, // Optional ILogger instance
	config,
);
```

### Rate Limiting Operations

```typescript
try {
	// Throttle a single operation
	throttler.incrementCount("user:12345", 1);

	// Throttle a weighted operation (e.g., expensive API call)
	throttler.incrementCount("api:upload", 5);

	// Process the operation...
} catch (error) {
	if (error instanceof ThrottlingError) {
		// Handle throttling
		const retryAfterSeconds = error.retryAfterInSeconds;
		console.log(`Rate limited. Retry after ${retryAfterSeconds} seconds`);
	}
}
```

### Replenishing Tokens

```typescript
// Return tokens for cancelled/failed operations
throttler.decrementCount("user:12345", 1);

// Return tokens for a weighted operation
throttler.decrementCount("api:upload", 5);
```

### Production Configuration Examples

#### API Gateway Setup

```typescript
const apiGatewayConfig: IDistributedTokenBucketThrottlerConfig = {
	localTokenBucket: {
		capacity: 50, // Burst protection per instance
		refillRatePerMs: 0.5, // 500 requests/second per instance
		minCooldownIntervalMs: 100,
	},
	distributedTokenBucket: {
		capacity: 500, // Global burst capacity
		refillRatePerMs: 5, // 5000 requests/second globally
		minCooldownIntervalMs: 1000,
		distributedSyncIntervalInMs: 10000, // Sync every 10 seconds
	},
	maxLocalCacheSize: 10000, // Track up to 10K users
	maxLocalCacheAgeInMs: 300000, // 5 minute cache expiration
	enableEnhancedTelemetry: true,
};
```

#### Low-Latency Service Setup

```typescript
const lowLatencyConfig: IDistributedTokenBucketThrottlerConfig = {
	localTokenBucket: {
		capacity: 100, // Higher local capacity for responsiveness
		refillRatePerMs: 2, // 2000 ops/second per instance
		minCooldownIntervalMs: 50, // Faster local refill
	},
	distributedTokenBucket: {
		capacity: 1000,
		refillRatePerMs: 20, // 20000 ops/second globally
		minCooldownIntervalMs: 500,
		distributedSyncIntervalInMs: 2000, // More frequent syncing
	},
	maxLocalCacheSize: 50000,
	maxLocalCacheAgeInMs: 120000, // 2 minute cache
};
```

## Best Practices

### Configuration Guidelines

1. **Local vs Distributed Capacity**: Set local capacity to 10-20% of distributed capacity
2. **Sync Interval**: Balance between accuracy and storage load (5-30 seconds typical)
3. **Cache Size**: Size cache to handle expected concurrent users with some overhead
4. **Cache Age**: Should be longer than sync interval to avoid losing tracking data

### Operational Considerations

1. **Monitor Cache Evictions**: Enable enhanced telemetry in production to detect undersized caches
2. **Storage Performance**: Ensure shared storage can handle sync frequency across all instances
3. **Gradual Rollout**: Test with conservative limits before applying production rates
4. **Alerting**: Monitor for storage failures that could disable distributed coordination

### Migration from Legacy Throttling

```typescript
// Legacy throttler usage
const legacyThrottler = new Throttler(storageManager /* ... */);

// Direct replacement with distributed throttling
const newThrottler = new DistributedTokenBucketThrottler(storageManager, logger, {
	// Configure to match or improve upon legacy behavior
	localTokenBucket: {
		/* ... */
	},
	distributedTokenBucket: {
		/* ... */
	},
});

// Same API - no code changes needed!
newThrottler.incrementCount(id, weight);
```

## Monitoring and Debugging

Enable enhanced telemetry for production monitoring:

```typescript
const config = {
	// ... other config
	enableEnhancedTelemetry: true,
};
```

This provides detailed logging for:

-   Cache evictions and memory pressure
-   Distributed sync operations and failures
-   Token bucket state changes
-   Throttling decisions and retry times

## Related Classes

-   **`TokenBucket`**: Core token bucket implementation for local rate limiting
-   **`DistributedTokenBucket`**: Distributed-aware token bucket with periodic syncing
-   **`RedisThrottleAndUsageStorageManager`**: Redis-based storage backend for distributed state
-   **Legacy classes**: `Throttler` and `ThrottlerHelper` for backward compatibility
