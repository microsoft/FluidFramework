/*!
 * Copyright (c) Microsoft Corporation and contributors. All rights reserved.
 * Licensed under the MIT License.
 */

import { strict as assert } from "node:assert";

import { IdCompressor } from "../idCompressor.js";
import { isFinalId } from "../identifiers.js";
import type { SessionSpaceCompressedId } from "../index.js";
import { SerializationVersion } from "../types/index.js";
import { createSessionId } from "../utilities.js";

import { isLocalId } from "./testCommon.js";

describe("IdCompressor Sharding", () => {
	describe("Basic Sharding", () => {
		it("can create shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate some IDs before sharding
			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			assert(isLocalId(id1));
			assert(isLocalId(id2));
			assert(isLocalId(id3));

			// Create 2 shards (parent + 2 children = 3 total)
			const shards = parent.shard(2);
			assert.equal(shards.length, 2);

			// Verify parent can still generate IDs (is in sharding mode)
			const id4 = parent.generateCompressedId();
			assert(isLocalId(id4));
		});

		it("children recognize parent's pre-shard IDs", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 3 IDs before sharding (genCounts 1, 2, 3 â†’ IDs -1, -2, -3)
			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			assert.equal(id1, -1);
			assert.equal(id2, -2);
			assert.equal(id3, -3);

			// Get UUIDs for these IDs from parent
			const uuid1 = parent.decompress(id1);
			const uuid2 = parent.decompress(id2);
			const uuid3 = parent.decompress(id3);

			// Shard into 3 (stride=3, offsets 0,1,2)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Children should be able to decompress parent's pre-shard IDs
			// They share the same session and are forks of the parent
			assert.equal(child1.decompress(id1), uuid1);
			assert.equal(child1.decompress(id2), uuid2);
			assert.equal(child1.decompress(id3), uuid3);

			assert.equal(child2.decompress(id1), uuid1);
			assert.equal(child2.decompress(id2), uuid2);
			assert.equal(child2.decompress(id3), uuid3);

			// Parent should still be able to decompress
			assert.equal(parent.decompress(id1), uuid1);
			assert.equal(parent.decompress(id2), uuid2);
			assert.equal(parent.decompress(id3), uuid3);
		});

		it("shards do not recognize IDs generated after sharding in other shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 shards (stride=3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Child1 generates an ID (-2, genCount 2)
			const child1Id = child1.generateCompressedId();
			assert.equal(child1Id, -2);

			// Child2 should NOT be able to decompress child1's ID
			// because it was generated after the shard point and child2 hasn't
			// received the information about child1's new ID yet
			assert.throws(() => {
				child2.decompress(child1Id);
			}, "Child2 should not recognize Child1's post-shard ID");

			// Parent also cannot decompress it yet, as the ID was generated by a shard
			// The parent would need to receive this information through the document
			assert.throws(() => {
				parent.decompress(child1Id);
			}, "Parent should not recognize Child1's post-shard ID until it receives that information");
		});

		it("sharding with pre-existing IDs follows stride pattern correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 3 IDs before sharding (genCounts 1,2,3 occupy first cycle)
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -2
			parent.generateCompressedId(); // -3

			// Shard into 3 (stride=3)
			// After sharding, stride pattern distributes future genCounts:
			//   - Parent (offset=0) owns: 1, 4, 7, 10, ... (has generated 1, next is 4)
			//   - Child1 (offset=1) owns: 2, 5, 8, 11, ... (has generated 1, next is 5)
			//   - Child2 (offset=2) owns: 3, 6, 9, 12, ... (has generated 1, next is 6)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify starting state by checking the IDs they generate
			// If localGenCount was inherited correctly, they should generate the right sequence

			// Now generate next IDs - should follow stride pattern from genCount 4 onward
			const parentNext = parent.generateCompressedId();
			const child1Next = child1.generateCompressedId();
			const child2Next = child2.generateCompressedId();

			assert.equal(parentNext, -4); // genCount 4
			assert.equal(child1Next, -5); // genCount 5
			assert.equal(child2Next, -6); // genCount 6
		});

		it("sharding with partial cycle follows stride pattern correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 5 IDs before sharding (completes 1 cycle, half-fills second)
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -2
			parent.generateCompressedId(); // -3
			parent.generateCompressedId(); // -4
			parent.generateCompressedId(); // -5

			// Shard into 3 (stride=3)
			// Distribution after sharding:
			//   - Cycle 0 (genCounts 1-3): all filled
			//   - Cycle 1 (genCounts 4-6): slots 4,5 filled, slot 6 empty
			// After sharding:
			//   - Parent (offset=0) owns: 1, 4, 7, ... (has generated 2: genCounts 1,4)
			//   - Child1 (offset=1) owns: 2, 5, 8, ... (has generated 2: genCounts 2,5)
			//   - Child2 (offset=2) owns: 3, 6, 9, ... (has generated 1: genCount 3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify state by checking the IDs they generate
			// The stride pattern should handle the partial cycle correctly

			// Generate next IDs - each jumps to next in its stride after localGenCount=5
			const parentNext = parent.generateCompressedId();
			const child1Next = child1.generateCompressedId();
			const child2Next = child2.generateCompressedId();

			assert.equal(parentNext, -7); // Next in {1,4,7,...} after 5
			assert.equal(child1Next, -8); // Next in {2,5,8,...} after 5
			assert.equal(child2Next, -6); // Next in {3,6,9,...} after 5
		});

		it("generates IDs with stride pattern", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 shards (stride = 3)
			const [serializedChild1, serializedChild2] = parent.shard(2);

			const child1 = IdCompressor.deserialize({
				serialized: serializedChild1,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: serializedChild2,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent (offset=0): should generate -1, -4, -7, ...
			const parentId1 = parent.generateCompressedId();
			assert.equal(parentId1, -1);
			const parentId2 = parent.generateCompressedId();
			assert.equal(parentId2, -4);

			// Child 1 (offset=1): should generate -2, -5, -8, ...
			const child1Id1 = child1.generateCompressedId();
			assert.equal(child1Id1, -2);
			const child1Id2 = child1.generateCompressedId();
			assert.equal(child1Id2, -5);

			// Child 2 (offset=2): should generate -3, -6, -9, ...
			const child2Id1 = child2.generateCompressedId();
			assert.equal(child2Id1, -3);
			const child2Id2 = child2.generateCompressedId();
			assert.equal(child2Id2, -6);
		});

		it("no eager finals during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate and finalize some IDs to create a cluster
			parent.generateCompressedId();
			parent.generateCompressedId();
			const range = parent.takeNextCreationRange();
			parent.finalizeCreationRange(range);

			// Now parent has a cluster with capacity, normally would generate eager finals
			// But after sharding, should only generate local IDs
			parent.shard(1);

			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			// All should be local IDs despite cluster availability
			assert(isLocalId(id1));
			assert(isLocalId(id2));
			assert(isLocalId(id3));
		});

		it("shards cannot decompress IDs beyond their generation count", () => {
			// When a shard generates an ID, it "backfills" the entire cycle containing that ID.
			// A cycle is a group of consecutive genCounts equal to the stride size.
			// For stride=3: cycle 0 = [1,2,3], cycle 1 = [4,5,6], cycle 2 = [7,8,9], etc.
			// Shards can only decompress IDs within cycles they have backfilled.

			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 child shards (stride = 3 total)
			// Parent: offset=0, generates genCounts 1, 4, 7, ...
			// Child1: offset=1, generates genCounts 2, 5, 8, ...
			const [serializedChild1] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: serializedChild1,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent generates 2 IDs, backfilling cycles 0 and 1
			const parentId1 = parent.generateCompressedId(); // genCount 1, backfills cycle 0
			const parentId2 = parent.generateCompressedId(); // genCount 4, backfills cycle 1
			assert.equal(parentId1, -1);
			assert.equal(parentId2, -4);

			// Child1 generates 1 ID, backfilling only cycle 0
			const child1Id1 = child1.generateCompressedId(); // genCount 2, backfills cycle 0
			assert.equal(child1Id1, -2);

			// Each shard can decompress its own IDs
			assert(parent.decompress(parentId1) !== undefined);
			assert(parent.decompress(parentId2) !== undefined);
			assert(child1.decompress(child1Id1) !== undefined);

			// Child1 can decompress parent's ID from cycle 0 (both backfilled it)
			assert(child1.decompress(parentId1) !== undefined);

			// Child1 cannot decompress parent's ID from cycle 1 (child1 never backfilled it)
			assert.throws(() => child1.decompress(parentId2), /Unknown ID/);

			// Neither shard can decompress IDs from cycles they haven't backfilled
			assert.throws(() => parent.decompress(-7 as SessionSpaceCompressedId), /Unknown ID/); // cycle 2
			assert.throws(() => child1.decompress(-5 as SessionSpaceCompressedId), /Unknown ID/); // cycle 1
		});
	});

	describe("Unsharding", () => {
		it("can unshard and resume normal operation", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs in child (-2 = genCount 2, -4 = genCount 4)
			child.generateCompressedId(); // -2
			child.generateCompressedId(); // -4

			// Dispose child and get its shard ID for unsharding
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			// Child's localGenCount = 4 (last genCount generated)
			assert.equal(childShardId.localGenCount, 4);

			// Unshard
			parent.unshard(childShardId);

			// Child should now be disposed and unusable
			assert.throws(() => {
				child.generateCompressedId();
			}, /disposed/);

			// Parent should now exit sharding mode (has no more active children)
			// We can verify this by checking it generates sequential IDs again

			// Next ID should be -5 (continuing from where shards left off)
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -5);
		});

		it("resumes eager final ID allocation after unsharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate and finalize IDs to create a cluster with capacity
			for (let i = 0; i < 3; i++) {
				parent.generateCompressedId();
			}
			const range = parent.takeNextCreationRange();
			parent.finalizeCreationRange(range);

			// At this point, cluster has capacity for more IDs (default is 512)
			// Normally would generate eager finals, but after sharding, should use locals
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// During sharding, both generate local IDs despite cluster capacity
			const id1 = parent.generateCompressedId();
			const id2 = child.generateCompressedId();
			assert(isLocalId(id1));
			assert(isLocalId(id2));

			// Dispose and unshard
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			parent.unshard(childShardId);

			// After unsharding, eager finals should resume since cluster has capacity
			const id3 = parent.generateCompressedId();
			assert(isFinalId(id3), "Should resume generating eager final IDs after unsharding");
		});

		it("merges normalizer state correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards (stride=2)
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent generates -1, child generates -2
			parent.generateCompressedId(); // -1
			child.generateCompressedId(); // -2

			// Dispose child and get its shard ID
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);

			// Unshard child
			parent.unshard(childShardId);

			// Parent should now know about both IDs
			// This is tested implicitly by decompress working
			const uuid1 = parent.decompress(-1 as SessionSpaceCompressedId);
			const uuid2 = parent.decompress(-2 as SessionSpaceCompressedId);

			assert(uuid1 !== undefined);
			assert(uuid2 !== undefined);
			assert(uuid1 !== uuid2);
		});

		it("handles empty shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shard
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Don't generate any IDs in child

			// Dispose empty child
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			assert.equal(childShardId.localGenCount, 0);

			// Unshard empty child
			parent.unshard(childShardId);

			// Should still work
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -1);
		});

		it("handles unsharding in any order", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 3 shards
			const [s1, s2, s3] = parent.shard(3);
			const child1 = IdCompressor.deserialize({
				serialized: s1,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: s2,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child3 = IdCompressor.deserialize({
				serialized: s3,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs
			child1.generateCompressedId();
			child2.generateCompressedId();
			child2.generateCompressedId();
			child3.generateCompressedId();
			child3.generateCompressedId();
			child3.generateCompressedId();

			// Dispose and unshard in reverse order
			const child3ShardId = child3.disposeShard();
			const child1ShardId = child1.disposeShard();
			const child2ShardId = child2.disposeShard();
			assert(child3ShardId !== undefined);
			assert(child1ShardId !== undefined);
			assert(child2ShardId !== undefined);
			parent.unshard(child3ShardId);
			parent.unshard(child1ShardId);
			parent.unshard(child2ShardId);

			// Should have exited sharding mode (verify by generating sequential ID)
			// After all children unsharded, parent should generate sequentially

			// localGenCount should be max of all shards: 3*4 = 12
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -13);
		});
	});

	describe("Recursive Sharding", () => {
		it("supports recursive sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// First shard: create 2 children (stride=3)
			const [child1Ser] = parent.shard(2);

			// Parent now has stride=3, offset=0
			const parentId1 = parent.generateCompressedId();
			assert.equal(parentId1, -1);

			// Second shard on parent: create 1 more child (stride=6)
			const [child3Ser] = parent.shard(1);

			// Child3 has stride=6, offset=3
			const child3 = IdCompressor.deserialize({
				serialized: child3Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child3Id = child3.generateCompressedId();
			assert.equal(child3Id, -4); // First in stride=6, offset=3 sequence

			// Child1 still has stride=3, offset=1 (unaffected by second shard)
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child1Id = child1.generateCompressedId();
			assert.equal(child1Id, -2); // First in stride=3, offset=1 sequence

			// Parent now has stride=6, offset=0
			const parentId2 = parent.generateCompressedId();
			assert.equal(parentId2, -7); // Next in stride=6 sequence from -1
		});

		it("handles complex multi-level sharding and unsharding", () => {
			const sessionId = createSessionId();
			const root = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Level 1: Root shards into 2 children (stride=3)
			const [child1Ser, child2Ser] = root.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Root (offset=0): generates -1
			const rootId1 = root.generateCompressedId();
			assert.equal(rootId1, -1);

			// Child1 (offset=1): generates -2
			const child1Id1 = child1.generateCompressedId();
			assert.equal(child1Id1, -2);

			// Level 2: Child1 recursively shards into 2 grandchildren (stride=6)
			const [grandchild1Ser, grandchild2Ser] = child1.shard(2);
			const grandchild1 = IdCompressor.deserialize({
				serialized: grandchild1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const grandchild2 = IdCompressor.deserialize({
				serialized: grandchild2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Grandchild1 (offset=4): generates -5
			const gc1Id = grandchild1.generateCompressedId();
			assert.equal(gc1Id, -5);

			// Grandchild2 (offset=7): generates -8
			const gc2Id = grandchild2.generateCompressedId();
			assert.equal(gc2Id, -8);

			// Child2 (offset=2): generates -3
			const child2Id1 = child2.generateCompressedId();
			assert.equal(child2Id1, -3);

			// Begin unsharding: Dispose grandchildren and unshard them back into child1
			const gc1ShardId = grandchild1.disposeShard();
			const gc2ShardId = grandchild2.disposeShard();
			assert(gc1ShardId !== undefined);
			assert(gc2ShardId !== undefined);
			child1.unshard(gc1ShardId);
			child1.unshard(gc2ShardId);

			// Child1 exits recursive sharding mode and restores its original stride-3 pattern
			// After unsharding, it continues its stride-3 pattern (2, 5, 8, 11, ...)
			// The highest genCount generated was 8, so the next in the pattern is 11
			const child1Id2 = child1.generateCompressedId();
			assert.equal(child1Id2, -11);

			// Child2 is still a shard of root with stride-3 pattern (3, 6, 9, ...)
			// Root is still in sharding mode because it has active children (child1 and child2)

			// Generate some more IDs to verify behavior
			const child2Id2 = child2.generateCompressedId();
			assert.equal(child2Id2, -6); // Child2's second ID in stride=3

			// Verify: child2 should generate -9 next (stride pattern: 3, 6, 9, ...)
			const child2Id3 = child2.generateCompressedId();
			assert.equal(child2Id3, -9); // This would be a collision if child1 also generated -9!
		});
	});

	describe("Error Conditions", () => {
		it("throws when attempting to start a ghost session while sharded", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards to enter sharding mode
			parent.shard(1);

			// Attempt to start a ghost session should throw
			const ghostSessionId = createSessionId();
			assert.throws(() => {
				parent.beginGhostSession(ghostSessionId, () => {
					// This callback should never be reached
					parent.generateCompressedId();
				});
			}, /Cannot start a ghost session while sharded/);
		});

		it("throws when attempting to shard during a ghost session", () => {
			const sessionId = createSessionId();
			const compressor = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Start a ghost session
			const ghostSessionId = createSessionId();

			// Attempt to shard during ghost session should throw
			assert.throws(() => {
				compressor.beginGhostSession(ghostSessionId, () => {
					// Attempt to shard while ghost session is active
					compressor.shard(1);
				});
			}, /Cannot shard during ghost session/);
		});
	});

	describe("Serialization", () => {
		it("serializes and deserializes sharding state", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			parent.shard(2);

			// Generate some IDs
			parent.generateCompressedId();
			parent.generateCompressedId();

			// Serialize
			const serialized = parent.serialize(true);

			// Deserialize
			const restored = IdCompressor.deserialize({
				serialized,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify sharding state preserved by checking ID generation continues correctly

			// Verify can continue generating with correct stride
			const nextId = restored.generateCompressedId();
			assert.equal(nextId, -7); // Next in sequence {1,4,7,...}
		});

		it("handles version 2 documents without sharding state", () => {
			const sessionId = createSessionId();
			// Create a version 2 document (no sharding support)
			const compressor = new IdCompressor(sessionId, undefined, SerializationVersion.V2);

			// Generate some IDs
			compressor.generateCompressedId();
			compressor.generateCompressedId();

			// Serialize as version 2 (no sharding state)
			const serialized = compressor.serialize(true);

			// Deserialize - should work fine even though deserialization code supports V3
			const restored = IdCompressor.deserialize({
				serialized,
				requestedWriteVersion: SerializationVersion.V2,
			});

			// Calling disposeShard() on V2 document should throw
			assert.throws(() => {
				restored.disposeShard();
			}, /Sharding requires document version 3 or higher/);

			// Should work normally
			const id = restored.generateCompressedId();
			assert.equal(id, -3);
		});

		it("serializes and deserializes recursive sharding state", () => {
			const sessionId = createSessionId();
			const root = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Root shards into 2 children
			const [child1Ser] = root.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Child1 recursively shards into 2 grandchildren
			const [grandchild1Ser] = child1.shard(2);
			const grandchild1 = IdCompressor.deserialize({
				serialized: grandchild1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs at each level
			root.generateCompressedId(); // -1
			child1.generateCompressedId(); // -5
			grandchild1.generateCompressedId(); // -9

			// Serialize each compressor
			const rootSerialized = root.serialize(true);
			const child1Serialized = child1.serialize(true);
			const grandchild1Serialized = grandchild1.serialize(true);

			// Deserialize and verify sharding state is preserved
			const rootRestored = IdCompressor.deserialize({
				serialized: rootSerialized,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child1Restored = IdCompressor.deserialize({
				serialized: child1Serialized,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const grandchild1Restored = IdCompressor.deserialize({
				serialized: grandchild1Serialized,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify sharding state is preserved after deserialization
			// by checking that they continue generating IDs correctly

			// Verify they continue generating IDs correctly after deserialization
			const rootNext = rootRestored.generateCompressedId();
			const child1Next = child1Restored.generateCompressedId();
			const grandchild1Next = grandchild1Restored.generateCompressedId();

			assert.equal(rootNext, -4); // Next in stride for root
			assert.equal(child1Next, -11); // Next in stride for child1
			assert.equal(grandchild1Next, -14); // Next in stride for grandchild1
		});
	});

	describe("LocalGenCount Semantics", () => {
		it("localGenCount is not decremented during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 5 IDs
			for (let i = 0; i < 5; i++) {
				parent.generateCompressedId();
			}

			// Shard into 3 (parent owns {1,4,7,...}, child1 owns {2,5,8,...}, child2 owns {3,6,9,...})
			parent.shard(2);

			// Can still decompress ID -5 (genCount 5) - proves localGenCount wasn't decremented
			assert.doesNotThrow(() => parent.decompress(-5 as SessionSpaceCompressedId));

			// takeNextCreationRange should include all 5 generated IDs
			const range = parent.takeNextCreationRange();
			assert(range.ids !== undefined);
			assert.equal(range.ids.count, 5, "Range should include all 5 generated IDs");

			// Next ID should jump to next in stride (genCount 7, ID -7)
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -7, "Should jump to next genCount in stride sequence");
		});

		it("localGenCount increments by stride in sharded mode", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Shard immediately (stride=2, parent owns {1,3,5,...}, child owns {2,4,6,...})
			const [childSer] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: childSer,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent generates IDs with stride 2
			const id1 = parent.generateCompressedId(); // genCount 1, ID -1
			assert.equal(id1, -1);
			const id2 = parent.generateCompressedId(); // genCount 3, ID -3
			assert.equal(id2, -3);
			const id3 = parent.generateCompressedId(); // genCount 5, ID -5
			assert.equal(id3, -5);

			// Child generates IDs with stride 2
			const childId1 = child.generateCompressedId(); // genCount 2, ID -2
			assert.equal(childId1, -2);
			const childId2 = child.generateCompressedId(); // genCount 4, ID -4
			assert.equal(childId2, -4);

			// Verify localGenCount by disposing child and checking
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			assert.equal(childShardId.localGenCount, 4, "Child localGenCount should be 4");
		});
	});

	describe("Creation Ranges", () => {
		it("takeNextCreationRange works correctly during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate some IDs before sharding
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -2
			parent.generateCompressedId(); // -3

			// Shard into 3 (stride=3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate more IDs in each shard
			parent.generateCompressedId(); // -4 (genCount 4)
			parent.generateCompressedId(); // -7 (genCount 7)
			child1.generateCompressedId(); // -5 (genCount 5)
			child1.generateCompressedId(); // -8 (genCount 8)
			child2.generateCompressedId(); // -6 (genCount 6)

			// Take ranges
			const parentRange = parent.takeNextCreationRange();
			const child1Range = child1.takeNextCreationRange();
			const child2Range = child2.takeNextCreationRange();

			// Verify parent range (genCounts 1-7, but only owns 1,4,7 in stride)
			assert(parentRange.ids !== undefined);
			assert.equal(parentRange.ids.firstGenCount, 1);
			assert.equal(parentRange.ids.count, 7); // Total genCounts generated: 1,2,3,4,5,6,7

			// Verify child1 range (genCounts 1-8, owns 2,5,8 in stride)
			assert(child1Range.ids !== undefined);
			assert.equal(child1Range.ids.firstGenCount, 1);
			assert.equal(child1Range.ids.count, 8); // Inherited pre-shard IDs plus own generated

			// Verify child2 range (genCounts 1-6, owns 3,6 in stride)
			assert(child2Range.ids !== undefined);
			assert.equal(child2Range.ids.firstGenCount, 1);
			assert.equal(child2Range.ids.count, 6); // Inherited pre-shard IDs plus own generated

			// Verify local ID ranges are correct (all IDs should be in normalizer)
			assert(parentRange.ids.localIdRanges.length > 0);
			assert(child1Range.ids.localIdRanges.length > 0);
			assert(child2Range.ids.localIdRanges.length > 0);
		});

		it("takeNextCreationRange after unsharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs
			parent.generateCompressedId(); // -1
			child.generateCompressedId(); // -2
			parent.generateCompressedId(); // -3
			child.generateCompressedId(); // -4

			// Dispose and unshard
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined, "child.disposeShard() returned undefined");
			parent.unshard(childShardId);

			// Take range after unsharding
			const range = parent.takeNextCreationRange();

			assert(range.ids !== undefined);
			assert.equal(range.ids.firstGenCount, 1);
			assert.equal(range.ids.count, 4); // All genCounts 1-4

			// Generate more IDs and take another range (should continue sequentially)
			parent.generateCompressedId(); // -5
			parent.generateCompressedId(); // -6

			const range2 = parent.takeNextCreationRange();
			assert(range2.ids !== undefined);
			assert.equal(range2.ids.firstGenCount, 5);
			assert.equal(range2.ids.count, 2);
		});

		it("multiple takeNextCreationRange calls during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Shard (don't need to use the child for this test)
			parent.shard(1);

			// Generate and take first range
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -3
			const range1 = parent.takeNextCreationRange();

			assert(range1.ids !== undefined);
			assert.equal(range1.ids.firstGenCount, 1);
			assert.equal(range1.ids.count, 3); // genCounts 1,2,3 (stride backfill)

			// Generate and take second range
			parent.generateCompressedId(); // -5
			const range2 = parent.takeNextCreationRange();

			assert(range2.ids !== undefined);
			assert.equal(range2.ids.firstGenCount, 4);
			assert.equal(range2.ids.count, 2); // genCounts 4,5 (parent owns 1,3,5 in stride=2)

			// Verify ranges are consecutive and non-overlapping
			assert.equal(range1.ids.firstGenCount + range1.ids.count, range2.ids.firstGenCount);
		});

		it("ranges can be finalized correctly during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Shard
			parent.shard(1);

			// Generate IDs
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -3

			// Take and finalize range
			const range = parent.takeNextCreationRange();
			assert(range.ids !== undefined);

			// Should not throw
			parent.finalizeCreationRange(range);

			// After finalization, parent should still be in sharding mode (no eager finals)
			const nextId = parent.generateCompressedId(); // -5
			assert(
				isLocalId(nextId),
				"Should still generate local IDs after finalization during sharding",
			);
		});
	});
});
