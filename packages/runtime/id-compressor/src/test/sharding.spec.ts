/*!
 * Copyright (c) Microsoft Corporation and contributors. All rights reserved.
 * Licensed under the MIT License.
 */

import { strict as assert } from "node:assert";

import { IdCompressor, SerializationVersion } from "../idCompressor.js";
import { isFinalId } from "../identifiers.js";
import type { SessionSpaceCompressedId } from "../index.js";
import { createSessionId } from "../utilities.js";

import { isLocalId } from "./testCommon.js";

describe("IdCompressor Sharding", () => {
	describe("Basic Sharding", () => {
		it("can create shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate some IDs before sharding
			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			assert(isLocalId(id1));
			assert(isLocalId(id2));
			assert(isLocalId(id3));

			// Create 2 shards (parent + 2 children = 3 total)
			const shards = parent.shard(2);
			assert.equal(shards.length, 2);

			// Verify parent's shard ID
			const parentShardId = parent.shardId();
			assert(parentShardId !== undefined);
			assert.equal(parentShardId.shardId, 0);
			assert.equal(parentShardId.strideFillCount, 1); // Parent now only "owns" genCount 1 in stride pattern
		});

		it("children recognize parent's pre-shard IDs", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 3 IDs before sharding (genCounts 1, 2, 3 â†’ IDs -1, -2, -3)
			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			assert.equal(id1, -1);
			assert.equal(id2, -2);
			assert.equal(id3, -3);

			// Get UUIDs for these IDs from parent
			const uuid1 = parent.decompress(id1);
			const uuid2 = parent.decompress(id2);
			const uuid3 = parent.decompress(id3);

			// Shard into 3 (stride=3, offsets 0,1,2)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Children should be able to decompress parent's pre-shard IDs
			// They share the same session and are forks of the parent
			assert.equal(child1.decompress(id1), uuid1);
			assert.equal(child1.decompress(id2), uuid2);
			assert.equal(child1.decompress(id3), uuid3);

			assert.equal(child2.decompress(id1), uuid1);
			assert.equal(child2.decompress(id2), uuid2);
			assert.equal(child2.decompress(id3), uuid3);

			// Parent should still be able to decompress
			assert.equal(parent.decompress(id1), uuid1);
			assert.equal(parent.decompress(id2), uuid2);
			assert.equal(parent.decompress(id3), uuid3);
		});

		it("shards do not recognize IDs generated after sharding in other shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 shards (stride=3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Child1 generates an ID (-2, genCount 2)
			const child1Id = child1.generateCompressedId();
			assert.equal(child1Id, -2);

			// Child2 should NOT be able to decompress child1's ID
			// because it was generated after the shard point and child2 hasn't
			// received the information about child1's new ID yet
			assert.throws(() => {
				child2.decompress(child1Id);
			}, "Child2 should not recognize Child1's post-shard ID");

			// Parent also cannot decompress it yet, as the ID was generated by a shard
			// The parent would need to receive this information through the document
			assert.throws(() => {
				parent.decompress(child1Id);
			}, "Parent should not recognize Child1's post-shard ID until it receives that information");
		});

		it("sharding with pre-existing IDs follows stride pattern correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 3 IDs before sharding (genCounts 1,2,3 occupy first cycle)
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -2
			parent.generateCompressedId(); // -3

			// Shard into 3 (stride=3)
			// After sharding, stride pattern distributes future genCounts:
			//   - Parent (offset=0) owns: 1, 4, 7, 10, ... (has generated 1, next is 4)
			//   - Child1 (offset=1) owns: 2, 5, 8, 11, ... (has generated 1, next is 5)
			//   - Child2 (offset=2) owns: 3, 6, 9, 12, ... (has generated 1, next is 6)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Verify starting localGenCount for each shard
			const parentShardId = parent.shardId();
			const child1ShardId = child1.shardId();
			const child2ShardId = child2.shardId();

			assert(parentShardId !== undefined);
			assert(child1ShardId !== undefined);
			assert(child2ShardId !== undefined);

			assert.equal(parentShardId.strideFillCount, 1); // Has generated 1 from its stride
			assert.equal(child1ShardId.strideFillCount, 1); // Has generated 1 from its stride
			assert.equal(child2ShardId.strideFillCount, 1); // Has generated 1 from its stride

			// Now generate next IDs - should follow stride pattern from genCount 4 onward
			const parentNext = parent.generateCompressedId();
			const child1Next = child1.generateCompressedId();
			const child2Next = child2.generateCompressedId();

			assert.equal(parentNext, -4); // genCount 4
			assert.equal(child1Next, -5); // genCount 5
			assert.equal(child2Next, -6); // genCount 6
		});

		it("sharding with partial cycle follows stride pattern correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 5 IDs before sharding (completes 1 cycle, half-fills second)
			parent.generateCompressedId(); // -1
			parent.generateCompressedId(); // -2
			parent.generateCompressedId(); // -3
			parent.generateCompressedId(); // -4
			parent.generateCompressedId(); // -5

			// Shard into 3 (stride=3)
			// Distribution after sharding:
			//   - Cycle 0 (genCounts 1-3): all filled
			//   - Cycle 1 (genCounts 4-6): slots 4,5 filled, slot 6 empty
			// After sharding:
			//   - Parent (offset=0) owns: 1, 4, 7, ... (has generated 2: genCounts 1,4)
			//   - Child1 (offset=1) owns: 2, 5, 8, ... (has generated 2: genCounts 2,5)
			//   - Child2 (offset=2) owns: 3, 6, 9, ... (has generated 1: genCount 3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Verify localGenCount
			const parentShardId = parent.shardId();
			const child1ShardId = child1.shardId();
			const child2ShardId = child2.shardId();

			assert(parentShardId !== undefined);
			assert(child1ShardId !== undefined);
			assert(child2ShardId !== undefined);

			assert.equal(parentShardId.strideFillCount, 2); // Completed 1 cycle + 1 in partial
			assert.equal(child1ShardId.strideFillCount, 2); // Completed 1 cycle + 1 in partial
			assert.equal(child2ShardId.strideFillCount, 1); // Completed 1 cycle + 0 in partial

			// Generate next IDs
			const parentNext = parent.generateCompressedId();
			const child1Next = child1.generateCompressedId();
			const child2Next = child2.generateCompressedId();

			assert.equal(parentNext, -7); // genCount 7
			assert.equal(child1Next, -8); // genCount 8
			assert.equal(child2Next, -6); // genCount 6 (filling the empty slot)
		});

		it("generates IDs with stride pattern", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 shards (stride = 3)
			const [serializedChild1, serializedChild2] = parent.shard(2);

			const child1 = IdCompressor.deserialize({
				serialized: serializedChild1,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: serializedChild2,
				writeVersion: SerializationVersion.V3,
			});

			// Parent (offset=0): should generate -1, -4, -7, ...
			const parentId1 = parent.generateCompressedId();
			assert.equal(parentId1, -1);
			const parentId2 = parent.generateCompressedId();
			assert.equal(parentId2, -4);

			// Child 1 (offset=1): should generate -2, -5, -8, ...
			const child1Id1 = child1.generateCompressedId();
			assert.equal(child1Id1, -2);
			const child1Id2 = child1.generateCompressedId();
			assert.equal(child1Id2, -5);

			// Child 2 (offset=2): should generate -3, -6, -9, ...
			const child2Id1 = child2.generateCompressedId();
			assert.equal(child2Id1, -3);
			const child2Id2 = child2.generateCompressedId();
			assert.equal(child2Id2, -6);
		});

		it("no eager finals during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate and finalize some IDs to create a cluster
			parent.generateCompressedId();
			parent.generateCompressedId();
			const range = parent.takeNextCreationRange();
			parent.finalizeCreationRange(range);

			// Now parent has a cluster with capacity, normally would generate eager finals
			// But after sharding, should only generate local IDs
			parent.shard(1);

			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			// All should be local IDs despite cluster availability
			assert(isLocalId(id1));
			assert(isLocalId(id2));
			assert(isLocalId(id3));
		});

		it("shards cannot decompress IDs beyond their generation count", () => {
			// When a shard generates an ID, it "backfills" the entire cycle containing that ID.
			// A cycle is a group of consecutive genCounts equal to the stride size.
			// For stride=3: cycle 0 = [1,2,3], cycle 1 = [4,5,6], cycle 2 = [7,8,9], etc.
			// Shards can only decompress IDs within cycles they have backfilled.

			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 child shards (stride = 3 total)
			// Parent: offset=0, generates genCounts 1, 4, 7, ...
			// Child1: offset=1, generates genCounts 2, 5, 8, ...
			const [serializedChild1] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: serializedChild1,
				writeVersion: SerializationVersion.V3,
			});

			// Parent generates 2 IDs, backfilling cycles 0 and 1
			const parentId1 = parent.generateCompressedId(); // genCount 1, backfills cycle 0
			const parentId2 = parent.generateCompressedId(); // genCount 4, backfills cycle 1
			assert.equal(parentId1, -1);
			assert.equal(parentId2, -4);

			// Child1 generates 1 ID, backfilling only cycle 0
			const child1Id1 = child1.generateCompressedId(); // genCount 2, backfills cycle 0
			assert.equal(child1Id1, -2);

			// Each shard can decompress its own IDs
			assert(parent.decompress(parentId1) !== undefined);
			assert(parent.decompress(parentId2) !== undefined);
			assert(child1.decompress(child1Id1) !== undefined);

			// Child1 can decompress parent's ID from cycle 0 (both backfilled it)
			assert(child1.decompress(parentId1) !== undefined);

			// Child1 cannot decompress parent's ID from cycle 1 (child1 never backfilled it)
			assert.throws(() => child1.decompress(parentId2), /Unknown ID/);

			// Neither shard can decompress IDs from cycles they haven't backfilled
			assert.throws(() => parent.decompress(-7 as SessionSpaceCompressedId), /Unknown ID/); // cycle 2
			assert.throws(() => child1.decompress(-5 as SessionSpaceCompressedId), /Unknown ID/); // cycle 1
		});
	});

	describe("Unsharding", () => {
		it("can unshard and resume normal operation", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				writeVersion: SerializationVersion.V3,
			});

			// Generate IDs in child
			child.generateCompressedId(); // -2
			child.generateCompressedId(); // -4

			const childShardId = child.shardId();
			assert(childShardId !== undefined);
			assert.equal(childShardId.strideFillCount, 2);

			// Unshard
			parent.unshard(childShardId);

			// Parent should now exit sharding mode
			assert.equal(parent.shardId(), undefined);

			// Next ID should be -5 (continuing from where shards left off)
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -5);
		});

		it("resumes eager final ID allocation after unsharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate and finalize IDs to create a cluster with capacity
			for (let i = 0; i < 3; i++) {
				parent.generateCompressedId();
			}
			const range = parent.takeNextCreationRange();
			parent.finalizeCreationRange(range);

			// At this point, cluster has capacity for more IDs (default is 512)
			// Normally would generate eager finals, but after sharding, should use locals
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				writeVersion: SerializationVersion.V3,
			});

			// During sharding, both generate local IDs despite cluster capacity
			const id1 = parent.generateCompressedId();
			const id2 = child.generateCompressedId();
			assert(isLocalId(id1));
			assert(isLocalId(id2));

			// Unshard
			const childShardId = child.shardId();
			assert(childShardId !== undefined);
			parent.unshard(childShardId);

			// After unsharding, eager finals should resume since cluster has capacity
			const id3 = parent.generateCompressedId();
			assert(isFinalId(id3), "Should resume generating eager final IDs after unsharding");
		});

		it("merges normalizer state correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards (stride=2)
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				writeVersion: SerializationVersion.V3,
			});

			// Parent generates -1, child generates -2
			parent.generateCompressedId(); // -1
			child.generateCompressedId(); // -2

			// Get child's shard ID
			const childShardId = child.shardId();
			assert(childShardId !== undefined);

			// Unshard child
			parent.unshard(childShardId);

			// Parent should now know about both IDs
			// This is tested implicitly by decompress working
			const uuid1 = parent.decompress(-1 as SessionSpaceCompressedId);
			const uuid2 = parent.decompress(-2 as SessionSpaceCompressedId);

			assert(uuid1 !== undefined);
			assert(uuid2 !== undefined);
			assert(uuid1 !== uuid2);
		});

		it("handles empty shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shard
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				writeVersion: SerializationVersion.V3,
			});

			// Don't generate any IDs in child
			const childShardId = child.shardId();
			assert(childShardId !== undefined);
			assert.equal(childShardId.strideFillCount, 0);

			// Unshard empty child
			parent.unshard(childShardId);

			// Should still work
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -1);
		});

		it("handles unsharding in any order", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 3 shards
			const [s1, s2, s3] = parent.shard(3);
			const child1 = IdCompressor.deserialize({
				serialized: s1,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: s2,
				writeVersion: SerializationVersion.V3,
			});
			const child3 = IdCompressor.deserialize({
				serialized: s3,
				writeVersion: SerializationVersion.V3,
			});

			// Generate IDs
			child1.generateCompressedId();
			child2.generateCompressedId();
			child2.generateCompressedId();
			child3.generateCompressedId();
			child3.generateCompressedId();
			child3.generateCompressedId();

			// Unshard in reverse order
			const child3ShardId = child3.shardId();
			const child1ShardId = child1.shardId();
			const child2ShardId = child2.shardId();
			assert(child3ShardId !== undefined);
			assert(child1ShardId !== undefined);
			assert(child2ShardId !== undefined);
			parent.unshard(child3ShardId);
			parent.unshard(child1ShardId);
			parent.unshard(child2ShardId);

			// Should have exited sharding mode
			assert.equal(parent.shardId(), undefined);

			// localGenCount should be max of all shards: 3*4 = 12
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -13);
		});
	});

	describe("Recursive Sharding", () => {
		it("supports recursive sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// First shard: create 2 children (stride=3)
			const [child1Ser] = parent.shard(2);

			// Parent now has stride=3, offset=0
			const parentId1 = parent.generateCompressedId();
			assert.equal(parentId1, -1);

			// Second shard on parent: create 1 more child (stride=6)
			const [child3Ser] = parent.shard(1);

			// Child3 has stride=6, offset=3
			const child3 = IdCompressor.deserialize({
				serialized: child3Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child3Id = child3.generateCompressedId();
			assert.equal(child3Id, -4); // First in stride=6, offset=3 sequence

			// Child1 still has stride=3, offset=1 (unaffected by second shard)
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child1Id = child1.generateCompressedId();
			assert.equal(child1Id, -2); // First in stride=3, offset=1 sequence

			// Parent now has stride=6, offset=0
			const parentId2 = parent.generateCompressedId();
			assert.equal(parentId2, -7); // Next in stride=6 sequence from -1
		});

		it("handles complex multi-level sharding and unsharding", () => {
			const sessionId = createSessionId();
			const root = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Level 1: Root shards into 2 children (stride=3)
			const [child1Ser, child2Ser] = root.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Root (offset=0): generates -1
			const rootId1 = root.generateCompressedId();
			assert.equal(rootId1, -1);

			// Child1 (offset=1): generates -2
			const child1Id1 = child1.generateCompressedId();
			assert.equal(child1Id1, -2);

			// Level 2: Child1 recursively shards into 2 grandchildren (stride=6)
			const [grandchild1Ser, grandchild2Ser] = child1.shard(2);
			const grandchild1 = IdCompressor.deserialize({
				serialized: grandchild1Ser,
				writeVersion: SerializationVersion.V3,
			});
			const grandchild2 = IdCompressor.deserialize({
				serialized: grandchild2Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Grandchild1 (offset=4): generates -5
			const gc1Id = grandchild1.generateCompressedId();
			assert.equal(gc1Id, -5);

			// Grandchild2 (offset=7): generates -8
			const gc2Id = grandchild2.generateCompressedId();
			assert.equal(gc2Id, -8);

			// Child2 (offset=2): generates -3
			const child2Id1 = child2.generateCompressedId();
			assert.equal(child2Id1, -3);

			// Begin unsharding: Unshard grandchildren back into child1
			const gc1ShardId = grandchild1.shardId();
			const gc2ShardId = grandchild2.shardId();
			assert(gc1ShardId !== undefined);
			assert(gc2ShardId !== undefined);
			child1.unshard(gc1ShardId);
			child1.unshard(gc2ShardId);

			// Child1 exits sharding mode and resumes normal sequential generation
			const child1ShardIdAfter = child1.shardId();
			assert.equal(
				child1ShardIdAfter,
				undefined,
				"Child1 should exit sharding mode after unsharding all children",
			);

			// Child1 now generates sequentially from where it left off
			// After unsharding, it continues from highest genCount across all shards
			const child1Id2 = child1.generateCompressedId();
			assert.equal(child1Id2, -10);

			// Child2 is still in sharding mode from root
			const child2ShardId = child2.shardId();
			assert(child2ShardId !== undefined);

			// Root is still in sharding mode because it has active child count = 2
			// (it doesn't know that child1 exited sharding mode independently)
			const rootShardIdBefore = root.shardId();
			assert(rootShardIdBefore !== undefined);

			// Generate some more IDs to verify behavior
			const child2Id2 = child2.generateCompressedId();
			assert.equal(child2Id2, -6); // Child2's second ID in stride=3
		});
	});

	describe("Serialization", () => {
		it("serializes and deserializes sharding state", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			parent.shard(2);

			// Generate some IDs
			parent.generateCompressedId();
			parent.generateCompressedId();

			// Serialize
			const serialized = parent.serialize(true);

			// Deserialize
			const restored = IdCompressor.deserialize({
				serialized,
				writeVersion: SerializationVersion.V3,
			});

			// Verify sharding state preserved
			const restoredShardId = restored.shardId();
			assert(restoredShardId !== undefined);
			assert.equal(restoredShardId.shardId, 0);
			assert.equal(restoredShardId.strideFillCount, 2);

			// Verify can continue generating with correct stride
			const nextId = restored.generateCompressedId();
			assert.equal(nextId, -7); // stride=3, third ID for offset=0
		});

		it("handles version 2 documents without sharding state", () => {
			const sessionId = createSessionId();
			// Create a version 2 document (no sharding support)
			const compressor = new IdCompressor(sessionId, undefined, SerializationVersion.V2);

			// Generate some IDs
			compressor.generateCompressedId();
			compressor.generateCompressedId();

			// Serialize as version 2 (no sharding state)
			const serialized = compressor.serialize(true);

			// Deserialize - should work fine even though deserialization code supports V3
			const restored = IdCompressor.deserialize({
				serialized,
				writeVersion: SerializationVersion.V2,
			});

			// Calling shardId() on V2 document should throw
			assert.throws(() => {
				restored.shardId();
			}, /Sharding requires document version 3 or higher/);

			// Should work normally
			const id = restored.generateCompressedId();
			assert.equal(id, -3);
		});

		it("serializes and deserializes recursive sharding state", () => {
			const sessionId = createSessionId();
			const root = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Root shards into 2 children
			const [child1Ser] = root.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Child1 recursively shards into 2 grandchildren
			const [grandchild1Ser] = child1.shard(2);
			const grandchild1 = IdCompressor.deserialize({
				serialized: grandchild1Ser,
				writeVersion: SerializationVersion.V3,
			});

			// Generate IDs at each level
			root.generateCompressedId(); // -1
			child1.generateCompressedId(); // -5
			grandchild1.generateCompressedId(); // -9

			// Serialize each compressor
			const rootSerialized = root.serialize(true);
			const child1Serialized = child1.serialize(true);
			const grandchild1Serialized = grandchild1.serialize(true);

			// Deserialize and verify sharding state is preserved
			const rootRestored = IdCompressor.deserialize({
				serialized: rootSerialized,
				writeVersion: SerializationVersion.V3,
			});
			const child1Restored = IdCompressor.deserialize({
				serialized: child1Serialized,
				writeVersion: SerializationVersion.V3,
			});
			const grandchild1Restored = IdCompressor.deserialize({
				serialized: grandchild1Serialized,
				writeVersion: SerializationVersion.V3,
			});

			// Verify shard IDs are correct after deserialization
			const rootShardId = rootRestored.shardId();
			const child1ShardId = child1Restored.shardId();
			const grandchild1ShardId = grandchild1Restored.shardId();

			assert(rootShardId !== undefined);
			assert(child1ShardId !== undefined);
			assert(grandchild1ShardId !== undefined);

			assert.equal(rootShardId.shardId, 0); // offset 0 in root's stride
			assert.equal(child1ShardId.shardId, 1); // offset 1 from root's sharding
			assert.equal(grandchild1ShardId.shardId, 4); // offset 4 in combined stride pattern

			// Verify they continue generating IDs correctly after deserialization
			const rootNext = rootRestored.generateCompressedId();
			const child1Next = child1Restored.generateCompressedId();
			const grandchild1Next = grandchild1Restored.generateCompressedId();

			assert.equal(rootNext, -4); // Next in stride for root
			assert.equal(child1Next, -11); // Next in stride for child1
			assert.equal(grandchild1Next, -14); // Next in stride for grandchild1
		});
	});
});
