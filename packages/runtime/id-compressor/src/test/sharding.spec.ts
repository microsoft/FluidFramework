/*!
 * Copyright (c) Microsoft Corporation and contributors. All rights reserved.
 * Licensed under the MIT License.
 */

import { strict as assert } from "node:assert";

import { IdCompressor } from "../idCompressor.js";
import { isFinalId } from "../identifiers.js";
import type { SessionSpaceCompressedId } from "../index.js";
import { SerializationVersion } from "../types/index.js";
import { createSessionId } from "../utilities.js";

import { isLocalId } from "./testCommon.js";

describe("IdCompressor Sharding", () => {
	describe("Basic Sharding", () => {
		it("can create shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate some IDs before sharding
			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			assert(isLocalId(id1));
			assert(isLocalId(id2));
			assert(isLocalId(id3));

			// Create 2 shards (parent + 2 children = 3 total)
			const shards = parent.shard(2);
			assert.equal(shards.length, 2);

			// Verify parent can still generate IDs (is in sharding mode)
			const id4 = parent.generateCompressedId();
			assert(isLocalId(id4));
		});

		it("children recognize parent's pre-shard IDs", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 3 IDs before sharding (genCounts 1, 2, 3 → IDs -1, -2, -3)
			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			assert.equal(id1, -1);
			assert.equal(id2, -2);
			assert.equal(id3, -3);

			// Get UUIDs for these IDs from parent
			const uuid1 = parent.decompress(id1);
			const uuid2 = parent.decompress(id2);
			const uuid3 = parent.decompress(id3);

			// Shard into 3 (stride=3, consecutive positioning: parent at 3, child1 at 4, child2 at 5)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Children should be able to decompress parent's pre-shard IDs
			// They share the same session and are forks of the parent
			assert.equal(child1.decompress(id1), uuid1);
			assert.equal(child1.decompress(id2), uuid2);
			assert.equal(child1.decompress(id3), uuid3);

			assert.equal(child2.decompress(id1), uuid1);
			assert.equal(child2.decompress(id2), uuid2);
			assert.equal(child2.decompress(id3), uuid3);

			// Parent should still be able to decompress
			assert.equal(parent.decompress(id1), uuid1);
			assert.equal(parent.decompress(id2), uuid2);
			assert.equal(parent.decompress(id3), uuid3);
		});

		it("shards do not recognize IDs generated after sharding in other shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 shards (stride=3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Child1 generates an ID (-4, genCount 4)
			// With consecutive positioning: child1 starts at localGenCount=1, adds stride=3
			const child1Id = child1.generateCompressedId();
			assert.equal(child1Id, -4);

			// Child2 should NOT be able to decompress child1's ID
			// because it was generated after the shard point and child2 hasn't
			// received the information about child1's new ID yet
			assert.throws(() => {
				child2.decompress(child1Id);
			}, "Child2 should not recognize Child1's post-shard ID");

			// Parent also cannot decompress it yet, as the ID was generated by a shard
			// The parent would need to receive this information through the document
			assert.throws(() => {
				parent.decompress(child1Id);
			}, "Parent should not recognize Child1's post-shard ID until it receives that information");
		});

		it("sharding with pre-existing IDs follows stride pattern correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 3 IDs before sharding (genCounts 1,2,3 occupy first cycle)
			assert.equal(parent.generateCompressedId(), -1);
			assert.equal(parent.generateCompressedId(), -2);
			assert.equal(parent.generateCompressedId(), -3);

			// Shard into 3 (stride=3)
			// With consecutive positioning after sharding:
			//   - Parent: localGenCount=3, next generates at 6, 9, 12, ...
			//   - Child1: localGenCount=4, next generates at 7, 10, 13, ...
			//   - Child2: localGenCount=5, next generates at 8, 11, 14, ...
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify starting state by checking the IDs they generate
			// If localGenCount was inherited correctly, they should generate the right sequence

			// Now generate next IDs - each adds stride to current localGenCount
			const parentNext = parent.generateCompressedId();
			const child1Next = child1.generateCompressedId();
			const child2Next = child2.generateCompressedId();

			assert.equal(parentNext, -6); // Parent: 3+3=6
			assert.equal(child1Next, -7); // Child1: 4+3=7
			assert.equal(child2Next, -8); // Child2: 5+3=8
		});

		it("sharding with partial cycle follows stride pattern correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 5 IDs before sharding (completes 1 cycle, half-fills second)
			assert.equal(parent.generateCompressedId(), -1);
			assert.equal(parent.generateCompressedId(), -2);
			assert.equal(parent.generateCompressedId(), -3);
			assert.equal(parent.generateCompressedId(), -4);
			assert.equal(parent.generateCompressedId(), -5);

			// Shard into 3 (stride=3)
			// With consecutive positioning after sharding (parent at localGenCount=5):
			//   - Parent: localGenCount=5, next generates at 8, 11, 14, ...
			//   - Child1: localGenCount=6, next generates at 9, 12, 15, ...
			//   - Child2: localGenCount=7, next generates at 10, 13, 16, ...
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify state by checking the IDs they generate
			// The stride pattern should handle the partial cycle correctly

			// Generate next IDs - each jumps to next in its stride after localGenCount=5
			const parentNext = parent.generateCompressedId();
			const child1Next = child1.generateCompressedId();
			const child2Next = child2.generateCompressedId();

			assert.equal(parentNext, -8); // 5+3=8
			assert.equal(child1Next, -9); // 6+3=9
			assert.equal(child2Next, -10); // 7+3=10
		});

		it("generates IDs with stride pattern", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 shards (stride = 3)
			const [serializedChild1, serializedChild2] = parent.shard(2);

			const child1 = IdCompressor.deserialize({
				serialized: serializedChild1,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: serializedChild2,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent: starts at localGenCount=0, generates at 3, 6, 9, ...
			const parentId1 = parent.generateCompressedId();
			assert.equal(parentId1, -3);
			const parentId2 = parent.generateCompressedId();
			assert.equal(parentId2, -6);

			// Child1: starts at localGenCount=1, generates at 4, 7, 10, ...
			const child1Id1 = child1.generateCompressedId();
			assert.equal(child1Id1, -4);
			const child1Id2 = child1.generateCompressedId();
			assert.equal(child1Id2, -7);

			// Child2: starts at localGenCount=2, generates at 5, 8, 11, ...
			const child2Id1 = child2.generateCompressedId();
			assert.equal(child2Id1, -5);
			const child2Id2 = child2.generateCompressedId();
			assert.equal(child2Id2, -8);
		});

		it("no eager finals during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate and finalize some IDs to create a cluster
			parent.generateCompressedId();
			parent.generateCompressedId();
			const range = parent.takeNextCreationRange();
			parent.finalizeCreationRange(range);

			// Now parent has a cluster with capacity, normally would generate eager finals
			// But after sharding, should only generate local IDs
			parent.shard(1);

			const id1 = parent.generateCompressedId();
			const id2 = parent.generateCompressedId();
			const id3 = parent.generateCompressedId();

			// All should be local IDs despite cluster availability
			assert(isLocalId(id1));
			assert(isLocalId(id2));
			assert(isLocalId(id3));
		});

		it("shards cannot decompress IDs beyond their generation count", () => {
			// When a shard generates an ID, it "backfills" the entire cycle containing that ID.
			// A cycle is a group of consecutive genCounts equal to the stride size.
			// With consecutive positioning:
			// - Parent starts at localGenCount=0, children at 1, 2, etc.
			// - Each shard adds stride when generating
			// - Backfilling happens up to the cycle end containing the generated ID
			// For stride=3: cycle ending at 3 = [1,2,3], cycle ending at 6 = [4,5,6], etc.
			// Shards can only decompress IDs within genCounts they have backfilled.

			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 2 child shards (stride = 3 total)
			// Parent: starts at localGenCount=0, generates at 3, 6, 9, ...
			// Child1: starts at localGenCount=1, generates at 4, 7, 10, ...
			const [serializedChild1] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: serializedChild1,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent generates 2 IDs
			const parentId1 = parent.generateCompressedId(); // localGenCount 0→3, ID=-3, backfills up to 3
			const parentId2 = parent.generateCompressedId(); // localGenCount 3→6, ID=-6, backfills up to 6
			assert.equal(parentId1, -3);
			assert.equal(parentId2, -6);

			// Child1 generates 1 ID
			const child1Id1 = child1.generateCompressedId(); // localGenCount 1→4, ID=-4, backfills up to 4
			assert.equal(child1Id1, -4);

			// Each shard can decompress its own IDs
			assert(parent.decompress(parentId1) !== undefined);
			assert(parent.decompress(parentId2) !== undefined);
			assert(child1.decompress(child1Id1) !== undefined);

			// Child1 CAN decompress parent's IDs if they're within child1's backfilled range
			// When child1 generates an ID at genCount 4, it backfills [2,3,4]
			// parentId1 is at genCount 3, so child1 can decompress it
			assert(child1.decompress(parentId1) !== undefined);
			// parentId2 is at genCount 6, beyond child1's backfilled range, so it cannot decompress it
			assert.throws(() => child1.decompress(parentId2));

			// Parent generates a 3rd ID to advance beyond child1's backfilled range
			const parentId3 = parent.generateCompressedId(); // localGenCount 6→9, ID=-9, backfills up to 9
			assert.equal(parentId3, -9);

			// Parent can decompress its own new ID
			assert(parent.decompress(parentId3) !== undefined);

			// Child1 cannot decompress parent's ID at genCount 9 (child1 only backfilled up to 6)
			assert.throws(() => child1.decompress(parentId3), /Unknown ID/);

			// Neither shard can decompress IDs from genCounts they haven't backfilled
			assert.throws(() => parent.decompress(-12 as SessionSpaceCompressedId), /Unknown ID/); // Beyond parent's genCount 9
			assert.throws(() => child1.decompress(-7 as SessionSpaceCompressedId), /Unknown ID/); // Beyond child1's genCount 4
		});
	});

	describe("Unsharding", () => {
		it("can unshard and resume normal operation", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs in child (with consecutive positioning, child starts at 1)
			assert.equal(child.generateCompressedId(), -3); // 1→3
			assert.equal(child.generateCompressedId(), -5); // 3→5

			// Dispose child and get its shard ID for unsharding
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			// Child's localGenCount = 5 (generated 3 then 5)
			assert.equal(childShardId.localGenCount, 5);

			// Unshard
			parent.unshard(childShardId);

			// Child should now be disposed and unusable
			assert.throws(() => {
				child.generateCompressedId();
			}, /disposed/);

			// Parent should now exit sharding mode (has no more active children)
			// We can verify this by checking it generates sequential IDs again

			// After realignment to 6 and exiting sharding, generates sequential -7
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -7);
		});

		it("resumes eager final ID allocation after unsharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate and finalize IDs to create a cluster with capacity
			for (let i = 0; i < 3; i++) {
				parent.generateCompressedId();
			}
			const range = parent.takeNextCreationRange();
			parent.finalizeCreationRange(range);

			// At this point, cluster has capacity for more IDs (default is 512)
			// Normally would generate eager finals, but after sharding, should use locals
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// During sharding, both generate local IDs despite cluster capacity
			const id1 = parent.generateCompressedId();
			const id2 = child.generateCompressedId();
			assert(isLocalId(id1));
			assert(isLocalId(id2));

			// Dispose and unshard
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			parent.unshard(childShardId);

			// After unsharding, eager finals should resume since cluster has capacity
			const id3 = parent.generateCompressedId();
			assert(isFinalId(id3), "Should resume generating eager final IDs after unsharding");
		});

		it("merges normalizer state correctly", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards (stride=2)
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent at 0, child at 1, stride=2
			assert.equal(parent.generateCompressedId(), -2); // 0→2
			assert.equal(child.generateCompressedId(), -3); // 1→3

			// Dispose child and get its shard ID
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);

			// Unshard child
			parent.unshard(childShardId);

			// Parent should now know about both IDs
			// This is tested implicitly by decompress working
			const uuid1 = parent.decompress(-1 as SessionSpaceCompressedId);
			const uuid2 = parent.decompress(-2 as SessionSpaceCompressedId);

			assert(uuid1 !== undefined);
			assert(uuid2 !== undefined);
			assert(uuid1 !== uuid2);
		});

		it("handles empty shards", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shard
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Don't generate any IDs in child

			// Dispose empty child
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			assert.equal(childShardId.localGenCount, 1);

			// Unshard empty child
			parent.unshard(childShardId);

			// After realignment and exiting sharding mode
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -3);
		});

		it("handles unsharding in any order", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create 3 shards
			const [s1, s2, s3] = parent.shard(3);
			const child1 = IdCompressor.deserialize({
				serialized: s1,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: s2,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child3 = IdCompressor.deserialize({
				serialized: s3,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs
			child1.generateCompressedId();
			child2.generateCompressedId();
			child2.generateCompressedId();
			child3.generateCompressedId();
			child3.generateCompressedId();
			child3.generateCompressedId();

			// Dispose and unshard in reverse order
			const child3ShardId = child3.disposeShard();
			const child1ShardId = child1.disposeShard();
			const child2ShardId = child2.disposeShard();
			assert(child3ShardId !== undefined);
			assert(child1ShardId !== undefined);
			assert(child2ShardId !== undefined);
			parent.unshard(child3ShardId);
			parent.unshard(child1ShardId);
			parent.unshard(child2ShardId);

			// Should have exited sharding mode (verify by generating sequential ID)
			// After all children unsharded, parent should generate sequentially

			// localGenCount should be max of all shards: 3*4 = 12
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -17);
		});
	});

	describe("Recursive Sharding", () => {
		it("supports recursive sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// First shard: create 2 children (stride=3)
			// Parent at localGenCount=0, children at 1, 2
			const [child1Ser] = parent.shard(2);

			// Parent generates: 0→3
			const parentId1 = parent.generateCompressedId();
			assert.equal(parentId1, -3);

			// Second shard on parent: create 1 more child (stride becomes 6)
			// Parent at localGenCount=3, new child (child3) at 4
			const [child3Ser] = parent.shard(1);

			// Child3 generates: 4→10 (adds stride 6)
			const child3 = IdCompressor.deserialize({
				serialized: child3Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child3Id = child3.generateCompressedId();
			assert.equal(child3Id, -10);

			// Child1 still has original stride=3, starts at localGenCount=1
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child1Id = child1.generateCompressedId();
			assert.equal(child1Id, -4); // 1→4 (adds stride 3)

			// Parent now has stride=6, generates: 3→9
			const parentId2 = parent.generateCompressedId();
			assert.equal(parentId2, -9);
		});

		it("handles complex multi-level sharding and unsharding", () => {
			const sessionId = createSessionId();
			const root = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Level 1: Root shards into 2 children (stride=3)
			// Root at 0, child1 at 1, child2 at 2
			const [child1Ser, child2Ser] = root.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Root generates: 0→3
			const rootId1 = root.generateCompressedId();
			assert.equal(rootId1, -3);

			// Child1 generates: 1→4
			const child1Id1 = child1.generateCompressedId();
			assert.equal(child1Id1, -4);

			// Level 2: Child1 recursively shards into 2 grandchildren (stride becomes 6)
			// Child1 at 4, grandchild1 at 5, grandchild2 at 6
			const [grandchild1Ser, grandchild2Ser] = child1.shard(2);
			const grandchild1 = IdCompressor.deserialize({
				serialized: grandchild1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const grandchild2 = IdCompressor.deserialize({
				serialized: grandchild2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Grandchild1 generates: 5→14 (adds stride 9, which is grandchild's original stride)
			const gc1Id = grandchild1.generateCompressedId();
			assert.equal(gc1Id, -14);

			// Grandchild2 generates: 6→15 (adds stride 9)
			const gc2Id = grandchild2.generateCompressedId();
			assert.equal(gc2Id, -15);

			// Child2 generates: 2→5 (adds stride 3)
			const child2Id1 = child2.generateCompressedId();
			assert.equal(child2Id1, -5);

			// Begin unsharding: Dispose grandchildren and unshard them back into child1
			const gc1ShardId = grandchild1.disposeShard();
			const gc2ShardId = grandchild2.disposeShard();
			assert(gc1ShardId !== undefined);
			assert(gc2ShardId !== undefined);
			child1.unshard(gc1ShardId);
			child1.unshard(gc2ShardId);

			// Child1 exits recursive sharding mode and restores its original stride-3 pattern
			// After unsharding, it continues its stride-3 pattern (2, 5, 8, 11, ...)
			// The highest genCount generated was 8, so the next in the pattern is 11
			const child1Id2 = child1.generateCompressedId();
			assert.equal(child1Id2, -25);

			// Child2 is still a shard of root with stride-3 pattern (3, 6, 9, ...)
			// Root is still in sharding mode because it has active children (child1 and child2)

			// Generate some more IDs to verify behavior
			const child2Id2 = child2.generateCompressedId();
			assert.equal(child2Id2, -8); // Child2's second ID in stride=3

			// Verify: child2 should generate -9 next (stride pattern: 3, 6, 9, ...)
			const child2Id3 = child2.generateCompressedId();
			assert.equal(child2Id3, -11); // This would be a collision if child1 also generated -9!
		});
	});

	describe("Error Conditions", () => {
		it("throws when attempting to start a ghost session while sharded", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards to enter sharding mode
			parent.shard(1);

			// Attempt to start a ghost session should throw
			const ghostSessionId = createSessionId();
			assert.throws(() => {
				parent.beginGhostSession(ghostSessionId, () => {
					// This callback should never be reached
					parent.generateCompressedId();
				});
			}, /Cannot start a ghost session while sharded/);
		});

		it("throws when attempting to shard during a ghost session", () => {
			const sessionId = createSessionId();
			const compressor = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Start a ghost session
			const ghostSessionId = createSessionId();

			// Attempt to shard during ghost session should throw
			assert.throws(() => {
				compressor.beginGhostSession(ghostSessionId, () => {
					// Attempt to shard while ghost session is active
					compressor.shard(1);
				});
			}, /Cannot shard during ghost session/);
		});
	});

	describe("Serialization", () => {
		it("serializes and deserializes sharding state", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			parent.shard(2);

			// Generate some IDs
			parent.generateCompressedId();
			parent.generateCompressedId();

			// Serialize
			const serialized = parent.serialize(true);

			// Deserialize
			const restored = IdCompressor.deserialize({
				serialized,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify sharding state preserved by checking ID generation continues correctly

			// Verify can continue generating with correct stride
			const nextId = restored.generateCompressedId();
			assert.equal(nextId, -9); // Next in sequence {3,6,9,...} // Next in sequence {1,4,7,...}
		});

		it("handles version 2 documents without sharding state", () => {
			const sessionId = createSessionId();
			// Create a version 2 document (no sharding support)
			const compressor = new IdCompressor(sessionId, undefined, SerializationVersion.V2);

			// Generate some IDs
			compressor.generateCompressedId();
			compressor.generateCompressedId();

			// Serialize as version 2 (no sharding state)
			const serialized = compressor.serialize(true);

			// Deserialize - should work fine even though deserialization code supports V3
			const restored = IdCompressor.deserialize({
				serialized,
				requestedWriteVersion: SerializationVersion.V2,
			});

			// Calling disposeShard() on V2 document should throw
			assert.throws(() => {
				restored.disposeShard();
			}, /Sharding requires document version 3 or higher/);

			// Should work normally
			const id = restored.generateCompressedId();
			assert.equal(id, -3);
		});

		it("serializes and deserializes recursive sharding state", () => {
			const sessionId = createSessionId();
			const root = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Root shards into 2 children
			const [child1Ser] = root.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Child1 recursively shards into 2 grandchildren
			const [grandchild1Ser] = child1.shard(2);
			const grandchild1 = IdCompressor.deserialize({
				serialized: grandchild1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs at each level
			assert.equal(root.generateCompressedId(), -3); // Root: 0→3
			assert.equal(child1.generateCompressedId(), -10); // Child1: 1→10 (stride 9)
			assert.equal(grandchild1.generateCompressedId(), -11); // Grandchild1: 2→11 (stride 9)

			// Serialize each compressor
			const rootSerialized = root.serialize(true);
			const child1Serialized = child1.serialize(true);
			const grandchild1Serialized = grandchild1.serialize(true);

			// Deserialize and verify sharding state is preserved
			const rootRestored = IdCompressor.deserialize({
				serialized: rootSerialized,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child1Restored = IdCompressor.deserialize({
				serialized: child1Serialized,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const grandchild1Restored = IdCompressor.deserialize({
				serialized: grandchild1Serialized,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Verify sharding state is preserved after deserialization
			// by checking that they continue generating IDs correctly

			// Verify they continue generating IDs correctly after deserialization
			const rootNext = rootRestored.generateCompressedId();
			const child1Next = child1Restored.generateCompressedId();
			const grandchild1Next = grandchild1Restored.generateCompressedId();

			assert.equal(rootNext, -6);
			assert.equal(child1Next, -19);
			assert.equal(grandchild1Next, -20);
		});
	});

	describe("LocalGenCount Semantics", () => {
		it("localGenCount is not decremented during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate 5 IDs
			for (let i = 0; i < 5; i++) {
				parent.generateCompressedId();
			}

			// Shard into 3 (parent owns {1,4,7,...}, child1 owns {2,5,8,...}, child2 owns {3,6,9,...})
			parent.shard(2);

			// Can still decompress ID -5 - proves all previously generated IDs remain accessible
			assert.doesNotThrow(() => parent.decompress(-5 as SessionSpaceCompressedId));

			// takeNextCreationRange should include all 5 generated IDs
			const range = parent.takeNextCreationRange();
			assert(range.ids !== undefined);
			assert.equal(range.ids.count, 5, "Range should include all 5 generated IDs");

			// Next ID adds stride: parent at 5, adds stride 3 → 8
			const nextId = parent.generateCompressedId();
			assert.equal(nextId, -8, "Should jump to next genCount in stride sequence");
		});

		it("localGenCount increments by stride in sharded mode", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Shard immediately (stride=2, parent at 0, child at 1)
			const [childSer] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: childSer,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Parent generates IDs: 0→2, 2→4, 4→6
			const id1 = parent.generateCompressedId();
			assert.equal(id1, -2);
			const id2 = parent.generateCompressedId();
			assert.equal(id2, -4);
			const id3 = parent.generateCompressedId();
			assert.equal(id3, -6);

			// Child generates IDs: 1→3, 3→5
			const childId1 = child.generateCompressedId();
			assert.equal(childId1, -3);
			const childId2 = child.generateCompressedId();
			assert.equal(childId2, -5);

			// Verify localGenCount by disposing child and checking
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined);
			assert.equal(childShardId.localGenCount, 5, "Child localGenCount should be 4");
		});
	});

	describe("Creation Ranges", () => {
		it("takeNextCreationRange works correctly during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Generate some IDs before sharding
			assert.equal(parent.generateCompressedId(), -1);
			assert.equal(parent.generateCompressedId(), -2);
			assert.equal(parent.generateCompressedId(), -3);

			// Shard into 3 (stride=3)
			const [child1Ser, child2Ser] = parent.shard(2);
			const child1 = IdCompressor.deserialize({
				serialized: child1Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});
			const child2 = IdCompressor.deserialize({
				serialized: child2Ser,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate more IDs in each shard
			assert.equal(parent.generateCompressedId(), -6); // 3→6
			assert.equal(parent.generateCompressedId(), -9); // 6→9
			assert.equal(child1.generateCompressedId(), -7); // 4→7
			assert.equal(child1.generateCompressedId(), -10); // 7→10
			assert.equal(child2.generateCompressedId(), -8); // 5→8

			// Take ranges
			const parentRange = parent.takeNextCreationRange();
			const child1Range = child1.takeNextCreationRange();
			const child2Range = child2.takeNextCreationRange();

			// Verify parent range: localGenCount went from 3 to 9
			assert(parentRange.ids !== undefined);
			assert.equal(parentRange.ids.firstGenCount, 1);
			assert.equal(parentRange.ids.count, 9); // Range covers genCounts 1-9

			// Verify child1 range: localGenCount went from 4 to 10
			assert(child1Range.ids !== undefined);
			assert.equal(child1Range.ids.firstGenCount, 1);
			assert.equal(child1Range.ids.count, 10); // Range covers genCounts 1-10

			// Verify child2 range: localGenCount went from 5 to 8
			assert(child2Range.ids !== undefined);
			assert.equal(child2Range.ids.firstGenCount, 1);
			assert.equal(child2Range.ids.count, 8); // Range covers genCounts 1-8

			// Verify local ID ranges are correct (all IDs should be in normalizer)
			assert(parentRange.ids.localIdRanges.length > 0);
			assert(child1Range.ids.localIdRanges.length > 0);
			assert(child2Range.ids.localIdRanges.length > 0);
		});

		it("takeNextCreationRange after unsharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Create shards
			const [serializedChild] = parent.shard(1);
			const child = IdCompressor.deserialize({
				serialized: serializedChild,
				requestedWriteVersion: SerializationVersion.V3,
			});

			// Generate IDs (parent at 0, child at 1, stride=2)
			assert.equal(parent.generateCompressedId(), -2); // 0→2
			assert.equal(child.generateCompressedId(), -3); // 1→3
			assert.equal(parent.generateCompressedId(), -4); // 2→4
			assert.equal(child.generateCompressedId(), -5); // 3→5

			// Dispose and unshard
			const childShardId = child.disposeShard();
			assert(childShardId !== undefined, "child.disposeShard() returned undefined");
			parent.unshard(childShardId);

			// Take range after unsharding
			const range = parent.takeNextCreationRange();

			assert(range.ids !== undefined);
			assert.equal(range.ids.firstGenCount, 1);
			assert.equal(range.ids.count, 6);

			// Generate more IDs and take another range (stride back to 1 after unshard)
			assert.equal(parent.generateCompressedId(), -7); // After unshard: 6→7
			assert.equal(parent.generateCompressedId(), -8); // 7→8

			const range2 = parent.takeNextCreationRange();
			assert(range2.ids !== undefined);
			assert.equal(range2.ids.firstGenCount, 7);
			assert.equal(range2.ids.count, 2);
		});

		it("multiple takeNextCreationRange calls during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Shard (don't need to use the child for this test)
			parent.shard(1);

			// Generate and take first range (parent at 0, stride=2)
			assert.equal(parent.generateCompressedId(), -2); // 0→2
			assert.equal(parent.generateCompressedId(), -4); // 2→4
			const range1 = parent.takeNextCreationRange();

			assert(range1.ids !== undefined);
			assert.equal(range1.ids.firstGenCount, 1);
			assert.equal(range1.ids.count, 4);

			// Generate and take second range
			assert.equal(parent.generateCompressedId(), -6); // 4→6
			const range2 = parent.takeNextCreationRange();

			assert(range2.ids !== undefined);
			assert.equal(range2.ids.firstGenCount, 5);
			assert.equal(range2.ids.count, 2); // Range covers genCounts 5-6

			// Verify ranges are consecutive and non-overlapping
			assert.equal(range1.ids.firstGenCount + range1.ids.count, range2.ids.firstGenCount);
		});

		it("ranges can be finalized correctly during sharding", () => {
			const sessionId = createSessionId();
			const parent = new IdCompressor(sessionId, undefined, SerializationVersion.V3);

			// Shard
			parent.shard(1);

			// Generate IDs (parent at 0, stride=2)
			assert.equal(parent.generateCompressedId(), -2); // 0→2
			assert.equal(parent.generateCompressedId(), -4); // 2→4

			// Take and finalize range
			const range = parent.takeNextCreationRange();
			assert(range.ids !== undefined);

			// Should not throw
			parent.finalizeCreationRange(range);

			// After finalization, parent should still be in sharding mode (no eager finals)
			const nextId = parent.generateCompressedId(); // 4→6
			assert.equal(nextId, -6);
			assert(
				isLocalId(nextId),
				"Should still generate local IDs after finalization during sharding",
			);
		});
	});
});
