# Copyright (c) Microsoft Corporation and contributors. All rights reserved.
# Licensed under the MIT License.

# build-performance-observability pipeline
# This pipeline collects build metrics using ADO REST APIs and generates an HTML dashboard
# When run from the "public" project: collects PR build metrics
# When run from the "internal" project: collects post-merge build metrics

name: $(Build.BuildId)

# Schedule to run daily at 2 AM UTC
# schedules:
# - cron: "0 2 * * *"
#   displayName: Daily build metrics collection
#   branches:
#     include:
#     - main
#   always: true

trigger: none

pr: none

variables:
  # Contains keys to upload dashboard to ASWA
  - group: build-dashboard-vars
  # Number of recent builds to fetch
  - name: buildCount
    value: 500
  # Organization
  - name: organization
    value: fluidframework
  # Mode: public = PR builds, internal = post-merge builds
  - name: isPublicProject
    value: ${{ eq(variables['System.TeamProject'], 'public') }}
  # Build definition IDs
  - name: publicPRBuildDefinitionId
    value: 11
  - name: internalBuildDefinitionId
    value: 12
  # Project to query (same as where pipeline runs)
  - name: targetProject
    value: $(System.TeamProject)

resources:
  repositories:
  - repository: m365Pipelines
    type: git
    name: 1ESPipelineTemplates/M365GPT
    ref: refs/tags/release

extends:
  ${{ if eq(variables['System.TeamProject'], 'internal') }}:
    template: v1/M365.Official.PipelineTemplate.yml@m365Pipelines
  ${{ else }}:
    template: v1/M365.Unofficial.PipelineTemplate.yml@m365Pipelines
  parameters:
    customBuildTags:
    - ES365AIMigrationTooling
    pool:
      name: Small-eastus2
      os: linux
    sdl:
      sourceAnalysisPool:
        name: Azure-Pipelines-1ESPT-ExDShared
        image: windows-2022
        os: windows

    stages:
    - stage: collect_metrics
      displayName: Collect Build Metrics
      jobs:
      - job: fetch_and_publish
        displayName: Fetch and Publish Build Metrics
        steps:
        - checkout: self
          fetchDepth: 1
          path: repo

        - task: Bash@3
          displayName: Fetch build data
          env:
            ADO_API_TOKEN: $(System.AccessToken)
            PR_BUILD_DEF_ID: $(publicPRBuildDefinitionId)
            INTERNAL_BUILD_DEF_ID: $(internalBuildDefinitionId)
            BUILD_COUNT: $(buildCount)
            ORG: $(organization)
            PROJECT: $(targetProject)
            IS_PUBLIC: $(isPublicProject)
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail

              # Determine mode based on project
              if [ "$IS_PUBLIC" = "True" ]; then
                MODE="pr"
                BUILD_DEF_ID="$PR_BUILD_DEF_ID"
              else
                MODE="postmerge"
                BUILD_DEF_ID="$INTERNAL_BUILD_DEF_ID"
              fi

              echo "=========================================="
              echo "Fetching build metrics"
              echo "=========================================="
              echo "Mode: $MODE"
              echo "Organization: $ORG"
              echo "Project: $PROJECT"
              echo "Build Definition: $BUILD_DEF_ID"
              echo "Build Count: $BUILD_COUNT"
              echo ""

              # Create output directory
              mkdir -p $(Build.ArtifactStagingDirectory)/metrics

              # Save mode for subsequent tasks
              echo "$MODE" > $(Build.ArtifactStagingDirectory)/metrics/mode.txt

              if [ "$MODE" = "pr" ]; then
                # Fetch PR builds with reasonFilter and statusFilter
                echo "Fetching last $BUILD_COUNT PR builds (reason=pullRequest, succeeded/partiallySucceeded, completed)..."

                curl -u ":$ADO_API_TOKEN" \
                  "https://dev.azure.com/$ORG/$PROJECT/_apis/build/builds?definitions=$BUILD_DEF_ID&reasonFilter=pullRequest&resultFilter=succeeded,partiallySucceeded&statusFilter=completed&\$top=$BUILD_COUNT&api-version=7.1" \
                  -o $(Build.ArtifactStagingDirectory)/metrics/builds-raw.json
              else
                # Fetch post-merge builds from main branch
                echo "Fetching last $BUILD_COUNT post-merge builds (branch=main, succeeded/partiallySucceeded, completed)..."

                curl -u ":$ADO_API_TOKEN" \
                  "https://dev.azure.com/$ORG/$PROJECT/_apis/build/builds?definitions=$BUILD_DEF_ID&branchName=refs/heads/main&resultFilter=succeeded,partiallySucceeded&statusFilter=completed&\$top=$BUILD_COUNT&api-version=7.1" \
                  -o $(Build.ArtifactStagingDirectory)/metrics/builds-raw.json
              fi

              echo "Build data fetched successfully!"

        - task: Bash@3
          displayName: Filter builds (PR mode only)
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail

              MODE=$(cat $(Build.ArtifactStagingDirectory)/metrics/mode.txt)

              if [ "$MODE" = "pr" ]; then
                echo "=========================================="
                echo "Filtering PR builds by target branch (main)"
                echo "=========================================="

                # Filter PR builds to only include those targeting main branch
                # The target branch is in the parameters field as JSON string: "system.pullRequest.targetBranch"

                cat $(Build.ArtifactStagingDirectory)/metrics/builds-raw.json | jq '
                  .value |= map(select(
                    .parameters != null and
                    (.parameters | fromjson | .["system.pullRequest.targetBranch"] == "main")
                  ))
                ' > $(Build.ArtifactStagingDirectory)/metrics/builds.json

                TOTAL_AFTER=$(cat $(Build.ArtifactStagingDirectory)/metrics/builds.json | jq '.value | length')
                echo "Filtered to $TOTAL_AFTER PR builds targeting main branch"
              else
                echo "=========================================="
                echo "Post-merge mode - no filtering needed"
                echo "=========================================="

                # Just copy the raw file to builds.json
                cp $(Build.ArtifactStagingDirectory)/metrics/builds-raw.json $(Build.ArtifactStagingDirectory)/metrics/builds.json

                TOTAL=$(cat $(Build.ArtifactStagingDirectory)/metrics/builds.json | jq '.value | length')
                echo "Total post-merge builds: $TOTAL"
              fi

        - task: Bash@3
          displayName: Fetch timeline data for builds
          env:
            ADO_API_TOKEN: $(System.AccessToken)
            ORG: $(organization)
            PROJECT: $(targetProject)
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail

              MODE=$(cat $(Build.ArtifactStagingDirectory)/metrics/mode.txt)

              echo "=========================================="
              echo "Fetching timeline data for builds ($MODE mode)"
              echo "=========================================="

              # Extract build IDs from filtered builds
              BUILD_IDS=$(cat $(Build.ArtifactStagingDirectory)/metrics/builds.json | jq -r '.value[] | .id')

              TOTAL_COUNT=$(echo "$BUILD_IDS" | wc -l | tr -d ' ')
              echo "Found $TOTAL_COUNT builds to fetch timeline data for"
              echo ""

              mkdir -p $(Build.ArtifactStagingDirectory)/metrics/timelines

              # Fetch in parallel using background jobs (20 at a time to avoid overwhelming the API)
              PARALLEL_JOBS=20
              count=0

              fetch_timeline() {
                local build_id=$1
                local output_file=$2
                curl -s -u ":$ADO_API_TOKEN" \
                  "https://dev.azure.com/$ORG/$PROJECT/_apis/build/builds/$build_id/timeline?api-version=7.1-preview.2" \
                  -o "$output_file" 2>/dev/null
              }

              for BUILD_ID in $BUILD_IDS; do
                count=$((count + 1))

                # Start background job
                fetch_timeline "$BUILD_ID" "$(Build.ArtifactStagingDirectory)/metrics/timelines/timeline_$BUILD_ID.json" &

                # Limit concurrent jobs
                if (( count % PARALLEL_JOBS == 0 )); then
                  wait  # Wait for current batch to complete
                  echo "[$count/$TOTAL_COUNT] Fetched timeline data..."
                fi
              done

              wait  # Wait for remaining jobs
              echo "Timeline data fetched for $count builds."

        - task: Bash@3
          displayName: Generate metrics JSON
          env:
            ORG: $(organization)
            PROJECT: $(targetProject)
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail

              METRICS_PATH="$(Build.ArtifactStagingDirectory)/metrics"
              MODE=$(cat "$METRICS_PATH/mode.txt")

              echo "=========================================="
              echo "Generating metrics JSON ($MODE mode)"
              echo "=========================================="

              BUILDS_FILE="$METRICS_PATH/builds.json"

              # Check if jq is available
              if ! command -v jq &> /dev/null; then
                echo "Error: jq is required but not installed"
                exit 1
              fi

              # Process builds
              FILTERED_BUILDS=$(cat "$BUILDS_FILE" | jq '.value')
              TOTAL_BUILDS=$(echo "$FILTERED_BUILDS" | jq 'length')

              echo "Processing $TOTAL_BUILDS builds..."

              # Set output filename based on mode
              if [ "$MODE" = "pr" ]; then
                OUTPUT_FILE="$(Build.ArtifactStagingDirectory)/pr-data.json"
              else
                OUTPUT_FILE="$(Build.ArtifactStagingDirectory)/internal-data.json"
              fi

              # Generate chart data JSON with pre-aggregated metrics
              echo "$FILTERED_BUILDS" | jq --arg org "$ORG" --arg project "$PROJECT" --arg generatedAt "$(date -u +%Y-%m-%dT%H:%M:%SZ)" '
                # Build duration trend (avg per day)
                (group_by(.startTime | split("T")[0]) | map({
                  date: .[0].startTime | split("T")[0],
                  avgDuration: (map((.finishTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) - (.startTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601)) | add / length / 60)
                })) as $durationTrend |

                # Recent 20 builds for table (sorted by date descending)
                ([.[] | select(.startTime and .finishTime) | {
                  id: .id,
                  startTime: .startTime,
                  duration: (((.finishTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) - (.startTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601)) / 60),
                  result: .result,
                  source: (if (.sourceBranch // "") | startswith("refs/pull/") then "PR #" + ((.sourceBranch // "") | split("/")[2] // "N/A") elif .sourceVersion then .sourceVersion[0:7] else (.sourceBranch // "N/A" | tostring | .[0:30]) end),
                  sourceUrl: (if (.sourceBranch // "") | startswith("refs/pull/") then "https://github.com/microsoft/FluidFramework/pull/" + ((.sourceBranch // "") | split("/")[2] // "") else "https://github.com/microsoft/FluidFramework/commit/" + (.sourceVersion // "") end),
                  url: "https://dev.azure.com/\($org)/\($project)/_build/results?buildId=\(.id)"
                }] | sort_by(.startTime) | reverse | .[0:20]) as $recentBuilds |

                # Longest 20 builds for table (sorted by duration descending)
                ([.[] | select(.startTime and .finishTime) | {
                  id: .id,
                  startTime: .startTime,
                  duration: (((.finishTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) - (.startTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601)) / 60),
                  result: .result,
                  source: (if (.sourceBranch // "") | startswith("refs/pull/") then "PR #" + ((.sourceBranch // "") | split("/")[2] // "N/A") elif .sourceVersion then .sourceVersion[0:7] else (.sourceBranch // "N/A" | tostring | .[0:30]) end),
                  sourceUrl: (if (.sourceBranch // "") | startswith("refs/pull/") then "https://github.com/microsoft/FluidFramework/pull/" + ((.sourceBranch // "") | split("/")[2] // "") else "https://github.com/microsoft/FluidFramework/commit/" + (.sourceVersion // "") end),
                  url: "https://dev.azure.com/\($org)/\($project)/_build/results?buildId=\(.id)"
                }] | sort_by(.duration) | reverse | .[0:20]) as $longestBuilds |

                {
                  generatedAt: $generatedAt,
                  summary: {
                    totalBuilds: (. | length),
                    succeeded: (map(select(.result == "succeeded")) | length),
                    successRate: ((map(select(.result == "succeeded")) | length) * 100 / (. | length)),
                    avgDuration: (map((.finishTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) - (.startTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601)) | add / length / 60)
                  },
                  durationTrend: $durationTrend,
                  recentBuilds: $recentBuilds,
                  longestBuilds: $longestBuilds
                }
              ' > "$OUTPUT_FILE"

              # Process timeline data to extract stage and task metrics
              STAGE_DATA="{}"
              STAGE_TASKS_DATA="{}"

              for timeline_file in "$METRICS_PATH/timelines"/*.json; do
                if [ -f "$timeline_file" ]; then
                  stage_metrics=$(jq -c 'if .records == null then [] else [.records[] | select(.type == "Stage" and .startTime and .finishTime) | {name: .name, duration: (((.finishTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) - (.startTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601)) / 60), id: .id}] end' "$timeline_file" 2>/dev/null || echo "[]")

                  if [ "$stage_metrics" != "[]" ]; then
                    STAGE_DATA=$(echo "$STAGE_DATA" | jq --argjson stages "$stage_metrics" '
                      reduce $stages[] as $s (.; .[$s.name] += [$s.duration])
                    ')
                  fi

                  stage_task_metrics=$(jq -c '
                    if .records == null then {} else
                    .records as $records |
                    [.records[] | select(.type == "Stage" and .startTime and .finishTime)] as $stages |
                    reduce $stages[] as $stage ({};
                      .[$stage.name] = [
                        $records[] | select(.type == "Phase" and .parentId == $stage.id and .startTime and .finishTime) | {
                          name: .name,
                          duration: (((.finishTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) - (.startTime | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601)) / 60)
                        }
                      ]
                    )
                    end
                  ' "$timeline_file" 2>/dev/null || echo "{}")

                  if [ "$stage_task_metrics" != "{}" ]; then
                    STAGE_TASKS_DATA=$(echo "$STAGE_TASKS_DATA" | jq --argjson stageTaskData "$stage_task_metrics" '
                      reduce ($stageTaskData | to_entries[]) as $stage (.;
                        reduce $stage.value[] as $task (.;
                          .[$stage.key][$task.name] += [$task.duration]
                        )
                      )
                    ')
                  fi
                fi
              done

              # Add stage data to output JSON
              jq --argjson stages "$STAGE_DATA" --argjson stageTasks "$STAGE_TASKS_DATA" '
                .stagePerformance = ($stages | to_entries | map({name: .key, avgDuration: ((.value | add) / (.value | length))})) |
                .stageTaskBreakdown = ($stageTasks | to_entries | map({
                  key: .key,
                  value: (.value | to_entries | map({name: .key, avgDuration: ((.value | add) / (.value | length))}))
                }) | from_entries)
              ' "$OUTPUT_FILE" > "${OUTPUT_FILE}.tmp"
              mv "${OUTPUT_FILE}.tmp" "$OUTPUT_FILE"

              echo "Metrics JSON generated: $OUTPUT_FILE"
              echo "Data size: $(wc -c < "$OUTPUT_FILE") bytes"

        - task: Bash@3
          displayName: Prepare deployment package
          env:
            ASWA_HOSTNAME: $(ASWA_HOSTNAME)
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail

              MODE=$(cat $(Build.ArtifactStagingDirectory)/metrics/mode.txt)
              DEPLOY_DIR="$(Build.ArtifactStagingDirectory)/deploy"

              echo "=========================================="
              echo "Preparing deployment package ($MODE mode)"
              echo "=========================================="

              mkdir -p "$DEPLOY_DIR/data"

              # Copy our generated data file
              if [ "$MODE" = "pr" ]; then
                cp "$(Build.ArtifactStagingDirectory)/pr-data.json" "$DEPLOY_DIR/data/pr-data.json"
                OTHER_FILE="internal-data.json"
              else
                cp "$(Build.ArtifactStagingDirectory)/internal-data.json" "$DEPLOY_DIR/data/internal-data.json"
                OTHER_FILE="pr-data.json"
              fi

              # Try to fetch the other mode's data from the live site (may not exist yet)
              echo "Fetching existing $OTHER_FILE from dashboard..."
              if curl -sf "https://$ASWA_HOSTNAME/data/$OTHER_FILE" -o "$DEPLOY_DIR/data/$OTHER_FILE" 2>/dev/null; then
                echo "Successfully fetched $OTHER_FILE"
              else
                echo "Note: $OTHER_FILE not available yet (first deployment or other mode hasn't run)"
              fi

              # Copy HTML template and config from repo
              REPO_PATH="$(Pipeline.Workspace)/repo"
              cp "$REPO_PATH/tools/pipelines/dashboard-template/index.html" "$DEPLOY_DIR/index.html"
              cp "$REPO_PATH/tools/pipelines/dashboard-template/staticwebapp.config.json" "$DEPLOY_DIR/staticwebapp.config.json"

              echo "Deployment package contents:"
              find "$DEPLOY_DIR" -type f

        - task: AzureStaticWebApp@0
          displayName: Deploy to Azure Static Web Apps
          inputs:
            skip_app_build: true
            skip_api_build: true
            cwd: $(Build.ArtifactStagingDirectory)
            app_location: 'deploy'
            output_location: ''
            azure_static_web_apps_api_token: $(ASWA_DEPLOYMENT_TOKEN)

        - task: Bash@3
          displayName: Clean up
          inputs:
            targetType: 'inline'
            script: |
              echo "Cleaning up temporary files..."
              rm -rf $(Build.ArtifactStagingDirectory)/metrics
              rm -rf $(Build.ArtifactStagingDirectory)/deploy
              rm -f $(Build.ArtifactStagingDirectory)/*.json
              echo "Cleanup complete"
