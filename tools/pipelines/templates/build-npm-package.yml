# Copyright (c) Microsoft Corporation and contributors. All rights reserved.
# Licensed under the MIT License.

# build-npm-package template to build NPM packages/projects

parameters:
- name: buildDirectory
  type: string

- name: taskBuild
  type: string
  default: ci:build

- name: taskBuildDocs
  type: boolean
  default: true

- name: publishDocs
  type: boolean
  default: false

- name: taskLint
  type: boolean
  default: true

- name: taskLintName
  type: string
  default: lint

- name: taskTest
  type: object
  default:
  - ci:test

# A list of directories (under the buildDirectory) to run the PublishTestResults task on in separate steps.
# Used to avoid the force merge limit of 100 result files.
- name: testResultDirs
  type: object
  default:
  - nyc

- name: taskBundleAnalysis
  type: boolean
  default: false

- name: taskPublishBundleSizeArtifacts
  type: boolean
  default: false

- name: taskPack
  type: boolean
  default: true

- name: poolCG
  type: object
  default: Small

- name: poolBuild
  type: object
  default: Small

- name: preCG
  type: stepList
  default: []

- name: cgSubDirectory
  type: string
  default:

- name: checkoutSubmodules
  type: boolean
  default: false

- name: namespace
  type: boolean
  default: true

- name: buildNumberInPatch
  type: string
  default:

- name: nonScopedPackages
  type: object
  default: []

- name: publishOverride
  type: string

- name: releaseBuildOverride
  type: string

- name: tagName
  type: string

- name: includeInternalVersions
  type: boolean
  default: false

- name: buildToolsVersionToInstall
  type: string
  default: repo

- name: packageManager
  type: string
  default: npm

# Parameter for modifying the 'types' field in the package.json.
# If the value 'none' is provided, the 'types' field in package.json will remain unchanged.
- name: packageTypesOverride
  type: string
  default: none

- name: packageManagerInstallCommand
  type: string
  default: 'npm ci --unsafe-perm'

- name: additionalBuildSteps
  type: stepList
  default: []

# The semver range constraint to use for interdependencies; that is, dependencies on other packages within the release
# group
- name: interdependencyRange
  type: string
  default: "^"

# A list of scripts that execute checks of the release group, e.g. prettier, syncpack, etc. These will be run serially
# in a pipeline stage separate from the build stage.
- name: checks
  type: object
  default: []

- name: telemetry
  type: boolean
  default: false

variables:
  # We use 'chalk' to colorize output, which auto-detects color support in the
  # running terminal.  The log output shown in Azure DevOps job runs only has
  # basic ANSI color support though, so force that in the pipeline
  - name: FORCE_COLOR
    value: 1
  - template: include-vars.yml
    parameters:
      publishOverride: ${{ parameters.publishOverride }}
      releaseBuildOverride: ${{ parameters.releaseBuildOverride }}
      buildNumberInPatch: ${{ parameters.buildNumberInPatch }}
      nonScopedPackages: ${{ parameters.nonScopedPackages }}
  - name: toolAbsolutePath
    value:  $(Build.SourcesDirectory)/tools/telemetry-generator
    readonly: true
  - group: ado-feeds

stages:
  - ${{ if ne(convertToJson(parameters.checks), '[]') }}:
    - template: include-policy-check.yml
      parameters:
        buildDirectory: ${{ parameters.buildDirectory }}
        checks: ${{ parameters.checks }}

  # Install / Build / Test Stage
  - stage: build
    displayName: Build Stage
    dependsOn: [] # this stage doesn't depend on preceding stage
    jobs:
      # Job - Build
      - job: build
        displayName: Build
        pool: ${{ parameters.poolBuild }}
        variables:
          testCoverage: ${{ ne(variables['Build.Reason'], 'PullRequest') }}
          releaseBuildVar: $[variables.releaseBuild]
          ${{ if eq(variables['Build.Reason'], 'PullRequest') }}:
            targetBranchName: $(System.PullRequest.TargetBranch)
        steps:
        # Setup
        - checkout: self
          clean: true
          lfs: ${{ parameters.checkoutSubmodules }}
          submodules: ${{ parameters.checkoutSubmodules }}

        - task: Bash@3
          displayName: Parameters
          inputs:
            targetType: 'inline'
            workingDirectory: ${{ parameters.buildDirectory }}
            script: |
              # Show all task group conditions

              echo "
              Pipeline Variables:
                releaseBuild=$(releaseBuildVar)

              Override Parameters:
                publishOverride=${{ parameters.publishOverride }}
                releaseBuildOverride=${{ parameters.releaseBuildOverride }}
                packageTypesOverride=${{ parameters.packageTypesOverride }}

              Tasks Parameters:
                BuildDir=${{ parameters.buildDirectory }}
                Build=${{ parameters.taskBuild }}
                Lint=${{ parameters.taskLint }}
                LintName: ${{ parameters.taskLintName }}
                Test=${{ convertToJson(parameters.taskTest) }}
                TestResultDirs=${{ convertToJson(parameters.testResultDirs) }}
                BuildDoc=${{ parameters.taskBuildDocs }}
                PublishDocs=${{ parameters.publishDocs }}
                TestCoverage=$(testCoverage)

              Variables:
                toolAbsolutePath=$(toolAbsolutePath)
                BuildReason=$(variables['Build.Reason'])

              Publish Parameters:
                nonScopedPackages=${{ join(', ', parameters.nonScopedPackages) }}
                interdependencyRange='${{ parameters.interdependencyRange }}'
                packageTypesOverride='${{ parameters.packageTypesOverride }}'

              Computed variables:
                shouldPublish=${{ variables.shouldPublish }}
                componentDetection=${{ variables.componentDetection }}
                publish=${{ variables.publish }}
                canRelease=${{ variables.canRelease }}
                publishNonScopedPackages=${{ variables.publishNonScopedPackages }}
                pnpmStorePath=${{ variables.pnpmStorePath }}

                release=$(release)"

              # Target Branch variable (PR policy related)
              if [[ ${{ variables['Build.Reason'] }} == "PullRequest" ]]; then
                echo "TargetBranchName=$(targetBranchName)"
              fi

              # Error checking
              if [[ "$(release)" == "release" ]]; then
                if [[ "${{ variables.canRelease }}" == "False" ]]; then
                  echo "##vso[task.logissue type=error]Invalid branch ${{ variables['Build.SourceBranch'] }} for release"
                  exit -1;
                fi

                if [ -f "lerna.json" ]; then
                  grep -e fluid.*[0-9]-[0-9] `find packages -name 'package.json'`
                else
                  grep -e fluid.*[0-9]-[0-9] `find . -name 'package.json'`
                fi

                if [[ $? == 0 ]]; then
                  echo "##vso[task.logissue type=error]Release shouldn't contain prerelease dependencies"
                  exit -1;
                fi
              fi

              if [[ "$(release)" == "prerelease" ]]; then
                if [[ "${{ parameters.buildNumberInPatch }}" == "true" ]]; then
                  echo "##vso[task.logissue type=error] Prerelease not allow for builds that put build number as the patch version"
                  exit -1;
                fi
              fi

              if [[ "$(release)" != "prerelease" ]]; then
                if [[ "${{ parameters.packageTypesOverride }}" == "alpha" || "${{ parameters.packageTypesOverride }}" == "beta" ]]; then
                  echo "##vso[task.logissue type=error]This release type is not supported. alpha/beta ***prerelease*** is allowed"
                  exit -1;
                fi
              fi

              if [[ "$(release)" != "none" ]] && [[ "$(release)" != "" ]]; then
                if [[ "${{ variables.publish }}" != "True" ]]; then
                  echo "##vso[task.logissue type=error]'$(release)'' is set but package is not published. Either the branch doesn't default to publish or it is skipped."
                  exit -1;
                fi
              fi

        - template: include-use-node-version.yml

        - template: include-install.yml
          parameters:
            packageManager: ${{ parameters.packageManager }}
            buildDirectory: ${{ parameters.buildDirectory }}
            packageManagerInstallCommand: ${{ parameters.packageManagerInstallCommand }}

        # This check is a workaround. We don't want to set versions for the build-bundle-size-artifacts pipeline because
        # the pipeline is special - it runs a client build but doesn't publish anything. Working around this properly is
        # challenging and would create a much bigger change. Since this is the only pipeline that sets this variable to
        # true, we use that to determine whether to set versions.
        - ${{ if eq(parameters.taskPublishBundleSizeArtifacts, false) }}:
          - template: include-set-package-version.yml
            parameters:
              buildDirectory: ${{ parameters.buildDirectory }}
              buildNumberInPatch: ${{ parameters.buildNumberInPatch }}
              buildToolsVersionToInstall: ${{ parameters.buildToolsVersionToInstall }}
              tagName: ${{ parameters.tagName }}
              interdependencyRange: ${{ parameters.interdependencyRange }}
              packageTypesOverride: ${{ parameters.packageTypesOverride }}

        # Build and Lint
        - template: include-build-lint.yml
          parameters:
            taskBuild: ${{ parameters.taskBuild }}
            taskLint: ${{ parameters.taskLint }}
            taskLintName: ${{ parameters.taskLintName }}
            buildDirectory: ${{ parameters.buildDirectory }}

        # Test
        - ${{ if ne(convertToJson(parameters.taskTest), '[]') }}:
          # Set variable startTest if the build succeed so that we can run all the test tasks whether they are failed or not
          - script: |
              echo "##vso[task.setvariable variable=startTest]true"
            displayName: Start Test

          - ${{ each taskTestStep in parameters.taskTest }}:
            - template: include-test-task.yml
              parameters:
                taskTestStep: ${{ taskTestStep }}
                buildDirectory: ${{ parameters.buildDirectory }}

          # Test - Upload coverage results
          # Some webpacked file using externals introduce file name with quotes in them
          # and Istanbul's cobertura reporter doesn't escape them causing parse error when we publish
          # A quick fix to patch the file with sed. (See https://github.com/bcoe/c8/issues/302)
          - ${{ if eq(variables['testCoverage'], true) }}:
            - task: Bash@3
              displayName: 'Check for nyc/report directory'
              inputs:
                targetType: 'inline'
                workingDirectory: ${{ parameters.buildDirectory }}
                script: |
                  test -d nyc/report && echo '##vso[task.setvariable variable=ReportDirExists;]true' || echo 'No nyc/report directory'
              condition: and(succeededOrFailed(), eq(variables['startTest'], 'true'))
            - task: Bash@3
              displayName: Patch Coverage Results
              inputs:
                targetType: 'inline'
                workingDirectory: ${{ parameters.buildDirectory }}/nyc/report
                script: |
                  sed -e 's/\(filename=\".*[\\/]external .*\)"\(.*\)""/\1\&quot;\2\&quot;"/' cobertura-coverage.xml > cobertura-coverage-patched.xml
              condition: and(succeededOrFailed(), eq(variables['ReportDirExists'], 'true'))
            - task: PublishCodeCoverageResults@1
              displayName: Publish Code Coverage
              inputs:
                codeCoverageTool: Cobertura
                summaryFileLocation: ${{ parameters.buildDirectory }}/nyc/report/cobertura-coverage-patched.xml
                reportDirectory: ${{ parameters.buildDirectory }}/nyc/report
                failIfCoverageEmpty: true
              condition: and(succeededOrFailed(), eq(variables['ReportDirExists'], 'true'))

          # Publish tinylicious log for troubleshooting
          - ${{ if contains(convertToJson(parameters.taskTest), 'tinylicious') }}:
            - task: PublishPipelineArtifact@1
              displayName: Publish Artifact - Tinylicious Log
              inputs:
                targetPath: '${{ parameters.buildDirectory }}/packages/test/test-end-to-end-tests/tinylicious.log'
                artifactName: 'tinyliciousLog_attempt-$(System.JobAttempt)'
                publishLocation: 'pipeline'
              condition: and(succeededOrFailed(), eq(variables['startTest'], 'true'))
              continueOnError: true # Keep running subsequent tasks even if this one fails (e.g. the tinylicious log wasn't there)

          # Process test result, include publishing and logging
          - template: include-process-test-results.yml
            parameters:
              buildDirectory: ${{ parameters.buildDirectory }}
              testResultDirs: ${{ parameters.testResultDirs }}

        # Pack
        - ${{ if ne(parameters.taskPack, false) }}:
          - task: Bash@3
            displayName: npm pack
            env:
              PACKAGE_MANAGER: ${{ parameters.packageManager }}
              PUBLISH_NON_SCOPED: ${{ variables.publishNonScopedPackages }}
              RELEASE_GROUP: ${{ parameters.tagName }}
              STAGING_PATH: $(Build.ArtifactStagingDirectory)
            inputs:
              targetType: 'filePath'
              workingDirectory: ${{ parameters.buildDirectory }}
              filePath: $(Build.SourcesDirectory)/scripts/pack-packages.sh

          - ${{ if eq(variables.publishNonScopedPackages, true) }}:
            - ${{ each parameter in parameters.nonScopedPackages }}:
              - task: Bash@3
                displayName: Move Non-Scoped Package ${{parameter}}
                inputs:
                  targetType: 'inline'
                  workingDirectory: ${{ parameters.buildDirectory }}
                  script: |
                    mv -t $(Build.ArtifactStagingDirectory)/pack/non-scoped/ $(Build.ArtifactStagingDirectory)/pack/scoped/${{parameter}}*.tgz

          - task: PublishPipelineArtifact@1
            displayName: Publish Artifact - pack
            inputs:
              targetPath: '$(Build.ArtifactStagingDirectory)/pack'
              artifactName: 'pack'
              publishLocation: 'pipeline'

          - task: PublishPipelineArtifact@1
            displayName: Publish Artifact - Test Files
            inputs:
              targetPath: '$(Build.ArtifactStagingDirectory)/test-files'
              artifactName: 'test-files'
              publishLocation: 'pipeline'

        # Collect/publish/run bundle analysis
        - ${{ if eq(parameters.taskBundleAnalysis, true) }}:
          - task: Npm@1
            displayName: npm run bundle-analysis:collect
            inputs:
              command: 'custom'
              workingDir: ${{ parameters.buildDirectory }}
              customCommand: 'run bundle-analysis:collect'

          # NOTE: this task is deliberately not updated to the newer PublishPipelineArtifact because some of our tooling
          # does not support the newer task.
          # See the getZipObjectFromArtifact function in @fluidframework/bundle-size-tools for details about the issue.
          - task: PublishBuildArtifacts@1
            displayName: Publish Artifacts - bundle-analysis
            condition:
              and(
                succeeded(),
                ne(variables['Build.Reason'], 'PullRequest'),
                eq(${{ parameters.taskPublishBundleSizeArtifacts }}, true)
              )
            inputs:
              PathtoPublish: '${{ parameters.buildDirectory }}/artifacts/bundleAnalysis'
              Artifactname: 'bundleAnalysis'
              publishLocation: 'Container'

          - task: Npm@1
            displayName: run bundle size comparison
            condition: and(succeeded(), eq(variables['Build.Reason'], 'PullRequest'))
            continueOnError: true
            env:
              ADO_API_TOKEN: $(System.AccessToken)
              DANGER_GITHUB_API_TOKEN: $(githubPublicRepoSecret)
              TARGET_BRANCH_NAME: ${{ variables.targetBranchName }}
            inputs:
              command: 'custom'
              workingDir: ${{ parameters.buildDirectory }}
              customCommand: 'run bundle-analysis:run'

          - ${{ if and(or(eq(variables['Build.Reason'], 'IndividualCI'), eq(variables['Build.Reason'], 'BatchedCI')), eq(variables['System.TeamProject'], 'internal')) }}:
            # Auth to internal feed
            - task: Bash@3
              name: Initialize
              displayName: Initialize .npmrc for telemetry logger
              inputs:
                targetType: 'inline'
                workingDirectory: ${{ variables.toolAbsolutePath }}
                # Note: $(ado-feeds-build) and $(ado-feeds-office) come from the ado-feeds variable group
                script: |
                  echo Initialize package
                  npm init --yes

                  echo Generating .npmrc
                  echo "registry=https://registry.npmjs.org" >> ./.npmrc
                  echo "always-auth=false" >> ./.npmrc

                  echo "@fluidframework:registry=${{ variables.feed }}" >> ./.npmrc
                  echo "@fluid-experimental:registry=${{ variables.feed }}" >> ./.npmrc

                  # This is confusing, but we are using the .npmrc here to load dependencies from different feeds. These
                  # scopes must be loaded from the "dev" feed because that is the only place they are published. Ideally
                  # this logic will be centralized outside of CI in the future.
                  echo "@fluid-internal:registry=${{ variables.devFeed }}" >> ./.npmrc
                  echo "@fluid-private:registry=${{ variables.devFeed }}" >> ./.npmrc

                  # This scope must be loaded from the "build" feed
                  echo "@ff-internal:registry=$(ado-feeds-build)" >> ./.npmrc

                  # This scope must be loaded from the internal Office feed
                  echo "@microsoft:registry=$(ado-feeds-office)" >> ./.npmrc

                  echo "always-auth=true" >> ./.npmrc
                  cat .npmrc

            - task: npmAuthenticate@0
              displayName: 'npm authenticate (internal feed)'
              inputs:
                workingFile: ${{ variables.toolAbsolutePath }}/.npmrc

            - task: Bash@3
              displayName: 'List report.json and .npmrc'
              inputs:
                targetType: 'inline'
                workingDirectory:  ${{ parameters.buildDirectory }}
                script: |
                  echo "Build Directory is ${{ parameters.buildDirectory }}"
                  ls -la '${{ parameters.buildDirectory }}/artifacts/bundleAnalysis/@fluid-example/bundle-size-tests';
                  cat '${{ variables.toolAbsolutePath }}/.npmrc';

            - task: Bash@3
              displayName: 'Prepare telemetry-generator for bundle size'
              inputs:
                targetType: 'inline'
                workingDirectory:  ${{ variables.toolAbsolutePath }}
                script: |
                  ls -la '${{ variables.toolAbsolutePath }}';
                  ls -la '${{ parameters.buildDirectory }}';
                  npm install @ff-internal/aria-logger;
                  npm i;
                  npm run build:compile;

            - task: Bash@3
              displayName: Write bundle sizes measurements to Aria/Kusto
              inputs:
                targetType: 'inline'
                workingDirectory: ${{ variables.toolAbsolutePath }}
                script: |
                  echo "Writing the following performance tests results to Aria/Kusto"
                  echo "Report Size:"
                  ls -la '../../examples/utils/bundle-size-tests/bundleAnalysis/report.json';
                  echo "Tools Path:"
                  ls -la '../../tools/telemetry-generator/dist/handlers';
                  node --require @ff-internal/aria-logger bin/run --handlerModule $(Build.SourcesDirectory)/tools/telemetry-generator/dist/handlers/bundleSizeHandler.js --dir '../../artifacts/bundleAnalysis/@fluid-example/bundle-size-tests';
                  echo "Removing .npmrc"
                  rm ../../tools/telemetry-generator/.npmrc;

        # Docs
        - ${{ if ne(parameters.taskBuildDocs, false) }}:
          - task: Npm@1
            displayName: npm run ci:build:docs
            inputs:
              command: 'custom'
              workingDir: ${{ parameters.buildDirectory }}
              customCommand: 'run ci:build:docs'

        - ${{ if or(eq(parameters.publishDocs, true), eq(parameters.taskBuildDocs, true)) }}:
          - task: PublishPipelineArtifact@1
            displayName: Publish Artifact - _api-extractor-temp
            inputs:
              targetPath: '${{ parameters.buildDirectory }}/_api-extractor-temp'
              artifactName: '_api-extractor-temp'
              publishLocation: 'pipeline'

        - ${{ if eq(parameters.packageManager, 'pnpm') }}:
          # Reset the pnpm-lock.yaml file since it's been modified by the versioning. But for dependency caching we want
          # the cache key (which is based on the contents of the lockfile) to be the unmodified file. So we reset the
          # lockfile as the last step so that when the dependency cache is uploaded, the cache key matches what it was
          # at the beginning of the CI job.
          - task: Bash@3
            displayName: Reset lockfile
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ parameters.buildDirectory }}
              script: |
                git checkout HEAD -- pnpm-lock.yaml

          # Prune the pnpm store before it's cached. This removes any deps that are not used by the current build.
          - task: Bash@3
            displayName: Prune pnpm store
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ parameters.buildDirectory }}
              script: |
                pnpm store prune


        - task: Bash@3
          displayName: Check for extraneous modified files
          inputs:
            targetType: 'inline'
            script: |
              git status | grep -v -E 'package.json|package-lock.json|packageVersion.ts|lerna.json|.npmrc|build-tools/.npmrc|\(use.*' | grep '^\s' > git_status.log
              if [ `cat git_status.log | wc -l` != "0" ]; then
                cat git_status.log
                echo "##vso[task.logissue type=error]Build should not create extraneous files"
                exit -1;
              fi

        # This additional build step is used to run step not part of the main build. In build client pipeline,
        # this is used to inject telemetry key file and upload built devtools extension.
        - ${{ parameters.additionalBuildSteps }}

      # Job - Component detection
      - ${{ if eq(variables.componentDetection, true) }}:
        - job: CG
          displayName: Component Detection
          pool: ${{ parameters.poolCG }}
          steps:
          - checkout: self
            clean: true
            lfs: false
            submodules: false

          - ${{ parameters.preCG }}

          - task: ComponentGovernanceComponentDetection@0
            displayName: Component Detection
            inputs:
              sourceScanPath: ${{ parameters.buildDirectory }}/${{ parameters.cgSubDirectory }}
              verbosity: Verbose
              scanType: Register
              alertWarningLevel: High

  # Publish stage
  - ${{ if eq(variables.publish, true) }}:
    - template: include-publish-npm-package.yml
      parameters:
        namespace: ${{ parameters.namespace }}
        tagName: ${{ parameters.tagName }}
        publishNonScopedPackages: ${{ variables.publishNonScopedPackages }}

  # Capture per-pipeline stage results
  - stage: upload_run_telemetry
    displayName: Upload pipeline run telemetry to Kusto
    condition: and(succeededOrFailed(), eq(variables['Build.Reason'], 'IndividualCI'), eq(${{parameters.telemetry}}, true))
    dependsOn:
      - build

    jobs:
      - job: upload_run_telemetry
        displayName: Upload pipeline run telemetry to Kusto
        pool: Small
        variables:
        - name: pipelineTelemetryWorkdir
          value: $(Pipeline.Workspace)/pipelineTelemetryWorkdir

        steps:
        - template: include-telemetry-setup.yml
          parameters:
            devFeedUrl: $(ado-feeds-dev)
            officeFeedUrl: $(ado-feeds-office)

        - task: Bash@3
          displayName: Retrieve buildId results
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Creating output folder ..."
              mkdir -p $(pipelineTelemetryWorkdir)/timingOutput
              echo "Retrieving pipeline run timeline data ..."
              echo 'curl -u ":<REDACTED>" "https://dev.azure.com/fluidframework/internal/_apis/build/builds/$BUILD_ID/timeline"'
              curl -u ":$ADO_API_TOKEN" "https://dev.azure.com/fluidframework/internal/_apis/build/builds/$BUILD_ID/timeline\?api-version\=6.0-preview.1" > $(pipelineTelemetryWorkdir)/timingOutput/output.json
              pwd;
              ls -laR $(pipelineTelemetryWorkdir)/timingOutput/output.json;
              cat $(pipelineTelemetryWorkdir)/timingOutput/output.json;
              node --require @ff-internal/aria-logger bin/run --handlerModule $(Build.SourcesDirectory)/tools/telemetry-generator/dist/handlers/stageTimingRetriever.js --dir '$(pipelineTelemetryWorkdir)/timingOutput/';
          env:
            BUILD_ID: $(Build.BuildId)
            ADO_API_TOKEN: $(System.AccessToken)
            PIPELINE: 'BuildClient'
