# Copyright (c) Microsoft Corporation and contributors. All rights reserved.
# Licensed under the MIT License.

# build-npm-package template to build NPM packages/projects

parameters:
- name: buildDirectory
  type: string

- name: taskBuild
  type: string
  default: ci:build

- name: taskBuildDocs
  type: boolean
  default: true

- name: publishDocs
  type: boolean
  default: false

- name: taskLint
  type: boolean
  default: true

- name: taskLintName
  type: string
  default: lint

- name: taskTest
  type: object
  default:
  - ci:test

# A list of directories (under the buildDirectory) to run the PublishTestResults task on in separate steps.
# Used to avoid the force merge limit of 100 result files.
- name: testResultDirs
  type: object
  default:
  - nyc

- name: taskBundleAnalysis
  type: boolean
  default: false

- name: taskPublishBundleSizeArtifacts
  type: boolean
  default: false

- name: taskPack
  type: boolean
  default: true

- name: poolBuild
  type: object
  default: Small-1ES

- name: preCG
  type: stepList
  default: []

- name: cgSubDirectory
  type: string
  default:

- name: checkoutSubmodules
  type: boolean
  default: false

- name: buildNumberInPatch
  type: string
  default:

- name: publishOverride
  type: string

- name: releaseBuildOverride
  type: string

- name: tagName
  type: string

- name: isReleaseGroup
  type: boolean
  default: false

- name: includeInternalVersions
  type: boolean
  default: false

- name: buildToolsVersionToInstall
  type: string
  default: repo

- name: packageManager
  type: string
  default: npm

# Parameter for modifying the 'types' field in the package.json.
# If the value 'none' is provided, the 'types' field in package.json will remain unchanged.
- name: packageTypesOverride
  type: string
  default: none

- name: packageManagerInstallCommand
  type: string
  default: 'npm ci --unsafe-perm'

- name: additionalBuildSteps
  type: stepList
  default: []

# The semver range constraint to use for interdependencies; that is, dependencies on other packages within the release
# group
- name: interdependencyRange
  type: string
  default: "^"

# A list of scripts that execute checks of the release group, e.g. prettier, syncpack, etc. These will be run serially
# in a pipeline stage separate from the build stage.
- name: checks
  type: object
  default: []

- name: telemetry
  type: boolean
  default: false

# Indicates if this run is going to publish npm packages (and run extra steps necessary in that case) or not
- name: publish
  type: boolean

# Indicates if tests should be run with code coverage analysis.
- name: testCoverage
  type: boolean

# The `resources` specify the location and version of the 1ES Pipeline Template.
resources:
  repositories:
    - repository: m365Pipelines
      type: git
      name: 1ESPipelineTemplates/M365GPT
      ref: refs/tags/release

extends:
  # The pipeline extends the 1ES PT which will inject different SDL and compliance tasks.
  # Read more: https://eng.ms/docs/cloud-ai-platform/devdiv/one-engineering-system-1es/1es-docs/1es-pipeline-templates/onboarding/overview
  template: v1/M365.Official.PipelineTemplate.yml@m365Pipelines
  parameters:
    pool:
      name: ${{ parameters.poolBuild }}
      os: linux
    sdl:
      arrow:
        # This is the service connection for the Arrow Service Connection in FluidFramework Azure DevOps organization
        # Currently we want to use different names for internal and public builds for Arrow Service Connection
        ${{ if eq(variables['System.TeamProject'], 'internal') }}:
          serviceConnection: ff-internal-arrow-sc
        ${{ else }}:
          serviceConnection: ff-public-arrow-sc
      sourceAnalysisPool:
        name: Azure-Pipelines-1ESPT-ExDShared
        image: windows-2022
        os: windows
      # Tentative workaround for the occasional Credscan failures
      credscan:
        batchSize: 4
    # Skip tagging if Github PR coming from a fork;  This skips Microsoft security checks that won't work on forks.
    settings:
      skipBuildTagsForGitHubPullRequests: true
    customBuildTags:
      - ES365AIMigrationTooling
    stages:
      - ${{ if ne(convertToJson(parameters.checks), '[]') }}:
          - template: /tools/pipelines/templates/include-policy-check.yml@self
            parameters:
              buildDirectory: '${{ parameters.buildDirectory }}'
              checks: '${{ parameters.checks }}'
              # Install all dependencies, not just the root ones
              dependencyInstallCommand: pnpm install --frozen-lockfile

      # Install / Build / Test Stage
      - stage: build
        displayName: Build Stage
        dependsOn: [] # this stage doesn't depend on preceding stage
        jobs:
          # Job - Build
          - job: build
            displayName: Build
            ${{ if eq(variables['Build.Reason'], 'PullRequest') }}:
              timeoutInMinutes: 120
            ${{ else }}:
              # CI builds run more aggressive compat configurations which can take longer.
              # See "FullCompat" under packages\test\test-version-utils\README.md for more details.
              # At the time of adding this comment, the full compat config is on the smaller side and so
              # CI builds consistently pass with a 60 minutes timeout. However, it will naturally grow
              # over time and it might be necessary to bump it.
              # AB#6680 is also relevant here, which tracks rethinking how and where we run tests (likely with
              # a focus on e2e tests)
              # Note, This was recently updated to 90 minutes to account for the additional build time added from extending
              # the Microsoft 1ES template required for corporate security compliance. Updated again to 120 to mitigate a
              # series of build breaks due to timeouts.
              timeoutInMinutes: 120
            variables:
              - group: ado-feeds
              - group: storage-vars
              - name: releaseBuildVar
                value: '$[variables.releaseBuild]'
              - ${{ if eq(variables['Build.Reason'], 'PullRequest') }}:
                - name: targetBranchName
                  value: $(System.PullRequest.TargetBranch)
              # Absolute path to the folder that contains the source code for the telemetry-generator package, which is
              # used in a few places in the pipeline to push custom telemetry to Kusto.
              - name: absolutePathToTelemetryGenerator
                value: $(Build.SourcesDirectory)/tools/telemetry-generator
                readonly: true
            steps:
              # Setup
              - checkout: self
                clean: true
                lfs: '${{ parameters.checkoutSubmodules }}'
                submodules: '${{ parameters.checkoutSubmodules }}'

              - task: Bash@3
                displayName: Parameters
                inputs:
                  targetType: inline
                  workingDirectory: '${{ parameters.buildDirectory }}'
                  script: |
                    # Show all task group conditions

                    echo "
                    Pipeline Variables:
                      releaseBuild=$(releaseBuildVar)

                    Override Parameters:
                      packageTypesOverride=${{ parameters.packageTypesOverride }}
                      publishOverride=${{ parameters.publishOverride }}
                      releaseBuildOverride=${{ parameters.releaseBuildOverride }}

                    Tasks Parameters:
                      Build=${{ parameters.taskBuild }}
                      BuildDir=${{ parameters.buildDirectory }}
                      BuildDoc=${{ parameters.taskBuildDocs }}
                      Lint=${{ parameters.taskLint }}
                      LintName: ${{ parameters.taskLintName }}
                      PublishDocs=${{ parameters.publishDocs }}
                      Test=${{ convertToJson(parameters.taskTest) }}
                      TestCoverage=${{ parameters.testCoverage }}
                      TestResultDirs=${{ convertToJson(parameters.testResultDirs) }}

                    Variables:
                      absolutePathToTelemetryGenerator=$(absolutePathToTelemetryGenerator)
                      BuildReason=${{ variables['Build.Reason'] }}

                    Publish Parameters:
                      interdependencyRange='${{ parameters.interdependencyRange }}'
                      packageTypesOverride='${{ parameters.packageTypesOverride }}'
                      publish=${{ parameters.publish }}

                    Computed variables:
                      canRelease=$(canRelease)
                      release=$(release)
                      shouldPublish=$(shouldPublish)
                    "

                    # Target Branch variable (PR policy related)
                    if [[ ${{ variables['Build.Reason'] }} == "PullRequest" ]]; then
                      echo "TargetBranchName=$(targetBranchName)"
                    fi

                    # Error checking
                    if [[ "$(release)" == "release" ]]; then
                      if [[ "$(canRelease)" == "False" ]]; then
                        echo "##vso[task.logissue type=error]Invalid branch ${{ variables['Build.SourceBranch'] }} for release"
                        exit -1;
                      fi

                      if [ -f "lerna.json" ]; then
                        grep -e fluid.*[0-9]-[0-9] `find packages -name 'package.json'`
                      else
                        grep -e fluid.*[0-9]-[0-9] `find . -name 'package.json'`
                      fi

                      if [[ $? == 0 ]]; then
                        echo "##vso[task.logissue type=error]Release shouldn't contain prerelease dependencies"
                        exit -1;
                      fi
                    fi

                    if [[ "$(release)" == "prerelease" ]]; then
                      if [[ "${{ parameters.buildNumberInPatch }}" == "true" ]]; then
                        echo "##vso[task.logissue type=error] Prerelease not allow for builds that put build number as the patch version"
                        exit -1;
                      fi
                    fi

                    if [[ "$(release)" != "prerelease" ]]; then
                      if [[ "${{ parameters.packageTypesOverride }}" == "alpha" || "${{ parameters.packageTypesOverride }}" == "beta" ]]; then
                        echo "##vso[task.logissue type=error]This release type is not supported. alpha/beta ***prerelease*** is allowed"
                        exit -1;
                      fi
                    fi

                    if [[ "$(release)" != "none" ]] && [[ "$(release)" != "" ]]; then
                      if [[ "${{ parameters.publish }}" != "True" ]]; then
                        echo "##vso[task.logissue type=error]'$(release)'' is set but package is not published. Either the branch doesn't default to publish or it is skipped."
                        exit -1;
                      fi
                    fi

              - template: /tools/pipelines/templates/include-use-node-version.yml@self

              - template: /tools/pipelines/templates/include-install.yml@self
                parameters:
                  packageManager: '${{ parameters.packageManager }}'
                  buildDirectory: '${{ parameters.buildDirectory }}'
                  packageManagerInstallCommand: '${{ parameters.packageManagerInstallCommand }}'

              # This check is a workaround. We don't want to set versions for the build-bundle-size-artifacts pipeline because
              # the pipeline is special - it runs a client build but doesn't publish anything. Working around this properly is
              # challenging and would create a much bigger change. Since this is the only pipeline that sets this variable to
              # true, we use that to determine whether to set versions.
              - ${{ if eq(parameters.taskPublishBundleSizeArtifacts, false) }}:
                  - template: /tools/pipelines/templates/include-set-package-version.yml@self
                    parameters:
                      buildDirectory: '${{ parameters.buildDirectory }}'
                      buildNumberInPatch: '${{ parameters.buildNumberInPatch }}'
                      buildToolsVersionToInstall: '${{ parameters.buildToolsVersionToInstall }}'
                      tagName: '${{ parameters.tagName }}'
                      interdependencyRange: '${{ parameters.interdependencyRange }}'
                      packageTypesOverride: '${{ parameters.packageTypesOverride }}'
                      STORAGE_ACCOUNT: $(STORAGE_ACCOUNT)
                      STORAGE_KEY: $(STORAGE_KEY)

              # Build and Lint
              - template: /tools/pipelines/templates/include-build-lint.yml@self
                parameters:
                  taskBuild: '${{ parameters.taskBuild }}'
                  taskLint: '${{ parameters.taskLint }}'
                  taskLintName: '${{ parameters.taskLintName }}'
                  buildDirectory: '${{ parameters.buildDirectory }}'

              # Test
              - ${{ if ne(convertToJson(parameters.taskTest), '[]') }}:
                  # Set variable startTest if the build succeed so that we can run all the test tasks whether they are failed or not
                  - script: |
                      echo "##vso[task.setvariable variable=startTest]true"
                    displayName: Start Test

                  - ${{ each taskTestStep in parameters.taskTest }}:
                      - template: /tools/pipelines/templates/include-test-task.yml@self
                        parameters:
                          taskTestStep: '${{ taskTestStep }}'
                          buildDirectory: '${{ parameters.buildDirectory }}'
                          testCoverage: ${{ parameters.testCoverage }}

                  - ${{ if contains(convertToJson(parameters.taskTest), 'tinylicious') }}:
                    - task: Bash@3
                      displayName: Upload tinylicious log
                      condition: succeededOrFailed()
                      continueOnError: true # Keep running subsequent tasks even if this one fails (e.g. the tinylicious log wasn't there)
                      inputs:
                        targetType: inline
                        script: |
                          PATH_TO_TINYLICIOUS_LOG=$(Build.SourcesDirectory)/packages/test/test-end-to-end-tests/tinylicious.log;
                          if [ -f $PATH_TO_TINYLICIOUS_LOG ] ; then
                            echo "Found file at '$PATH_TO_TINYLICIOUS_LOG'. Uploading.";
                            echo "##vso[task.uploadfile]$PATH_TO_TINYLICIOUS_LOG";
                          else
                            echo "##vso[task.logissue type=warning]Failed to upload tinylicious log file ('$PATH_TO_TINYLICIOUS_LOG' not found).";
                          fi

                    # At this point we want to publish the tinylicious.log artifact, but as part of 1ES migration
                    # that is now part of templateContext.outputs below.

                  # Test - Upload coverage results
                  # Some webpacked file using externals introduce file name with quotes in them
                  # and Istanbul's cobertura reporter doesn't escape them causing parse error when we publish
                  # A quick fix to patch the file with sed. (See https://github.com/bcoe/c8/issues/302)
                  - ${{ if parameters.testCoverage }}:
                      - task: Bash@3
                        displayName: Check for nyc/report directory
                        inputs:
                          targetType: 'inline'
                          workingDirectory: '${{ parameters.buildDirectory }}'
                          script: |
                            test -d nyc/report && echo '##vso[task.setvariable variable=ReportDirExists;]true' || echo 'No nyc/report directory'
                        condition: and(succeededOrFailed(), eq(variables['startTest'], 'true'))
                      - task: Bash@3
                        displayName: Patch Coverage Results
                        inputs:
                          targetType: 'inline'
                          workingDirectory: '${{ parameters.buildDirectory }}/nyc/report'
                          script: |
                            sed -e 's/\(filename=\".*[\\/]external .*\)"\(.*\)""/\1\&quot;\2\&quot;"/' cobertura-coverage.xml > cobertura-coverage-patched.xml
                        condition: and(succeededOrFailed(), eq(variables['ReportDirExists'], 'true'))
                      - task: PublishCodeCoverageResults@2
                        displayName: Publish Code Coverage
                        inputs:
                          summaryFileLocation: ${{ parameters.buildDirectory }}/nyc/report/cobertura-coverage-patched.xml
                          failIfCoverageEmpty: true
                        condition: and(succeededOrFailed(), eq(variables['ReportDirExists'], 'true'))

                  # Process test result, include publishing and logging
                  - template: /tools/pipelines/templates/include-process-test-results.yml@self
                    parameters:
                      buildDirectory: '${{ parameters.buildDirectory }}'
                      testResultDirs: '${{ parameters.testResultDirs }}'

              # Pack
              - ${{ if ne(parameters.taskPack, false) }}:
                  - task: Bash@3
                    displayName: npm pack
                    env:
                      PACKAGE_MANAGER: '${{ parameters.packageManager }}'
                      RELEASE_GROUP: '${{ parameters.tagName }}'
                      STAGING_PATH: $(Build.ArtifactStagingDirectory)
                    inputs:
                      targetType: filePath
                      workingDirectory: '${{ parameters.buildDirectory }}'
                      filePath: $(Build.SourcesDirectory)/scripts/pack-packages.sh

                  # At this point we want to publish the artifact with npm-packed packages, and the one with test files,
                  # but as part of 1ES migration that's now part of templateContext.outputs below.

              # Collect/publish/run bundle analysis
              - ${{ if eq(parameters.taskBundleAnalysis, true) }}:
                  - task: Npm@1
                    displayName: 'npm run bundle-analysis:collect'
                    inputs:
                      command: custom
                      workingDir: '${{ parameters.buildDirectory }}'
                      customCommand: 'run bundle-analysis:collect'

                  # Copy files so all artifacts we publish end up under the same parent folder.
                  # The sourceFolder should be wherever the 'npm run bundle-analysis:collect' task places its output.
                  - task: CopyFiles@2
                    displayName: Copy _api-extractor-temp files to artifact staging directory
                    inputs:
                      sourceFolder: '${{ parameters.buildDirectory }}/artifacts/bundleAnalysis'
                      targetFolder: $(Build.ArtifactStagingDirectory)/bundleAnalysis


                  # At this point we want to publish the artifact with the bundle size analysis,
                  # but as part of 1ES migration that's now part of templateContext.outputs below.

                  - task: Npm@1
                    displayName: run bundle size comparison
                    condition: and(succeeded(), eq(variables['Build.Reason'], 'PullRequest'))
                    continueOnError: true
                    env:
                      ADO_API_TOKEN: $(System.AccessToken)
                      DANGER_GITHUB_API_TOKEN: $(githubPublicRepoSecret)
                      TARGET_BRANCH_NAME: '$(targetBranchName)'
                    inputs:
                      command: custom
                      workingDir: '${{ parameters.buildDirectory }}'
                      customCommand: 'run bundle-analysis:run'

                  - ${{ if and(or(eq(variables['Build.Reason'], 'IndividualCI'), eq(variables['Build.Reason'], 'BatchedCI')), eq(variables['System.TeamProject'], 'internal')) }}:
                      - task: Bash@3
                        displayName: List report.json
                        inputs:
                          targetType: inline
                          workingDirectory: '${{ parameters.buildDirectory }}'
                          script: |
                            echo "Build Directory is ${{ parameters.buildDirectory }}";
                            BUNDLE_SIZE_TESTS_DIR="${{ parameters.buildDirectory }}/artifacts/bundleAnalysis/@fluid-example/bundle-size-tests";
                            echo "Contents of $BUNDLE_SIZE_TESTS_DIR:";
                            ls -la $BUNDLE_SIZE_TESTS_DIR;

                      - template: /tools/pipelines/templates/include-telemetry-setup.yml@self
                        parameters:
                          devFeedUrl: $(ado-feeds-dev)
                          officeFeedUrl: $(ado-feeds-office)

                      - task: Bash@3
                        displayName: Write bundle sizes measurements to Aria/Kusto
                        inputs:
                          targetType: inline
                          workingDirectory: $(absolutePathToTelemetryGenerator)
                          script: |
                            echo "Writing the following performance tests results to Aria/Kusto"
                            echo "Report Size:"
                            ls -la '../../examples/utils/bundle-size-tests/bundleAnalysis/report.json';
                            node --require @ff-internal/aria-logger bin/run --handlerModule $(absolutePathToTelemetryGenerator)/dist/handlers/bundleSizeHandler.js --dir '../../artifacts/bundleAnalysis/@fluid-example/bundle-size-tests';

              # Docs
              - ${{ if ne(parameters.taskBuildDocs, false) }}:
                  - task: Npm@1
                    displayName: 'npm run ci:build:docs'
                    inputs:
                      command: custom
                      workingDir: '${{ parameters.buildDirectory }}'
                      customCommand: 'run ci:build:docs'

                  # Copy files so all artifacts we publish end up under the same parent folder.
                  # The sourceFolder should be wherever the 'npm run ci:build:docs' task places its output.
                  - task: CopyFiles@2
                    displayName: Copy _api-extractor-temp files to artifact staging directory
                    inputs:
                      sourceFolder: '${{ parameters.buildDirectory }}/_api-extractor-temp'
                      targetFolder: $(Build.ArtifactStagingDirectory)/_api-extractor-temp

                  # At this point we want to publish the artifact with the _api-extractor-temp folder,
                  # but as part of 1ES migration that's now part of templateContext.outputs below.

              - ${{ if eq(parameters.packageManager, 'pnpm') }}:
                # Reset the pnpm-lock.yaml file since it's been modified by the versioning. But for dependency caching we want
                # the cache key (which is based on the contents of the lockfile) to be the unmodified file. So we reset the
                # lockfile as the last step so that when the dependency cache is uploaded, the cache key matches what it was
                # at the beginning of the CI job.
                - task: Bash@3
                  displayName: Reset lockfile
                  inputs:
                    targetType: inline
                    workingDirectory: '${{ parameters.buildDirectory }}'
                    script: |
                      git checkout HEAD -- pnpm-lock.yaml

                # Prune the pnpm store before it's cached. This removes any deps that are not used by the current build.
                - task: Bash@3
                  displayName: Prune pnpm store
                  inputs:
                    targetType: inline
                    workingDirectory: '${{ parameters.buildDirectory }}'
                    script: |
                      pnpm store prune

              - task: Bash@3
                displayName: Check for extraneous modified files
                inputs:
                  targetType: inline
                  script: |
                    git status | grep -v -E 'package.json|package-lock.json|packageVersion.ts|lerna.json|.npmrc|build-tools/.npmrc|\(use.*' | grep '^\s' > git_status.log
                    if [ `cat git_status.log | wc -l` != "0" ]; then
                      cat git_status.log
                      echo "##vso[task.logissue type=error]Build should not create extraneous files"
                      exit -1;
                    fi

              # This additional build step is used to run step not part of the main build. In build client pipeline,
              # this is used to inject telemetry key file and upload built devtools extension.
              - ${{ parameters.additionalBuildSteps }}

            templateContext:
              outputParentDirectory: $(Build.ArtifactStagingDirectory)
              outputs:
                - ${{ if ne(parameters.taskPack, false) }}:
                    - output: pipelineArtifact
                      displayName: Publish Artifact - pack
                      targetPath: $(Build.ArtifactStagingDirectory)/pack
                      artifactName: pack
                      publishLocation: pipeline

                    - output: pipelineArtifact
                      displayName: Publish Artifact - Test Files
                      targetPath: $(Build.ArtifactStagingDirectory)/test-files
                      artifactName: test-files
                      publishLocation: pipeline
                      sbomEnabled: false

                - ${{ if eq(parameters.taskBundleAnalysis, true) }}:
                    - output: pipelineArtifact
                      displayName: Publish Artifacts - bundle-analysis
                      condition: and( succeeded(), ne(variables['Build.Reason'], 'PullRequest'), eq(${{ parameters.taskPublishBundleSizeArtifacts }}, true) )
                      targetPath: $(Build.ArtifactStagingDirectory)/bundleAnalysis
                      artifactName: bundleAnalysis
                      sbomEnabled: false
                      publishLocation: pipeline

                - ${{ if or(eq(parameters.publishDocs, true), eq(parameters.taskBuildDocs, true)) }}:
                    - output: pipelineArtifact
                      displayName: Publish Artifact - _api-extractor-temp
                      targetPath: $(Build.ArtifactStagingDirectory)/_api-extractor-temp
                      artifactName: _api-extractor-temp
                      sbomEnabled: false
                      publishLocation: pipeline

                # This condition should be kept in sync with the one in include-set-package-version, which decides if
                # upload-dev-manifest.yml should be included or not.
                - ${{ if and(eq(variables['System.TeamProject'], 'internal'), eq(parameters.tagName, 'client'), or(eq(variables['Build.SourceBranch'], 'refs/heads/main'), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'))) }}:
                  - output: pipelineArtifact
                    displayName: Publish Artifact - release_reports
                    targetPath: $(Build.ArtifactStagingDirectory)/release_reports
                    artifactName: release_reports
                    sbomEnabled: false
                    publishLocation: pipeline

      # Publish stage
      - ${{ if eq(parameters.publish, true) }}:
        - template: include-publish-npm-package.yml
          parameters:
            tagName: ${{ parameters.tagName }}
            isReleaseGroup: ${{ parameters.isReleaseGroup }}

      # Capture pipeline stage results
      - ${{ if eq(parameters.telemetry, true) }}:
        - stage: upload_run_telemetry
          displayName: Upload pipeline run telemetry to Kusto
          condition: succeededOrFailed()
          dependsOn:
            - build
            # NOTE: This is brittle; we need to only apply these stage dependencies when the corresponding stages actually
            # get created in the pipeline, in the include-publish-npm-package.yml file, so we want to match the compile-time
            # conditions *and exact stage names* that exist there. At some point it might be preferable to always create the
            # stages, control their execution with 'condition:', and update this stage to always depend on all previous
            # stages (while still running if some of the dependencies were skipped).
            - ${{ if eq(parameters.publish, true) }}:
              - ${{ if eq(variables['testBuild'], true) }}:
                - publish_npm_internal_test
              - ${{ if eq(variables['testBuild'], false) }}:
                - publish_npm_internal_build
              - ${{ if and(eq(variables['testBuild'], false), eq(parameters.isReleaseGroup, true)) }}:
                - publish_npm_internal_dev
              - ${{ if or(eq(variables['release'], 'release'), eq(variables['release'], 'prerelease')) }}:
                - publish_npm_public
          jobs:
            - job: upload_run_telemetry
              displayName: Upload pipeline run telemetry to Kusto
              pool: Small-1ES
              variables:
              - group: ado-feeds
              - name: pipelineTelemetryWorkdir
                value: $(Pipeline.Workspace)/pipelineTelemetryWorkdir
                readonly: true
              - name: absolutePathToTelemetryGenerator
                value: $(Build.SourcesDirectory)/tools/telemetry-generator
                readonly: true
              steps:
              - template: /tools/pipelines/templates/include-telemetry-setup.yml@self
                parameters:
                  devFeedUrl: $(ado-feeds-dev)
                  officeFeedUrl: $(ado-feeds-office)
                  isCheckoutNeeded: true
              - task: Bash@3
                displayName: Retrieve buildId results
                inputs:
                  targetType: inline
                  workingDirectory: $(absolutePathToTelemetryGenerator)
                  script: |
                    echo "Creating output folder ..."
                    mkdir -p $(pipelineTelemetryWorkdir)/timingOutput
                    echo "Retrieving pipeline run timeline data ..."
                    echo 'curl -u ":<REDACTED>" "https://dev.azure.com/fluidframework/internal/_apis/build/builds/$BUILD_ID/timeline"'
                    curl -u ":$ADO_API_TOKEN" "https://dev.azure.com/fluidframework/internal/_apis/build/builds/$BUILD_ID/timeline\?api-version\=6.0-preview.1" > $(pipelineTelemetryWorkdir)/timingOutput/output.json
                    pwd;
                    ls -laR $(pipelineTelemetryWorkdir)/timingOutput/output.json;
                    cat $(pipelineTelemetryWorkdir)/timingOutput/output.json;
                    node --require @ff-internal/aria-logger bin/run --handlerModule $(absolutePathToTelemetryGenerator)/dist/handlers/stageTimingRetriever.js --dir '$(pipelineTelemetryWorkdir)/timingOutput/';
                env:
                  BUILD_ID: $(Build.BuildId)
                  ADO_API_TOKEN: $(System.AccessToken)
                  PIPELINE: BuildClient
