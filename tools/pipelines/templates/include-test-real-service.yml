# Copyright (c) Microsoft Corporation and contributors. All rights reserved.
# Licensed under the MIT License.

# include-test-real-service

parameters:
# Id for the stage that runs tests
- name: stageId
  type: string

# Display name for the stage that runs tests
- name: stageDisplayName
  type: string

# The stage that runs tests will have its dependsOn property set to this value
- name: stageDependencies
  type: object
  default: []

# Variables to be set in the stage that runs tests
- name: stageVariables
  type: object
  default:

# If true, the stage that uploads pipeline telemetry to Kusto will include a task to upload
# test pass rate telemetry.
- name: uploadTestPassRateTelemetry
  type: boolean
  default: false

# Unique identifier used to identify telemetry data in Kusto for this pipeline
- name: pipelineIdentifierForTelemetry
  type: string

- name: poolBuild
  type: object
  default: Small-eastus2

- name: testPackage
  type: string
  default: "@fluid-private/test-end-to-end-tests"

- name: testWorkspace
  type: string

- name: timeoutInMinutes
  type: number
  default: 60

- name: env
  type: object
  default:

- name: splitTestVariants
  type: object
  default:
  - name: ""
    flags: ""

- name: testCommand
  type: string

- name: continueOnError
  type: boolean
  default: false

- name: testFileTarName
  type: string
  default: null

# Id of the pipeline run that contains the artifacts to download.
# Needed to workaround a bug in the DownloadPipelineArtifact task that might cause artifacts to be downloaded from the
# incorrect pipeline run (see https://github.com/microsoft/azure-pipelines-tasks/issues/13518).
- name: artifactBuildId
  type: string

# Name of the Secure File that contains the self-signed cert for the R11s deployment.
# If not blank, the pipeline will try to install it to the local cert store.
- name: r11sSelfSignedCertSecureFile
  type: string
  default: ""

- name: condition
  type: string
  default: true

- name: loggerPackage
  type: string
  default: '@ff-internal/aria-logger'

- name: tenantSetupPackage
  type: string
  default: '@ff-internal/trips-setup'

# If true, skip publishing report files for test results.
# Useful because our stress tests pipeline doesn't generate any test result files.
- name: skipTestResultPublishing
  type: boolean
  default: false

# Custom steps specified by the "caller" of this template, for any additional things that need to be done
# after the steps in this template complete.
- name: additionalSteps
  type: stepList
  default: []

# If true, the versions of our packages installed for compat testing will be cached.
- name: cacheCompatVersionsInstalls
  type: boolean
  default: false

# If tests need to run against an ODSP tenant, specify the type of tenant here. Steps will be injected to lease one for the duration of the test.
- name: odspTenantType
  type: string
  default: none
  values:
    - none
    - prod
    - dogfood

# lockBehavior of the stage (if any).
- name: lockBehavior
  type: string
  default: none
  values:
    - none
    - sequential

stages:
- stage: ${{ parameters.stageId}}
  ${{ if ne(parameters.lockBehavior, 'none') }}:
    lockBehavior: ${{ parameters.lockBehavior }}
  condition: ${{ parameters.condition }}
  displayName: ${{ parameters.stageDisplayName }}
  dependsOn: ${{ parameters.stageDependencies }}
  ${{ if parameters.stageVariables }}:
    variables:
      ${{ parameters.stageVariables }}
  jobs:
    - ${{ each variant in parameters.splitTestVariants }}:
      - job:
        displayName: Run ${{ variant.name }}
        pool: ${{ parameters.poolBuild }}
        timeoutInMinutes: ${{ parameters.timeoutInMinutes }}
        variables:
        - group: ado-feeds
        - name: isTestBranch
          value: ${{ startsWith(variables['Build.SourceBranch'], 'refs/heads/test/') }}
          readonly: true
        # We use 'chalk' to colorize output, which auto-detects color support in the
        # running terminal.  The log output shown in Azure DevOps job runs only has
        # basic ANSI color support though, so force that in the pipeline
        - name: FORCE_COLOR
          value: 1
        - name: testPackageDir
          value: '$(Build.SourcesDirectory)/node_modules/${{ parameters.testPackage }}'
        - name: testPackageFilePattern
          value: ${{ replace(replace(parameters.testPackage, '@', '' ), '/', '-') }}-[0-9]*.tgz
        # Note that this path must match the path that the packed packages are saved to in the build pipeline.
        # It should be kept up to date with the path defined in scripts/pack-packages.sh.
        - name: testPackagePathPattern
          value: $(Pipeline.Workspace)/client/pack/tarballs/${{ variables.testPackageFilePattern }}
        - name: skipComponentGovernanceDetection
          value: true
        - name: artifactPipeline
          value: Build - client packages

        steps:
        # Setup
        - checkout: PipelineHost
          clean: true

        # Install self-signed cert for R11s deployment in local cert store
        - ${{ if ne(parameters.r11sSelfSignedCertSecureFile, '') }}:
          - task: DownloadSecureFile@1
            displayName: 'Download r11s self-signed cert'
            name: downloadCertTask
            inputs:
              secureFile: ${{ parameters.r11sSelfSignedCertSecureFile }}
              retryCount: '2'

          - task: Bash@3
            displayName: 'Install r11s self-signed cert in local cert store'
            inputs:
              targetType: 'inline'
              script: |
                set -eu -o pipefail

                # Extract public part from cert
                openssl x509 -in $(downloadCertTask.secureFilePath) -out cert.crt
                # Install cert
                sudo cp cert.crt /usr/local/share/ca-certificates/
                sudo update-ca-certificates

        # Print parameters/Vars
        # Variables declared outside this template will only work with "macro syntax": $(name).
        # Variables declared inside this template also work with "template expression syntax": ${{ variables.name }}.
        - task: Bash@3
          displayName: Print Parameters and Variables
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail

              # Show all task group conditions

              echo "
              Pipeline Parameters:
                poolBuild=${{ parameters.poolBuild }}
                testPackage=${{ parameters.testPackage }}

              Pipeline Variables:
                isTestBranch=${{ variables.isTestBranch }}
                testWorkspace=${{ parameters.testWorkspace }}
                testPackageFilePattern=${{ variables.testPackageFilePattern }}
                testCommand=${{ parameters.testCommand }}
                continueOnError=${{ parameters.continueOnError }}
                variant.flag=${{ variant.flags }}
                testFileTarName=${{ parameters.testFileTarName }}
                artifactPipeline=${{ variables.artifactPipeline }}
                artifactBuildId=${{ parameters.artifactBuildId }}
              "

        - template: /tools/pipelines/templates/include-use-node-version.yml@self

        - template: /tools/pipelines/templates/include-install-pnpm.yml@self
          parameters:
            buildDirectory: $(Build.SourcesDirectory)

        - template: /tools/pipelines/templates/include-setup-npmrc-for-download.yml@self

        - task: Bash@3
          displayName: Install base dependencies
          inputs:
            targetType: 'inline'
            script: |
              set -eu -o pipefail
              pnpm install

        # Download artifact
        - task: DownloadPipelineArtifact@2
          displayName: Download test package
          inputs:
            source: specific
            project: internal
            pipeline: ${{ variables.artifactPipeline }}
            buildVersionToDownload: specific
            buildId: ${{ parameters.artifactBuildId }}
            artifact: pack
            patterns: "**/${{ variables.testPackageFilePattern }}"
            path: $(Pipeline.Workspace)/client/pack
            # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
            # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific
            # It seems there's a bug and preferTriggeringPipeline is not respected.
            # We force the behavior by explicitly specifying:
            # - buildVersionToDownload: specific
            # - buildId: <the id of the triggering build>
            # preferTriggeringPipeline: true

        - task: Bash@3
          name: Initialize
          displayName: Initialize
          inputs:
            targetType: 'inline'
            workingDirectory: $(Build.SourcesDirectory)
            script: |
              set -eu -o pipefail
              if [[ `ls -1 ${{ variables.testPackagePathPattern }} | wc -l` -eq 1 ]]; then
                echo "##vso[task.setvariable variable=testPackageTgz;isOutput=true]`ls ${{ variables.testPackagePathPattern }}`"
              else
                ls -1 ${{ variables.testPackagePathPattern }}
                echo "##vso[task.logissue type=error]Test package '${{ parameters.testPackage }}' not found, or there are more than one found"
                exit -1
              fi
        # Install test package
        - task: Bash@3
          displayName: 'pnpm install'
          # ADO feeds have latency on the order of minutes before packages are available downstream. See:
          # https://learn.microsoft.com/en-us/azure/devops/artifacts/concepts/upstream-sources?view=azure-devops#upstream-sources-health-status
          # This pipeline installs packages which were published very recently relative to its runtime, hence the rather high retry count here.
          retryCountOnTaskFailure: 10
          inputs:
            targetType: 'inline'
            script: 'pnpm install $(Initialize.testPackageTgz)'

        # Download Test Files & Install Extra Dependencies
        # These steps are intended to include extra dependencies that are not available as
        # part of the normal package .tgz installed previously in the pipeline.
        - ${{ if ne(parameters.testFileTarName, 'null') }}:
          # Download Artifact - Test Files
          - task: DownloadPipelineArtifact@2
            displayName: Download test files
            inputs:
              source: specific
              project: internal
              pipeline: ${{ variables.artifactPipeline }}
              buildVersionToDownload: specific
              buildId: ${{ parameters.artifactBuildId }}
              artifact: test-files
              path: $(Pipeline.Workspace)/test-files
              # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
              # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific
              # It seems there's a bug and preferTriggeringPipeline is not respected.
              # We force the behavior by explicitly specifying:
              # - buildVersionToDownload: specific
              # - buildId: <the id of the triggering build>
              # preferTriggeringPipeline: true

          # Unpack test files
          - task: Bash@3
            displayName: Unpack test files
            inputs:
              workingDirectory: $(Build.SourcesDirectory)/node_modules/${{ parameters.testPackage }}
              targetType: 'inline'
              script: |
                set -eu -o pipefail

                TAR_PATH=$(Pipeline.Workspace)/test-files/${{ parameters.testFileTarName }}.test-files.tar
                echo "Unpacking test files for ${{ parameters.testPackage }} from file '$TAR_PATH' in '$(pwd)'"
                # Note: we could skip the last argument and have it unpack everything at once, but if we later change
                # the structure/contents of the tests tar file, the extraction could overwrite things we didn't intend to,
                # so keeping the paths to extract explicit.
                # Also, extracting is finicky with the exact format of the last argument, it needs to match how the
                # tarfile was created (e.g. './lib/test' works here but 'lib/test' does not).
                tar --extract --verbose --file $TAR_PATH ./lib/test
                tar --extract --verbose --file $TAR_PATH ./dist/test
                tar --extract --verbose --file $TAR_PATH ./src/test

          - template: /tools/pipelines/templates/include-copy-dev-dependencies.yml@self
            parameters:
              sourcePackageLocation: $(Build.SourcesDirectory)/node_modules/${{ parameters.testPackage }}
              destPackageLocation: $(Build.SourcesDirectory)

        - ${{ if eq(parameters.cacheCompatVersionsInstalls, true) }}:
          - task: Bash@3
            displayName: Compute compat versions install location and version
            inputs:
              targetType: 'inline'
              workingDirectory: $(Build.SourcesDirectory)/node_modules/@fluid-private/test-end-to-end-tests
              # Using import.meta.resolve to compute this is more resilient to different install tree types.
              # Also note that test-version-utils is esm-only, so cannot be loaded with require.
              script: |
                set -eu -o pipefail
                node --input-type=module -e "
                  import { createRequire } from 'module';
                  const require = createRequire(import.meta.url);
                  const path = require('path');
                  const versionUtilsIndexUrl = await import.meta.resolve('@fluid-private/test-version-utils');
                  const basePath = new URL(versionUtilsIndexUrl.replace('/lib/index.js', '')).pathname;
                  const legacyModulesPath = path.join(basePath, 'node_modules', '.legacy');
                  console.log('Resolved @fluid-private/test-version-utils legacy modules to ' + legacyModulesPath);
                  console.log('##vso[task.setvariable variable=compatVersionInstallsPath]' + legacyModulesPath);
                  const packageJsonPath = path.join(basePath, 'package.json');
                  const packageJson = require(packageJsonPath);
                  const packageVersion = packageJson.version;
                  const [major, minor] = packageVersion.split('.');
                  const cacheKey = 'major:' + major + ',minor:' + minor;
                  console.log('Computed compat version cache key: ' + cacheKey);
                  console.log('##vso[task.setvariable variable=compatVersionCacheKey;]'+ cacheKey);
                "

          - task: Cache@2
            displayName: Cache compat versions install location
            timeoutInMinutes: 3
            continueOnError: true
            inputs:
              key: '"compat-version-installs" | "$(Agent.OS)" | "${{ parameters.testCommand }}" | "${{ variant.name }}" |  $(compatVersionCacheKey)'
              path: $(compatVersionInstallsPath)

        # Only check out tenants from the tenant pool if we are running tests against ODSP
        - ${{ if ne(parameters.odspTenantType, 'none') }}:
          # Retrieve a tenant from the tenant pool
          - task: AzureCLI@2
            displayName: 'Log in to retrieve tenant credentials'
            inputs:
              azureSubscription: 'Fluid Framework Tests'
              # This injects environment variables into the below script. See https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/reference/azure-cli-v2?view=azure-pipelines
              addSpnToEnvironment: true
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                set -eu -o pipefail

                az login --service-principal -u $servicePrincipalId -p $idToken --tenant $tenantId

          - task: Bash@3
            displayName: 'Run tenant setup script'
            env:
              SYSTEM_ACCESSTOKEN: $(System.AccessToken)
            inputs:
              targetType: 'inline'
              script: |
                set -eu -o pipefail

                # Increase the maximum time to wait for a tenant to 1 hour to accommodate multiple test runs at the same time.
                pnpm exec trips-setup --waitTime=3600 --accessToken=$SYSTEM_ACCESSTOKEN --odspEndpoint=${{ parameters.odspTenantType }}
                echo "##vso[task.setvariable variable=tenantSetupSuccess;]true"

        # run the test
        - task: Npm@1
          displayName: '[test] ${{ parameters.testCommand }} ${{ variant.flags }}'
          continueOnError: ${{ parameters.continueOnError }}
          env:
            ${{ each pair in parameters.env }}:
              ${{ pair.key }}: ${{ pair.value }}
            # ODSP tenant setup script injects the values here (appClientId, tenantCreds).
            # The e2e test workload references the keys (login__*).
            ${{ if eq(parameters.odspTenantType, 'dogfood') }}:
              login__microsoft__clientId: $(appClientId)
              login__odspdf__test__tenants: $(tenantCreds)
            ${{ elseif eq(parameters.odspTenantType, 'prod') }}:
              login__microsoft__clientId: $(appClientId)
              login__odsp__test__tenants: $(tenantCreds)
          inputs:
            command: 'custom'
            workingDir: $(Build.SourcesDirectory)/node_modules/${{ parameters.testPackage }}
            customCommand: 'run ${{ parameters.testCommand }} -- ${{ variant.flags }}'

        - ${{ if eq(parameters.skipTestResultPublishing, false) }}:
          # filter report
          - task: Bash@3
            displayName: Filter skipped test from report
            condition: succeededOrFailed()
            inputs:
              targetType: 'inline'
              script: |
                set -eu -o pipefail

                if [[ -d ${{ variables.testPackageDir }}/nyc ]]; then
                  echo "directory '${{ variables.testPackageDir }}/nyc' exists."
                  cd ${{ variables.testPackageDir }}/nyc
                  if ! [[ -z "$(ls -A .)" ]]; then
                    curdirfiles=`ls`
                    echo "report file(s) ${curdirfiles} found. Filtering skipped tests..."
                    for i in `ls`; do sed -i '/<skipped/d' $i; done
                  else
                    echo "No report files found in '${{ variables.testPackageDir }}/nyc'"
                  fi
                else
                  echo "Directory '${{ variables.testPackageDir }}/nyc' not found"
                fi

          # Upload results
          - task: PublishTestResults@2
            displayName: Publish Test Results
            inputs:
              testResultsFormat: 'JUnit'
              testResultsFiles: '**/*junit-report.xml'
              searchFolder: ${{ variables.testPackageDir }}/nyc
              mergeTestResults: false
            condition: succeededOrFailed()

        # Publish tinylicious log for troubleshooting
        - ${{ if or(contains(convertToJson(parameters.testCommand), 'tinylicious'), contains(convertToJson(parameters.testCommand), 't9s')) }}:
          - task: PublishPipelineArtifact@1
            displayName: Publish Artifact - Tinylicious Log
            inputs:
              targetPath: '$(Build.SourcesDirectory)/node_modules/${{ parameters.testPackage }}/tinylicious.log'
              artifactName: 'tinyliciousLog_attempt-$(System.JobAttempt)'
              publishLocation: 'pipeline'
            condition: always()
            continueOnError: true # Keep running subsequent tasks even if this one fails (e.g. the tinylicious log wasn't there)

        # Only release tenants that were checked out from the tenant pool for ODSP/ODSPDF tests
        - ${{ if ne(parameters.odspTenantType, 'none') }}:
          # Login to release tenant credentials
          # Currently, some of the compat tests run for longer than 60 minutes and exceed the average token lifetime:
          # https://learn.microsoft.com/en-us/entra/identity-platform/configurable-token-lifetimes#access-tokens
          - task: AzureCLI@2
            displayName: 'Log in to release tenant credentials'
            inputs:
              azureSubscription: 'Fluid Framework Tests'
              addSpnToEnvironment: true
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                set -eu -o pipefail

                az login --service-principal -u $servicePrincipalId -p $idToken --tenant $tenantId
            condition: eq(variables['tenantSetupSuccess'], 'true')

          # Release the tenant back to the tenant pool
          - task: Bash@3
            displayName: 'Release tenant credentials'
            inputs:
              targetType: 'inline'
              script: |
                set -eu -o pipefail
                pnpm exec trips-cleanup --reservationId=$(stringBearerToken) --odspEndpoint=${{ parameters.odspTenantType }}
            condition: eq(variables['tenantSetupSuccess'], 'true')

        # Log Test Failures
        # - template: /tools/pipelines/templates/include-process-test-results.yml@self
        #   parameters:
        #     buildDirectory: ${{ variables.testPackageDir }}

        - ${{ parameters.additionalSteps }}

        - template: /tools/pipelines/templates/include-upload-npm-logs.yml@self

- template: /tools/pipelines/templates/include-upload-stage-telemetry.yml@self
  parameters:
    stageId: ${{ parameters.stageId }}
    uploadTestPassRateTelemetry: ${{ parameters.uploadTestPassRateTelemetry }}
    pipelineIdentifierForTelemetry: ${{ parameters.pipelineIdentifierForTelemetry }}
    testWorkspace: $(Build.SourcesDirectory)
