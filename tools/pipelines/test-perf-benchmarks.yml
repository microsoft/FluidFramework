# Copyright (c) Microsoft Corporation and contributors. All rights reserved.
# Licensed under the MIT License.

name: $(Build.BuildId)

trigger: none
pr: none

resources:
  pipelines:
  - pipeline: client   # Name of the pipeline resource
    source: Build - client packages
    branch: main # Default branch for manual/scheduled triggers if none is selected
    trigger:
      branches:
      - release/*
      - main
      - next
      - lts

parameters:

- name: poolBuild
  type: object
  default: Large

- name: memoryTestPackages
  type: object
  default:
    - "@fluidframework/sequence"
    - "@fluidframework/map"
    - "@fluidframework/matrix"

- name: executionTestPackages
  type: object
  default:
    - "@fluid-internal/tree"
    - "@fluid-experimental/tree"

variables:
  # We use 'chalk' to colorize output, which auto-detects color support in the
  # running terminal.  The log output shown in Azure DevOps job runs only has
  # basic ANSI color support though, so force that in the pipeline
  - name: FORCE_COLOR
    value: 1
    readonly: true
  - name: testWorkspace
    value: $(Pipeline.Workspace)/test
    readonly: true
  - name: artifactPipeline
    value: $(resources.pipeline.client.pipelineName)
    readonly: true
  - name: artifactBuildId
    value: $(resources.pipeline.client.runID)
    readonly: true
  - name: toolAbsolutePath
    value: $(Build.SourcesDirectory)/tools/telemetry-generator
    readonly: true

stages:
  # Performance unit tests - runtime
  - stage: perf_unit_tests_runtime
    displayName: Perf unit tests - runtime
    dependsOn: []
    variables:
      - name: consolidatedTestsOutputFolder
        value: ${{ variables.testWorkspace }}/benchmarkOutput
        readonly: true
    jobs:
    - template: templates/include-test-perf-benchmarks.yml
      parameters:
        poolBuild: ${{ parameters.poolBuild }}
        testWorkspace: ${{ variables.testWorkspace }}
        artifactPipeline: ${{ variables.artifactPipeline }}
        customSteps:

        # Download artifact with test files
        - task: DownloadPipelineArtifact@2
          displayName: Download test files
          inputs:
            # It seems there's a bug and preferTriggeringPipeline is not respected.
            # We force the behavior by explicitly specifying:
            # - buildVersionToDownload: specific
            # - buildId: <the id of the triggering build>
            # preferTriggeringPipeline: true
            source: specific
            project: internal
            pipeline: ${{ variables.artifactPipeline }}
            buildVersionToDownload: specific
            buildId: ${{ variables.artifactBuildId }}
            artifact: test-files
            path: $(Pipeline.Workspace)/test-files/
            # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
            # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

        # Run tests for each package that has them
        - ${{ each testPackage in parameters.executionTestPackages }}:

          # Download artifact for package to be tested
          - task: DownloadPipelineArtifact@2
            displayName: Download test package
            inputs:
              # It seems there's a bug and preferTriggeringPipeline is not respected.
              # We force the behavior by explicitly specifying:
              # - buildVersionToDownload: specific
              # - buildId: <the id of the triggering build>
              # preferTriggeringPipeline: true
              source: specific
              project: internal
              pipeline: ${{ variables.artifactPipeline }}
              buildVersionToDownload: specific
              buildId: ${{ variables.artifactBuildId }}
              artifact: pack
              patterns: "**/${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz"
              path: $(Pipeline.Workspace)/client/pack
              # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
              # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

          # Install package to be tested
          - task: Bash@3
            displayName: Install test package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}
              script: |
                echo "Install ${{ testPackage }}"
                TEST_PACKAGE_FILE_PATTERN=${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz
                TEST_PACKAGE_PATH_PATTERN=$(Pipeline.Workspace)/client/pack/scoped/$TEST_PACKAGE_FILE_PATTERN

                echo $TEST_PACKAGE_FILE_PATTERN
                echo $TEST_PACKAGE_PATH_PATTERN

                echo `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l`
                echo `ls $TEST_PACKAGE_PATH_PATTERN`

                if [[ `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l` -eq 1 ]]; then
                  TEST_PACKAGE_TGZ=`ls $TEST_PACKAGE_PATH_PATTERN`
                else
                  ls -1 $TEST_PACKAGE_PATH_PATTERN
                  echo "##vso[task.logissue type=error]Test package '${{ testPackage }}' not found, or there are more then one found"
                  exit -1
                fi

                npm install $TEST_PACKAGE_TGZ

          # Unpack test files
          - task: Bash@3
            displayName: Unpack test files
            inputs:
              targetType: 'inline'
              script: |
                echo "Unpack test files for ${{ testPackage }}"
                TAR_FILE=${{ replace(replace(replace(replace(testPackage, '@fluidframework/', '' ), '@fluid-internal/', '' ),'@fluid-', '' ), '/', '-') }}
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test
                tar -xvf $(Pipeline.Workspace)/test-files/$TAR_FILE.test-files.tar -C $(Pipeline.Workspace)/test-files
                mv $(Pipeline.Workspace)/test-files/dist/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test
                mv $(Pipeline.Workspace)/test-files/src/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test

          # Run tests
          - task: Bash@3
            displayName: Run execution-time tests
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}
              script: |
                echo "Run execution-time tests for ${{ testPackage }}"
                cp ${{ variables.testWorkspace }}/.npmrc . ;
                npm i;
                npm run test:benchmark:report;

          # Consolidate output files
          - task: CopyFiles@2
            displayName: Consolidate output files
            inputs:
              sourceFolder: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/node_modules/@fluid-tools/benchmark/dist/.output/
              contents: '**'
              targetFolder: ${{ variables.consolidatedTestsOutputFolder }}/${{ testPackage }}

          # Cleanup package
          - task: Bash@3
            displayName: Cleanup package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/
              script: |
                echo "Cleanup package ${{ testPackage }} from ${{ variables.testWorkspace }}/node_modules/"
                rm -rf ${{ testPackage }};

        - task: Bash@3
          displayName: Write measurements to Aria/Kusto
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Write the following benchmark output to Aria/Kusto"
              ls -laR ${{ variables.consolidatedTestsOutputFolder }};
              node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/executionTimeTestHandler.js --dir '${{ variables.consolidatedTestsOutputFolder }}';

        - task: PublishPipelineArtifact@1
          displayName: Publish Artifact - Perf tests output - execution time
          inputs:
            targetPath: '${{ variables.consolidatedTestsOutputFolder }}'
            artifactName: 'perf-test-outputs_execution-time'
          condition: succeededOrFailed()

  # Performance unit tests - memory
  - stage: perf_unit_tests_memory
    displayName: Perf unit tests - memory
    dependsOn: []
    variables:
      - name: consolidatedTestsOutputFolder
        value: ${{ variables.testWorkspace }}/memoryTestsOutput
        readonly: true
    jobs:
    - template: templates/include-test-perf-benchmarks.yml
      parameters:
        poolBuild: ${{ parameters.poolBuild }}
        testWorkspace: ${{ variables.testWorkspace }}
        artifactPipeline: ${{ variables.artifactPipeline }}
        customSteps:

        # Download Artifact - Test Files
        - task: DownloadPipelineArtifact@2
          displayName: Download test files
          inputs:
            # It seems there's a bug and preferTriggeringPipeline is not respected.
            # We force the behavior by explicitly specifying:
            # - buildVersionToDownload: specific
            # - buildId: <the id of the triggering build>
            # preferTriggeringPipeline: true
            source: specific
            project: internal
            pipeline: ${{ variables.artifactPipeline }}
            buildVersionToDownload: specific
            buildId: ${{ variables.artifactBuildId }}
            artifact: test-files
            path: $(Pipeline.Workspace)/test-files/
            # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
            # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

        # Run tests for each package that has them
        - ${{ each testPackage in parameters.memoryTestPackages }}:

          # Download package artifacts
          - task: DownloadPipelineArtifact@2
            displayName: Download test package
            inputs:
              # It seems there's a bug and preferTriggeringPipeline is not respected.
              # We force the behavior by explicitly specifying:
              # - buildVersionToDownload: specific
              # - buildId: <the id of the triggering build>
              # preferTriggeringPipeline: true
              source: specific
              project: internal
              pipeline: ${{ variables.artifactPipeline }}
              buildVersionToDownload: specific
              buildId: ${{ variables.artifactBuildId }}
              artifact: pack
              patterns: "**/${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz"
              path: $(Pipeline.Workspace)/client/pack
              # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
              # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

          # Install test package
          - task: Bash@3
            displayName: Install test package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}
              script: |
                echo "Install ${{ testPackage }}"
                TEST_PACKAGE_FILE_PATTERN=${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz
                TEST_PACKAGE_PATH_PATTERN=$(Pipeline.Workspace)/client/pack/scoped/$TEST_PACKAGE_FILE_PATTERN

                echo $TEST_PACKAGE_FILE_PATTERN
                echo $TEST_PACKAGE_PATH_PATTERN

                echo `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l`
                echo `ls $TEST_PACKAGE_PATH_PATTERN`

                if [[ `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l` -eq 1 ]]; then
                  TEST_PACKAGE_TGZ=`ls $TEST_PACKAGE_PATH_PATTERN`
                else
                  ls -1 $TEST_PACKAGE_PATH_PATTERN
                  echo "##vso[task.logissue type=error]Test package '${{ testPackage }}' not found, or there are more then one found"
                  exit -1
                fi

                npm install $TEST_PACKAGE_TGZ

          # Unpack test files
          - task: Bash@3
            displayName: Unpack test files
            inputs:
              targetType: 'inline'
              script: |
                echo "Unpack test files for ${{ testPackage }}"
                TAR_FILE=${{ replace(replace(replace(replace(testPackage, '@fluidframework/', '' ), '@fluid-internal/', '' ),'@fluid-', '' ), '/', '-') }}
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test
                tar -xvf $(Pipeline.Workspace)/test-files/$TAR_FILE.test-files.tar -C $(Pipeline.Workspace)/test-files
                mv $(Pipeline.Workspace)/test-files/src/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test
                mv $(Pipeline.Workspace)/test-files/dist/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test

          # Run tests
          - task: Bash@3
            displayName: Run memory performance tests
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}
              script: |
                echo "Run memory performance test for ${{ testPackage }}"
                cp ${{ variables.testWorkspace }}/.npmrc . ;
                npm i ;
                npm run test:memory-profiling:report;

          # Consolidate output files
          - task: CopyFiles@2
            displayName: Consolidate output files
            inputs:
              sourceFolder: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/.memoryTestsOutput
              contents: '**'
              targetFolder: ${{ variables.consolidatedTestsOutputFolder }}/${{ testPackage }}

          # Cleanup package
          - task: Bash@3
            displayName: 'Cleanup package'
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/
              script: |
                echo "Cleanup package ${{ testPackage }} from ${{ variables.testWorkspace }}/node_modules/"
                rm -rf ${{ testPackage }};

        - task: Bash@3
          displayName: Write measurements to Aria/Kusto
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Write the following benchmark output to Aria/Kusto";
              ls -laR ${{ variables.consolidatedTestsOutputFolder }};
              node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/memoryUsageTestHandler.js --dir ${{ variables.consolidatedTestsOutputFolder }};

        - task: PublishPipelineArtifact@1
          displayName: Publish Artifact - Perf tests output - memory usage
          inputs:
            targetPath: '${{ variables.consolidatedTestsOutputFolder }}'
            artifactName: 'perf-test-outputs_memory-usage'
          condition: succeededOrFailed()

  # Performance e2e tests
  - stage: perf_e2e_tests
    displayName: Perf e2e tests
    dependsOn: []
    variables:
      # The following two paths are defined by the npm scripts invocations in @fluidframework/test-end-to-end-tests
      - name: executionTimeTestOutputFolder
        value: ${{ variables.testWorkspace }}/node_modules/@fluidframework/test-end-to-end-tests/.timeTestsOutput
        readonly: true
      - name: memoryUsageTestOutputFolder
        value: ${{ variables.testWorkspace }}/node_modules/@fluidframework/test-end-to-end-tests/.memoryTestsOutput
        readonly: true
      - name: testPackage
        value: '@fluidframework/test-end-to-end-tests'
        readonly: true
      - name: escapedTestPackage
        value: ${{ replace(replace(variables.testPackage, '@', '' ), '/', '-') }}
        readonly: true
    jobs:
    - template: templates/include-test-perf-benchmarks.yml
      parameters:
        poolBuild: ${{ parameters.poolBuild }}
        testWorkspace: ${{ variables.testWorkspace }}
        artifactPipeline: ${{ variables.artifactPipeline }}
        customSteps:

        # Download test package
        - task: DownloadPipelineArtifact@2
          displayName: Download test package
          inputs:
            # It seems there's a bug and preferTriggeringPipeline is not respected.
            # We force the behavior by explicitly specifying:
            # - buildVersionToDownload: specific
            # - buildId: <the id of the triggering build>
            # preferTriggeringPipeline: true
            source: specific
            project: internal
            pipeline: ${{ variables.artifactPipeline }}
            buildVersionToDownload: specific
            buildId: ${{ variables.artifactBuildId }}
            artifact: pack
            patterns: "**/${{ variables.escapedTestPackage }}-?.?.?-*.tgz"
            path: $(Pipeline.Workspace)/client/pack
            # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
            # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

        # Install e2e test package
        - task: Bash@3
          displayName: Install Test Package
          inputs:
            targetType: 'inline'
            workingDirectory: ${{ variables.testWorkspace }}
            script: |
              echo "Install ${{ variables.testPackage }}"
              TEST_PACKAGE_FILE_PATTERN=${{ variables.escapedTestPackage }}-?.?.?-*.tgz
              TEST_PACKAGE_PATH_PATTERN=$(Pipeline.Workspace)/client/pack/scoped/$TEST_PACKAGE_FILE_PATTERN

              echo $TEST_PACKAGE_FILE_PATTERN
              echo $TEST_PACKAGE_PATH_PATTERN

              echo `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l`
              echo `ls $TEST_PACKAGE_PATH_PATTERN`

              if [[ `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l` -eq 1 ]]; then
                TEST_PACKAGE_TGZ=`ls $TEST_PACKAGE_PATH_PATTERN`
              else
                ls -1 $TEST_PACKAGE_PATH_PATTERN
                echo "##vso[task.logissue type=error]Test package '${{ variables.testPackage }}' not found, or there are more then one found"
                exit -1
              fi

              npm install $TEST_PACKAGE_TGZ

        - task: Bash@3
          displayName: Prepare test package to run tests
          inputs:
            targetType: 'inline'
            workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ variables.testPackage }}
            script: |
              cp ${{ variables.testWorkspace }}/.npmrc . ;
              npm i ;

        # We run both types of tests in the same bash step so we can make sure to run the second set even if the first
        # one fails.
        # Doing this with separate ADO steps is not easy.
        # This step reports failure if either of the test runs reports failure.
        - task: Bash@3
          displayName: Run tests
          inputs:
            targetType: 'inline'
            workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ variables.testPackage }}
            script: |

              # Run execution time tests
              npm run test:benchmark:report;
              executionTimeTestsExitCode=$?;

              # Run memory tests
              npm run test:memory-profiling:report;
              memoryTestsExitCode=$?;

              if [[ $executionTimeTestsExitCode -ne 0 ]]; then
                echo "##vso[task.logissue type=error]Exit code for runtime tests execution = $executionTimeTestsExitCode"
              fi

              if [[ $memoryTestsExitCode -ne 0 ]]; then
                echo "##vso[task.logissue type=error]Exit code for memory tests execution = $memoryTestsExitCode"
              fi

              if [[ $executionTimeTestsExitCode -ne 0 ]] || [[ $memoryTestsExitCode -ne 0 ]]; then
                exit 1;
              fi

        - task: Bash@3
          displayName: Write measurements to Aria/Kusto - execution time
          condition: succeededOrFailed()
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Writing the following performance tests results to Aria/Kusto"
              ls -la ${{ variables.executionTimeTestOutputFolder }};
              node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/executionTimeTestHandler.js --dir ${{ variables.executionTimeTestOutputFolder }};

        - task: Bash@3
          displayName: Write measurements to Aria/Kusto - memory usage
          condition: succeededOrFailed()
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Writing the following performance tests results to Aria/Kusto"
              ls -la ${{ variables.memoryUsageTestOutputFolder }};
              node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/memoryUsageTestHandler.js --dir ${{ variables.memoryUsageTestOutputFolder }};

        - task: PublishPipelineArtifact@1
          displayName: Publish Artifact - E2E perf tests output - execution time
          condition: succeededOrFailed()
          inputs:
            targetPath: '${{ variables.executionTimeTestOutputFolder }}'
            artifactName: 'perf-test-outputs-e2e_execution-time'

        - task: PublishPipelineArtifact@1
          displayName: Publish Artifact - E2E perf tests output - memory usage
          condition: succeededOrFailed()
          inputs:
            targetPath: '${{ variables.memoryUsageTestOutputFolder }}'
            artifactName: 'perf-test-outputs-e2e_memory-usage'
