# Copyright (c) Microsoft Corporation and contributors. All rights reserved.
# Licensed under the MIT License.

name: $(Build.BuildId)

trigger: none
pr: none

resources:
  pipelines:
  - pipeline: client   # Name of the pipeline resource
    source: Build - client packages
    branch: main # Default branch for manual/scheduled triggers if none is selected
    trigger:
      branches:
      - release/*
      - main
      - next
      - lts

parameters:

- name: poolBuild
  type: object
  default: Large

- name: memoryTestPackages
  type: object
  default:
    - "@fluidframework/sequence"
    - "@fluidframework/map"
    - "@fluidframework/matrix"

- name: executionTestPackages
  type: object
  default:
    - "@fluid-experimental/tree2"
    - "@fluid-experimental/tree"
    - "@fluidframework/merge-tree"

# Performance e2e tests
- name: endpoints
  type: object
  default:
  - endpointName: 'local'
  - endpointName: 'odsp'
    lockVariableGroupName: 'e2e-odsp-lock'
    timeoutInMinutes: 360
  - endpointName: 'frs'
    lockVariableGroupName: 'e2e-frs-lock'
    timeoutInMinutes: 360

variables:
  # We use 'chalk' to colorize output, which auto-detects color support in the
  # running terminal.  The log output shown in Azure DevOps job runs only has
  # basic ANSI color support though, so force that in the pipeline
  - name: FORCE_COLOR
    value: 1
    readonly: true
  - name: testWorkspace
    value: $(Pipeline.Workspace)/test
    readonly: true
  - name: artifactPipeline
    value: $(resources.pipeline.client.pipelineName)
    readonly: true
  - name: artifactBuildId
    value: $(resources.pipeline.client.runID)
    readonly: true
  - name: toolAbsolutePath
    value: $(Build.SourcesDirectory)/tools/telemetry-generator
    readonly: true
  - group: prague-key-vault

lockBehavior: sequential
stages:
  # Performance unit tests - runtime
  - stage: perf_unit_tests_runtime
    displayName: Perf unit tests - runtime
    dependsOn: []
    variables:
      - name: consolidatedTestsOutputFolder
        value: ${{ variables.testWorkspace }}/benchmarkOutput
        readonly: true
    jobs:
    - template: templates/include-test-perf-benchmarks.yml
      parameters:
        poolBuild: ${{ parameters.poolBuild }}
        testWorkspace: ${{ variables.testWorkspace }}
        customSteps:

        # Download artifact with test files
        - task: DownloadPipelineArtifact@2
          displayName: Download test files
          inputs:
            # It seems there's a bug and preferTriggeringPipeline is not respected.
            # We force the behavior by explicitly specifying:
            # - buildVersionToDownload: specific
            # - buildId: <the id of the triggering build>
            # preferTriggeringPipeline: true
            source: specific
            project: internal
            pipeline: ${{ variables.artifactPipeline }}
            buildVersionToDownload: specific
            buildId: ${{ variables.artifactBuildId }}
            artifact: test-files
            path: $(Pipeline.Workspace)/test-files/
            # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
            # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

        # Run tests for each package that has them
        - ${{ each testPackage in parameters.executionTestPackages }}:

          # Download artifact for package to be tested
          - task: DownloadPipelineArtifact@2
            displayName: Download test package
            inputs:
              # It seems there's a bug and preferTriggeringPipeline is not respected.
              # We force the behavior by explicitly specifying:
              # - buildVersionToDownload: specific
              # - buildId: <the id of the triggering build>
              # preferTriggeringPipeline: true
              source: specific
              project: internal
              pipeline: ${{ variables.artifactPipeline }}
              buildVersionToDownload: specific
              buildId: ${{ variables.artifactBuildId }}
              artifact: pack
              patterns: "**/${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz"
              path: $(Pipeline.Workspace)/client/pack
              # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
              # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

          # Install package to be tested
          - task: Bash@3
            displayName: Install test package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}
              script: |
                echo "Install ${{ testPackage }}"
                TEST_PACKAGE_FILE_PATTERN=${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz
                TEST_PACKAGE_PATH_PATTERN=$(Pipeline.Workspace)/client/pack/scoped/$TEST_PACKAGE_FILE_PATTERN

                echo $TEST_PACKAGE_FILE_PATTERN
                echo $TEST_PACKAGE_PATH_PATTERN

                echo `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l`
                echo `ls $TEST_PACKAGE_PATH_PATTERN`

                if [[ `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l` -eq 1 ]]; then
                  TEST_PACKAGE_TGZ=`ls $TEST_PACKAGE_PATH_PATTERN`
                else
                  ls -1 $TEST_PACKAGE_PATH_PATTERN
                  echo "##vso[task.logissue type=error]Test package '${{ testPackage }}' not found, or there are more then one found"
                  exit -1
                fi

                npm install $TEST_PACKAGE_TGZ

          # Unpack test files
          - task: Bash@3
            displayName: Unpack test files
            inputs:
              targetType: 'inline'
              script: |
                echo "Unpack test files for ${{ testPackage }}"
                TAR_FILE=${{ replace(replace(replace(replace(testPackage, '@fluidframework/', '' ), '@fluid-internal/', '' ),'@fluid-', '' ), '/', '-') }}
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test
                tar -xvf $(Pipeline.Workspace)/test-files/$TAR_FILE.test-files.tar -C $(Pipeline.Workspace)/test-files
                mv $(Pipeline.Workspace)/test-files/dist/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test
                mv $(Pipeline.Workspace)/test-files/src/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test

          # Run tests
          - task: Bash@3
            displayName: Run execution-time tests
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}
              script: |
                echo "Run execution-time tests for ${{ testPackage }}"
                cp ${{ variables.testWorkspace }}/.npmrc . ;
                npm i;
                npm run test:benchmark:report;

          # Consolidate output files
          - task: CopyFiles@2
            displayName: Consolidate output files
            inputs:
              sourceFolder: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/node_modules/@fluid-tools/benchmark/dist/.output/
              contents: '**'
              targetFolder: ${{ variables.consolidatedTestsOutputFolder }}/${{ testPackage }}

          # Cleanup package
          - task: Bash@3
            displayName: Cleanup package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/
              script: |
                echo "Cleanup package ${{ testPackage }} from ${{ variables.testWorkspace }}/node_modules/"
                rm -rf ${{ testPackage }};

        - task: Bash@3
          displayName: Write measurements to Aria/Kusto
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Write the following benchmark output to Aria/Kusto"
              ls -laR ${{ variables.consolidatedTestsOutputFolder }};
              node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/executionTimeTestHandler.js --dir '${{ variables.consolidatedTestsOutputFolder }}';

        - task: Bash@3
          displayName: Send Execution Time Performance Benchmark Measurments to Azure App Insights
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Writing performance benchmark output to Azure App Insights..."
              ls -laR ${{ variables.consolidatedTestsOutputFolder }};
              node bin/run appInsights --handlerModule $(toolAbsolutePath)/dist/handlers/appInsightsExecutionTimeTestHandler.js --dir '${{ variables.consolidatedTestsOutputFolder }}' --connectionString '$(fluid-interal-app-insights-connection-string)';
          env:
            BUILD_ID: $(Build.BuildId)
            BRANCH_NAME: $(Build.SourceBranchName)

        - task: PublishPipelineArtifact@1
          displayName: Publish Artifact - Perf tests output - execution time
          inputs:
            targetPath: '${{ variables.consolidatedTestsOutputFolder }}'
            artifactName: 'perf-test-outputs_execution-time'
          condition: succeededOrFailed()

  # Performance unit tests - memory
  - stage: perf_unit_tests_memory
    displayName: Perf unit tests - memory
    dependsOn: []
    variables:
      - name: consolidatedTestsOutputFolder
        value: ${{ variables.testWorkspace }}/memoryTestsOutput
        readonly: true
    jobs:
    - template: templates/include-test-perf-benchmarks.yml
      parameters:
        poolBuild: ${{ parameters.poolBuild }}
        testWorkspace: ${{ variables.testWorkspace }}
        customSteps:

        # Download Artifact - Test Files
        - task: DownloadPipelineArtifact@2
          displayName: Download test files
          inputs:
            # It seems there's a bug and preferTriggeringPipeline is not respected.
            # We force the behavior by explicitly specifying:
            # - buildVersionToDownload: specific
            # - buildId: <the id of the triggering build>
            # preferTriggeringPipeline: true
            source: specific
            project: internal
            pipeline: ${{ variables.artifactPipeline }}
            buildVersionToDownload: specific
            buildId: ${{ variables.artifactBuildId }}
            artifact: test-files
            path: $(Pipeline.Workspace)/test-files/
            # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
            # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

        # Run tests for each package that has them
        - ${{ each testPackage in parameters.memoryTestPackages }}:

          # Download package artifacts
          - task: DownloadPipelineArtifact@2
            displayName: Download test package
            inputs:
              # It seems there's a bug and preferTriggeringPipeline is not respected.
              # We force the behavior by explicitly specifying:
              # - buildVersionToDownload: specific
              # - buildId: <the id of the triggering build>
              # preferTriggeringPipeline: true
              source: specific
              project: internal
              pipeline: ${{ variables.artifactPipeline }}
              buildVersionToDownload: specific
              buildId: ${{ variables.artifactBuildId }}
              artifact: pack
              patterns: "**/${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz"
              path: $(Pipeline.Workspace)/client/pack
              # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
              # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

          # Install test package
          - task: Bash@3
            displayName: Install test package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}
              script: |
                echo "Install ${{ testPackage }}"
                TEST_PACKAGE_FILE_PATTERN=${{ replace(replace(testPackage, '@', '' ), '/', '-') }}-?.?.?-*.tgz
                TEST_PACKAGE_PATH_PATTERN=$(Pipeline.Workspace)/client/pack/scoped/$TEST_PACKAGE_FILE_PATTERN

                echo $TEST_PACKAGE_FILE_PATTERN
                echo $TEST_PACKAGE_PATH_PATTERN

                echo `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l`
                echo `ls $TEST_PACKAGE_PATH_PATTERN`

                if [[ `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l` -eq 1 ]]; then
                  TEST_PACKAGE_TGZ=`ls $TEST_PACKAGE_PATH_PATTERN`
                else
                  ls -1 $TEST_PACKAGE_PATH_PATTERN
                  echo "##vso[task.logissue type=error]Test package '${{ testPackage }}' not found, or there are more then one found"
                  exit -1
                fi

                npm install $TEST_PACKAGE_TGZ

          # Unpack test files
          - task: Bash@3
            displayName: Unpack test files
            inputs:
              targetType: 'inline'
              script: |
                echo "Unpack test files for ${{ testPackage }}"
                TAR_FILE=${{ replace(replace(replace(replace(testPackage, '@fluidframework/', '' ), '@fluid-internal/', '' ),'@fluid-', '' ), '/', '-') }}
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test
                mkdir -p ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test
                tar -xvf $(Pipeline.Workspace)/test-files/$TAR_FILE.test-files.tar -C $(Pipeline.Workspace)/test-files
                mv $(Pipeline.Workspace)/test-files/src/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/src/test
                mv $(Pipeline.Workspace)/test-files/dist/test/* ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/dist/test

          # Run tests
          - task: Bash@3
            displayName: Run memory performance tests
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}
              script: |
                echo "Run memory performance test for ${{ testPackage }}"
                cp ${{ variables.testWorkspace }}/.npmrc . ;
                npm i ;
                npm run test:memory-profiling:report;

          # Consolidate output files
          - task: CopyFiles@2
            displayName: Consolidate output files
            inputs:
              sourceFolder: ${{ variables.testWorkspace }}/node_modules/${{ testPackage }}/.memoryTestsOutput
              contents: '**'
              targetFolder: ${{ variables.consolidatedTestsOutputFolder }}/${{ testPackage }}

          # Cleanup package
          - task: Bash@3
            displayName: 'Cleanup package'
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/
              script: |
                echo "Cleanup package ${{ testPackage }} from ${{ variables.testWorkspace }}/node_modules/"
                rm -rf ${{ testPackage }};

        - task: Bash@3
          displayName: Write measurements to Aria/Kusto
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Write the following benchmark output to Aria/Kusto";
              ls -laR ${{ variables.consolidatedTestsOutputFolder }};
              node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/memoryUsageTestHandler.js --dir ${{ variables.consolidatedTestsOutputFolder }};

        - task: Bash@3
          displayName: Send Memory Usage Performance Benchmark Measurments to Azure App Insights
          inputs:
            targetType: 'inline'
            workingDirectory: $(toolAbsolutePath)
            script: |
              echo "Writing performance benchmark output to Azure App Insights..."
              ls -laR ${{ variables.consolidatedTestsOutputFolder }};
              node bin/run appInsights --handlerModule $(toolAbsolutePath)/dist/handlers/appInsightsMemoryUsageTestHandler.js --dir '${{ variables.consolidatedTestsOutputFolder }}' --connectionString '$(fluid-interal-app-insights-connection-string)';
          env:
            BUILD_ID: $(Build.BuildId)
            BRANCH_NAME: $(Build.SourceBranchName)

        - task: PublishPipelineArtifact@1
          displayName: Publish Artifact - Perf tests output - memory usage
          inputs:
            targetPath: '${{ variables.consolidatedTestsOutputFolder }}'
            artifactName: 'perf-test-outputs_memory-usage'
          condition: succeededOrFailed()

  - ${{ each endpointObject in parameters.endpoints }}:

    - stage: perf_e2e_tests_${{ endpointObject.endpointName }}
      displayName: Perf e2e tests - ${{ endpointObject.endpointName }}
      dependsOn: []
      variables:
        # Use contention-lock variable groups when appropriate. Note that null gets coalesced into an empty string.
        - ${{ if ne(endpointObject.lockVariableGroupName, '') }}:
          - group: ${{ endpointObject.lockVariableGroupName }}

        # The following two paths are defined by the npm scripts invocations in @fluid-internal/test-end-to-end-tests
        - name: executionTimeTestOutputFolder
          value: ${{ variables.testWorkspace }}/node_modules/@fluid-internal/test-end-to-end-tests/.timeTestsOutput
          readonly: true
        - name: memoryUsageTestOutputFolder
          value: ${{ variables.testWorkspace }}/node_modules/@fluid-internal/test-end-to-end-tests/.memoryTestsOutput
          readonly: true
        - name: testPackage
          value: '@fluid-internal/test-end-to-end-tests'
          readonly: true
        - name: escapedTestPackage
          value: ${{ replace(replace(variables.testPackage, '@', '' ), '/', '-') }}
          readonly: true
      jobs:
      - template: templates/include-test-perf-benchmarks.yml
        parameters:
          poolBuild: ${{ parameters.poolBuild }}
          testWorkspace: ${{ variables.testWorkspace }}
          timeoutInMinutes: ${{ coalesce(endpointObject.timeoutInMinutes, 60) }}
          customSteps:

          # Download test package
          - task: DownloadPipelineArtifact@2
            displayName: Download test package
            inputs:
              # It seems there's a bug and preferTriggeringPipeline is not respected.
              # We force the behavior by explicitly specifying:
              # - buildVersionToDownload: specific
              # - buildId: <the id of the triggering build>
              # preferTriggeringPipeline: true
              source: specific
              project: internal
              pipeline: ${{ variables.artifactPipeline }}
              buildVersionToDownload: specific
              buildId: ${{ variables.artifactBuildId }}
              artifact: pack
              patterns: "**/${{ variables.escapedTestPackage }}-?.?.?-*.tgz"
              path: $(Pipeline.Workspace)/client/pack
              # allowPartiallySucceededBuilds: true # No effect as long as we have buildVersionToDownload: specific
              # branchName: $(Build.SourceBranch)   # No effect as long as we have buildVersionToDownload: specific

          # Install e2e test package
          - task: Bash@3
            displayName: Install Test Package
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}
              script: |
                echo "Install ${{ variables.testPackage }}"
                TEST_PACKAGE_FILE_PATTERN=${{ variables.escapedTestPackage }}-?.?.?-*.tgz
                TEST_PACKAGE_PATH_PATTERN=$(Pipeline.Workspace)/client/pack/scoped/$TEST_PACKAGE_FILE_PATTERN

                echo $TEST_PACKAGE_FILE_PATTERN
                echo $TEST_PACKAGE_PATH_PATTERN

                echo `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l`
                echo `ls $TEST_PACKAGE_PATH_PATTERN`

                if [[ `ls -1 $TEST_PACKAGE_PATH_PATTERN | wc -l` -eq 1 ]]; then
                  TEST_PACKAGE_TGZ=`ls $TEST_PACKAGE_PATH_PATTERN`
                else
                  ls -1 $TEST_PACKAGE_PATH_PATTERN
                  echo "##vso[task.logissue type=error]Test package '${{ variables.testPackage }}' not found, or there are more then one found"
                  exit -1
                fi

                npm install $TEST_PACKAGE_TGZ

          - task: Bash@3
            displayName: Prepare test package to run tests
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ variables.testPackage }}
              script: |
                cp ${{ variables.testWorkspace }}/.npmrc . ;
                npm i ;

          # We run both types of tests in the same bash step so we can make sure to run the second set even if the first
          # one fails.
          # Doing this with separate ADO steps is not easy.
          # This step reports failure if either of the test runs reports failure.
          - task: Bash@3
            displayName: Run tests ${{ endpointObject.endpointName }}
            inputs:
              targetType: 'inline'
              workingDirectory: ${{ variables.testWorkspace }}/node_modules/${{ variables.testPackage }}
              script: |

                echo "FLUID_LOGGER_PROPS = $FLUID_LOGGER_PROPS"

                # Run execution time tests
                echo "FLUID_ENDPOINTNAME = $FLUID_ENDPOINTNAME"
                if [[ '${{ endpointObject.endpointName }}' == 'local' ]]; then
                  npm run test:benchmark:report;
                else
                  npm run test:benchmark:report:${{ endpointObject.endpointName }};
                fi
                executionTimeTestsExitCode=$?;

                echo "FLUID_ENDPOINTNAME = $FLUID_ENDPOINTNAME"
                # Run memory tests
                if [[ '${{ endpointObject.endpointName }}' == 'local' ]]; then
                  npm run test:memory-profiling:report;
                else
                  npm run test:memory-profiling:report:${{ endpointObject.endpointName }};
                fi

                memoryTestsExitCode=$?;

                if [[ $executionTimeTestsExitCode -ne 0 ]]; then
                  echo "##vso[task.logissue type=error]Exit code for runtime tests execution = $executionTimeTestsExitCode ${{ endpointObject.endpointName }}"
                fi

                if [[ $memoryTestsExitCode -ne 0 ]]; then
                  echo "##vso[task.logissue type=error]Exit code for memory tests execution = $memoryTestsExitCode ${{ endpointObject.endpointName }}"
                fi

                if [[ $executionTimeTestsExitCode -ne 0 ]] || [[ $memoryTestsExitCode -ne 0 ]]; then
                  exit 1;
                fi
            env:
              FLUID_TEST_LOGGER_PKG_PATH: ${{ variables.testWorkspace }}/node_modules/@ff-internal/aria-logger # Contains getTestLogger impl to inject
              FLUID_BUILD_ID: $(Build.BuildId)
              FLUID_ENDPOINTNAME: ${{ endpointObject.endpointName }}
              FLUID_LOGGER_PROPS: '{ "hostName": "Benchmark" }'
              login__microsoft__clientId: $(login-microsoft-clientId)
              login__microsoft__secret: $(login-microsoft-secret)
              ${{ if eq( endpointObject.endpointName, 'odsp' ) }}:
                login__odsp__test__tenants: $(automation-stress-login-odsp-test-tenants)
              ${{ if eq( endpointObject.endpointName, 'frs' ) }}:
                fluid__test__driver__frs: $(automation-fluid-test-driver-frs-stress-test)

          - task: Bash@3
            displayName: Write measurements to Aria/Kusto - execution time ${{ endpointObject.endpointName }}
            condition: succeededOrFailed()
            inputs:
              targetType: 'inline'
              workingDirectory: $(toolAbsolutePath)
              script: |
                echo "Writing the following performance tests results to Aria/Kusto - ${{ endpointObject.endpointName }}"
                ls -la ${{ variables.executionTimeTestOutputFolder }};
                node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/executionTimeTestHandler.js --dir ${{ variables.executionTimeTestOutputFolder }};
            env:
              FLUID_ENDPOINTNAME: ${{ endpointObject.endpointName }}

          - task: Bash@3
            displayName: Write measurements to Aria/Kusto - memory usage ${{ endpointObject.endpointName }}
            condition: succeededOrFailed()
            inputs:
              targetType: 'inline'
              workingDirectory: $(toolAbsolutePath)
              script: |
                echo "Writing the following performance tests results to Aria/Kusto - ${{ endpointObject.endpointName }}"
                ls -la ${{ variables.memoryUsageTestOutputFolder }};
                node --require @ff-internal/aria-logger bin/run --handlerModule $(toolAbsolutePath)/dist/handlers/memoryUsageTestHandler.js --dir ${{ variables.memoryUsageTestOutputFolder }};
            env:
              FLUID_ENDPOINTNAME: ${{ endpointObject.endpointName }}

          - task: Bash@3
            displayName: Send Execution Time Perf Benchmark Measurements to Azure App Insights
            condition: eq('${{ endpointObject.endpointName }}', 'local')
            inputs:
              targetType: 'inline'
              workingDirectory: $(toolAbsolutePath)
              script: |
                echo "Writing execution time performance benchmark output to Azure App Insights..."
                ls -laR ${{ variables.executionTimeTestOutputFolder }};
                node bin/run appInsights --handlerModule $(toolAbsolutePath)/dist/handlers/appInsightsExecutionTimeTestHandler.js --dir '${{ variables.executionTimeTestOutputFolder }}' --connectionString '$(fluid-interal-app-insights-connection-string)';
            env:
              BUILD_ID: $(Build.BuildId)
              BRANCH_NAME: $(Build.SourceBranchName)
              FLUID_ENDPOINTNAME: ${{ endpointObject.endpointName }}

          - task: Bash@3
            displayName: Send Memory Usage Perf Benchmark Measurements to Azure App Insights
            condition: eq('${{ endpointObject.endpointName }}', 'local')
            inputs:
              targetType: 'inline'
              workingDirectory: $(toolAbsolutePath)
              script: |
                echo "Writing memory usage performance benchmark output to Azure App Insights..."
                ls -laR ${{ variables.memoryUsageTestOutputFolder }};
                node bin/run appInsights --handlerModule $(toolAbsolutePath)/dist/handlers/appInsightsMemoryUsageTestHandler.js --dir '${{ variables.memoryUsageTestOutputFolder }}' --connectionString '$(fluid-interal-app-insights-connection-string)';
            env:
              BUILD_ID: $(Build.BuildId)
              BRANCH_NAME: $(Build.SourceBranchName)
              FLUID_ENDPOINTNAME: ${{ endpointObject.endpointName }}

          - task: PublishPipelineArtifact@1
            displayName: Publish Artifact - E2E perf tests output - execution time {{ $stage }}
            condition: succeededOrFailed()

            inputs:
              targetPath: '${{ variables.executionTimeTestOutputFolder }}'
              artifactName: 'perf-test-outputs-e2e_execution-time-${{ endpointObject.endpointName }}'

          - task: PublishPipelineArtifact@1
            displayName: Publish Artifact - E2E perf tests output - memory usage {{ $stage }}
            condition: succeededOrFailed()
            inputs:
              targetPath: '${{ variables.memoryUsageTestOutputFolder }}'
              artifactName: 'perf-test-outputs-e2e_memory-usage-${{ endpointObject.endpointName }}'

          - task: Bash@3
            displayName: Remove Output Folders from local server run ${{ endpointObject.endpointName }}
            inputs:
              targetType: 'inline'
              workingDirectory: $(toolAbsolutePath)
              script: |
                ls -laR ${{ variables.executionTimeTestOutputFolder }};
                echo "Cleanup  ${{ variables.executionTimeTestOutputFolder }}"
                rm -rf ${{ variables.executionTimeTestOutputFolder }};
                ls -laR ${{ variables.memoryUsageTestOutputFolder }};
                echo "Cleanup  ${{ variables.memoryUsageTestOutputFolder }}"
                rm -rf ${{ variables.memoryUsageTestOutputFolder }};

  - stage: runAfterAll
    condition: always()
    dependsOn:
      - perf_unit_tests_runtime
      - perf_unit_tests_memory
      - perf_e2e_tests_local
      - perf_e2e_tests_odsp
      - perf_e2e_tests_frs

    jobs:
      - template: templates/include-test-perf-benchmarks.yml
        parameters:
          poolBuild: ${{ parameters.poolBuild }}
          testWorkspace: ${{ variables.testWorkspace }}
          customSteps:

          - task: Bash@3
            displayName: Retrieve and Upload pipeline run stats to Kusto
            inputs:
              targetType: 'inline'
              workingDirectory: $(toolAbsolutePath)
              script: |
                echo "creating output folder"
                mkdir -p ${{ variables.testWorkspace }}/timingOutput
                echo "Executing curl command ..."
                echo  'curl -u ":<REDACTED>" "https://dev.azure.com/fluidframework/internal/_apis/build/builds/$(Build.BuildId)/timeline"'
                curl -u ":$(System.AccessToken)" "https://dev.azure.com/fluidframework/internal/_apis/build/builds/$(Build.BuildId)/timeline\?api-version\=6.0-preview.1" > ${{ variables.testWorkspace }}/timingOutput/output.json
                pwd;
                ls -laR ${{ variables.testWorkspace }}/timingOutput/output.json;
                cat ${{ variables.testWorkspace }}/timingOutput/output.json;
                node --require @ff-internal/aria-logger bin/run --handlerModule $(Build.SourcesDirectory)/tools/telemetry-generator/dist/handlers/stageTimingRetriever.js --dir '${{ variables.testWorkspace }}/timingOutput/';
            env:
              BUILD_ID: $(Build.BuildId)
              ADO_API_TOKEN: $(System.AccessToken)
              PIPELINE: 'PerformanceBenchmark'
